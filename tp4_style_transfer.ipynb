{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nacho2904/orga_de_datos/blob/main/tp4_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yu-Gi-Oh Style Transfer"
      ],
      "metadata": {
        "id": "Fa2C1AOApMb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook implementaremos un algoritmo de **Neural Style Transfer** (NST) basado en [Gatys et al.](https://arxiv.org/pdf/1508.06576.pdf). Para más información acerca de las diferentes formas de NSS, también tenemos [este otro paper](https://arxiv.org/abs/1705.04058)."
      ],
      "metadata": {
        "id": "nY1Mbw01p8Tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview del problema y el método"
      ],
      "metadata": {
        "id": "t1siigJXqrG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"In fine art, especially painting, humans have mastered the skill to create unique\n",
        "visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is\n",
        "unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition\n",
        "near-human performance was recently demonstrated by a class of biologically\n",
        "inspired vision models called Deep Neural Networks. Here we introduce an\n",
        "artificial system based on a Deep Neural Network that creates artistic images\n",
        "of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural\n",
        "algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and\n",
        "biological vision, our work offers a path forward to an algorithmic under-\n",
        "standing of how humans create and perceive artistic imagery.\""
      ],
      "metadata": {
        "id": "2r6Ymtc6qwPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En problemas de **Style Transfer**, buscamos utilizar el **contenido** de una imagen $x_c$ y el **estilo** de una imagen $x_s$ para sintetizar una imagen que muestra los objetos de $x_c$ con el estilo de $x_s$.\n",
        "\n",
        " ![Ejemplo de Style Transfer](https://github.com/Nacho2904/orga_de_datos/raw/main/screen.jpg)"
      ],
      "metadata": {
        "id": "or_BAxGcq4th"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por lo tanto, el problema se reduce a encontrar una manera de poder obtener tanto el **estilo** de una imagen $x_s$ (muy relacionado con su **textura**, por lo que ambos términos serán usados de forma intercambiable) y el **contenido** de una imagen $x_c$, y luego encontrar la mejor imagen posible que se ajuste a ambos."
      ],
      "metadata": {
        "id": "ui4micBqscEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más generalmente, podemos relacionar la extracción de contenido de una imagen con problemas de **síntesis de información o reducción de dimensionalidad**. Lo que estamos buscando es un **feature map** que nos resuma las partes relevantes de la imagen y que nos permita reconstruir su contenido en base a ello."
      ],
      "metadata": {
        "id": "Zv3PBi0Cue_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por otro lado, el problema de **modelado de texturas visuales** es un problema considerablemente más complejo que no es tan fácil de encasillar. Resumidamente, hay dos formas de atacarlo: el **modelado paramétrico de texturas** utiliza métodos estadísticos para describir la imagen, por ejemplo usando correlaciones entre diferentes lugares de la imagen, mientras que el **modelado no paramétrico mediante campos aleatorios de Markov** utiliza técnicas probabilísticas para modelar pixeles y sus vecindarios."
      ],
      "metadata": {
        "id": "nZbC8XH0vuNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, también necesitamos recontruir la imagen a partir de un resumen del contenido y del estilo. Para ello también hay varios métodos posibles dependiendo de qué utilizamos para extraer el contenido y el estilo."
      ],
      "metadata": {
        "id": "pdyBw9U8x_DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un ejemplo muy simple posible de Style Transfer sería reducir la dimensionalidad de la imagen de contenido mediante una técnica de dimensionality reduction como PCA que extraería el contenido de la imagen (antes habría que preprocesar la imagen para que tenga las dimensiones adecuadas, además de que habría que aplicarle filtros). Con el PCA entrenado en un conjunto de imágenes con el estilo deseado, podríamos aplicar un algoritmo de clustering sobre el espacio de dimensionalidad baja como $KMeans$.\n",
        "\n",
        "Con ello, podríamos reducir $x_c$ al espacio latente para resumir su contenido, y buscar el centroide más cercano $\\mu_s$ y utilizarlo como media para una distribución normal, cuya covarianza sería la matriz de covarianza de los factores latentes del PCA. De esta forma, el centroide nos daría el contenido y la matriz de covarianza, el estilo. "
      ],
      "metadata": {
        "id": "mkWf2QpxySSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Style Transfer"
      ],
      "metadata": {
        "id": "PA3nwXhHx35c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando utilizamos una red neuronal convolucional (CNN) sobre imágenes generalmente lo que buscamos es modelar una distribución $p(y|x)$, donde $y \\in \\mathcal{Y}$, $\\mathcal{Y}$ siendo el conjunto de clases, y $x \\in \\mathbb{R}^{C \\times H \\times W}$ es la imagen que queremos clasificar, con $C$ la cantidad de **canales**, $H$ y $W$ la altura y ancho. "
      ],
      "metadata": {
        "id": "Jaj2nw8Yz89D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentro de la red neuronal, esencialmente el modelo va reduciendo progresivamente la dimensionalidad de la imagen mediante una combinación de layers de filtro (layers de $convolución$) y layers de $pooling$. \n",
        "\n",
        "El paper del que extraemos el método explora la posibilidad de utilizar los outputs de los layers de convolución (que efectivamente es una reducción de dimensiones de la imagen original) como **feature maps** que extraen el contenido de la imagen, y utilizar estadísticas de dichos feature maps como representaciones del estilo de la imagen, pudiendo simultáneamente obtener una forma de extraer el estilo y el contenido mediante el entrenamiento de una CNN en una tarea de clasificación."
      ],
      "metadata": {
        "id": "lZZXSZ1M1P1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Ejemplo de NST](https://github.com/Nacho2904/orga_de_datos/raw/main/screen01.jpg)"
      ],
      "metadata": {
        "id": "BGI1CL2N477n"
      }
    }
  ]
}