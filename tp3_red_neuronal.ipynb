{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1W0lM0rzUN8VMWorH/qXu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nacho2904/orga_de_datos/blob/main/tp3_red_neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "h_aJs-4Im0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ea34e2-714c-470e-dc09-2d4dd628d5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from google.colab import drive \n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import functools\n",
        "drive.mount('/content/gdrive')\n",
        "path_a_training_set = 'gdrive/MyDrive/TP3 dataset music/train.parquet'\n",
        "path_a_test_set = 'gdrive/MyDrive/TP3 dataset music/test.parquet'\n",
        "\n",
        "\n",
        "df_music_train = pd.read_parquet(path_a_training_set).fillna(\"\")\n",
        "df_music_test = pd.read_parquet(path_a_test_set).fillna(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "fwptY_P6y2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "def apply_sentiment_analysis_to_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  negative, neutral, positive, compound = 0, 1, 2, 3\n",
        "  sentimentAnalysisOfLyrics = df_music[\"lyric\"].map(lambda lyric: list(sia.polarity_scores(lyric).values()))\n",
        "  negativeScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[negative])\n",
        "  positiveScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[positive])\n",
        "  neutralScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[neutral])\n",
        "  compoundScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[compound])\n",
        "  return pd.DataFrame(pd.concat([negativeScoreOfLyrics, positiveScoreOfLyrics,neutralScoreOfLyrics,compoundScoreOfLyrics], axis = 1))"
      ],
      "metadata": {
        "id": "hMMWFU6D4BON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3d4e86-9807-4b16-cf18-4d072234b729"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "genres = list(df_music_train[\"genre\"].unique())\n",
        "def get_vectorizers_by_genre(df_music: pd.DataFrame) -> dict:\n",
        "  df_music_lyric_tokenized = df_music.copy().fillna(\"\")\n",
        "  df_music_lyric_tokenized[\"lyric\"] = df_music_lyric_tokenized[\"lyric\"].map(lambda lyric: set(nltk.word_tokenize(lyric)))\n",
        "  df_music_grouped_by_genre = df_music_lyric_tokenized[[\"genre\", \"lyric\"]].groupby('genre').agg(lambda x: functools.reduce(set.union, x)).reset_index()\n",
        "  vocabs = dict(zip(df_music_grouped_by_genre.genre.to_list(), df_music_grouped_by_genre.lyric.to_list()))\n",
        "  stopwords = set(nltk.corpus.stopwords.words(\"english\")).union(set(nltk.corpus.stopwords.words(\"spanish\"))).union(set(nltk.corpus.stopwords.words(\"french\")))\n",
        "  vectorizers = {genre: TfidfVectorizer(input = \"content\", stop_words = stopwords, vocabulary = vocabs[genre]) for genre in genres}\n",
        "  for genre in genres:\n",
        "    vectorizers[genre].fit(df_music[df_music[\"genre\"] == genre][\"genre\"])\n",
        "  return vectorizers\n",
        "\n",
        "vectorizers = get_vectorizers_by_genre(df_music_train)"
      ],
      "metadata": {
        "id": "UuLe4UY82Fv9",
        "outputId": "1facb303-918d-46a3-8abe-e054da45874e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_tfidf_from_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music = df_music.fillna(\"\")\n",
        "  column_names = [\"sum_tfidf_for_\" + genre.lower() for genre in genres]\n",
        "  for i in range(0, len(genres)):\n",
        "    df_music[column_names[i]] = np.sum(vectorizers[genres[i]].transform(df_music[\"lyric\"]), axis = 1)\n",
        "  return df_music[column_names]"
      ],
      "metadata": {
        "id": "Hn7ojEFq-YXi"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_genres_without_enough_observations(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music_recuento_filas_por_genero = df_music.groupby(\"genre\").count().reset_index()[[\"genre\", \"track_name\"]].rename(\n",
        "    columns = {\"track_name\": \"rowCount\"}).sort_values(\"rowCount\")\n",
        "  problematic_genres = list(df_music_recuento_filas_por_genero[df_music_recuento_filas_por_genero[\"rowCount\"] < 50].genre)[1:]\n",
        "  return df_music[~df_music[\"genre\"].isin(problematic_genres)]"
      ],
      "metadata": {
        "id": "TQCnc16lQAxu"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "def get_length_transforms_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"number_of_lines\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric.split(\"\\n\")))\n",
        "  df_music[\"number_of_tokens\"] = df_music[\"lyric\"].map(lambda lyric: len(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"length_lyrics\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric))\n",
        "  df_music[\"length_of_track_name\"] = df_music[\"track_name\"].map(lambda track_name: len(track_name))\n",
        "  return df_music[[\"length_lyrics\", \"length_of_track_name\", \"number_of_lines\", \"number_of_tokens\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1QqQUHIEHzj",
        "outputId": "03844902-01e7-4a93-f3c2-40890699c624"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_POS_vector_from_lyric_POS(lyric_POS):\n",
        "  useful_pos_tags = [\"FW\", \"JJR\", \"NN\", \"NNS\", \"NNP\", \"PDT\", \"PRP\", \"RB\", \"RBR\",\n",
        "                   \"UH\", \"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"]\n",
        "  POS_dictionary = {pos_tag:0 for pos_tag in useful_pos_tags}\n",
        "  POS_dictionary.update({\"other\":0})\n",
        "\n",
        "  for token in lyric_POS:\n",
        "    if token[1] in useful_pos_tags:\n",
        "      POS_dictionary[token[1]] += 1\n",
        "    else:\n",
        "      POS_dictionary[\"other\"] += 1\n",
        "\n",
        "  return [POS_dictionary[pos_tag] for pos_tag in POS_dictionary]\n",
        "  \n",
        "\n",
        "def get_POS_chunk_taggin_counts_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric\"].map(lambda lyric: nltk.pos_tag(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric_POS\"].map(lambda lyric_pos: get_POS_vector_from_lyric_POS(lyric_pos))\n",
        "  return pd.DataFrame(df_music[\"lyric_POS\"].to_list())\n"
      ],
      "metadata": {
        "id": "LOEyM2E-Ny6P",
        "outputId": "559791f2-ffe9-4cf8-ecd9-cd370da8d8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_music_filtered_genres = eliminate_genres_without_enough_observations(df_music_train)\n",
        "artists = list(df_music_filtered_genres[\"artist\"].unique())\n",
        "train_artists = set(artists[:int(0.9*len(artists))])\n",
        "validation_artists = set(artists[int(0.9*len(artists)):])\n",
        "train_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(train_artists)]\n",
        "validation_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(validation_artists)]"
      ],
      "metadata": {
        "id": "0WXfDLhA174X"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_hot_encoder(df_music: pd.DataFrame, df_training: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_training_grouped_by_lang = df_training.groupby(\"language\").mean().reset_index()[[\"language\", \"popularity\", \"a_popularity\", \"loudness\"]]\n",
        "  df_new_columns = df_music.merge(df_training_grouped_by_lang, on = \"language\", how = \"left\")\n",
        "  return df_new_columns[[\"popularity_y\", \"a_popularity_y\", \"loudness_y\"]].fillna(0)\n",
        "\n",
        "mean_hot_encoder_using_training_set = lambda df_to_encode: mean_hot_encoder(df_to_encode, df_music_train) "
      ],
      "metadata": {
        "id": "wG1TiABKECHD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "text_features = [\"track_name\", \"lyric\", \"artist\"]\n",
        "\n",
        "numerical_features = [\"a_songs\", \"a_popularity\", \"popularity\", \"acousticness\", \"danceability\", \"duration_ms\",\n",
        "                   \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\"]\n",
        "\n",
        "ordinal_features = [\"key\", \"time_signature\"]\n",
        "\n",
        "one_hot_features = [\"mode\"]\n",
        "\n",
        "mean_enc_features = [\"language\"]\n",
        "\n",
        "artist_genres = [\"a_genres\", \"genre\"]\n",
        "\n",
        "label = [\"genre\"]\n",
        "\n",
        "identity_transformer = preprocessing.FunctionTransformer(None)\n",
        "\n",
        "full_processor = ColumnTransformer(transformers=[\n",
        "    ('text_sentiment_analysis', preprocessing.FunctionTransformer(apply_sentiment_analysis_to_lyrics), text_features),\n",
        "    ('text_tf_idf', preprocessing.FunctionTransformer(get_sum_tfidf_from_lyrics), text_features),\n",
        "    ('text_simple_transforms', preprocessing.FunctionTransformer(get_length_transforms_for_text), text_features),\n",
        "    ('text_POS_count', preprocessing.FunctionTransformer(get_POS_chunk_taggin_counts_for_text), text_features),\n",
        "    ('mean_encoding', preprocessing.FunctionTransformer(mean_hot_encoder_using_training_set), list(df_music_train.columns)),\n",
        "    ('one_hot_encoding', preprocessing.OneHotEncoder(), one_hot_features),\n",
        "    ('numerical', identity_transformer, numerical_features),\n",
        "    ('ordinal', preprocessing.OrdinalEncoder(categories = [['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'],\n",
        "                                                            ['1/4', '3/4', '4/4', '5/4']]), ordinal_features)])\n"
      ],
      "metadata": {
        "id": "ApBgPVOuocwU"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red Neuronal"
      ],
      "metadata": {
        "id": "h4qA0iu40-GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = full_processor.fit_transform(train_set)\n",
        "y_train = label_encoder.transform(train_set.genre)\n",
        "X_validation = full_processor.transform(validation_set)\n",
        "y_validation = label_encoder.transform(validation_set.genre)"
      ],
      "metadata": {
        "id": "2BSfUO_v1aEl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(model):\n",
        "    for l in model.layers:\n",
        "        if hasattr(l,\"kernel_initializer\"):\n",
        "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
        "        if hasattr(l,\"bias_initializer\"):\n",
        "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
        "        if hasattr(l,\"recurrent_initializer\"):\n",
        "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))\n"
      ],
      "metadata": {
        "id": "of1d2SgUqZRX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_columns = X_train.shape[1]\n",
        "num_classes = len(label_encoder.classes_)\n",
        "width = 40\n",
        "depth = 20\n",
        "activation = \"ReLU\"\n",
        "\n",
        "input = tf.keras.layers.Input(shape = (num_columns))\n",
        "normalize = tf.keras.layers.Normalization()(input)\n",
        "\n",
        "hidden_layers = [tf.keras.layers.Dense(width- int(0.3*i), activation = activation, kernel_initializer = tf.keras.initializers.HeNormal(),\n",
        "                                       kernel_constraint=tf.keras.constraints.MaxNorm(5))\n",
        "                  for i in range(0,depth)]\n",
        "\n",
        "for i in range(0, depth):\n",
        "  if i==0:\n",
        "    hidden_layers[i] = hidden_layers[i](input)\n",
        "  else:\n",
        "    hidden_layers[i] = hidden_layers[i](hidden_layers[i-1])\n",
        "\n",
        "output = tf.keras.layers.Dense(units = num_classes, activation = \"softmax\")(hidden_layers[-1])\n",
        "model_NN = tf.keras.models.Model(inputs = input, outputs = output)\n",
        "model_NN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yL7Q5xQougL",
        "outputId": "5640f48d-e66b-43b9-8674-86fb102fff89"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 71)]              0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 40)                2880      \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 40)                1640      \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 40)                1640      \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 40)                1640      \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 39)                1599      \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 39)                1560      \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 39)                1560      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 38)                1520      \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 38)                1482      \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 38)                1482      \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 37)                1443      \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 37)                1406      \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 37)                1406      \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 37)                1406      \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 36)                1368      \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 36)                1332      \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 36)                1332      \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 35)                1295      \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 35)                1260      \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 35)                1260      \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 26)                936       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,447\n",
            "Trainable params: 31,447\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_weights(model_NN)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "model_NN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.000001),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 metrics = [\"accuracy\"])\n",
        "\n",
        "hist = model_NN.fit(x=X_train, y=y_train, batch_size = 64, epochs=10000,\n",
        "                 validation_data=(X_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tE71MNcLqKzP",
        "outputId": "6dd9b782-0404-4ead-d3ab-4785a09aadb8"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "453/453 [==============================] - 5s 6ms/step - loss: 14281.6680 - accuracy: 0.0141 - val_loss: 13315.7334 - val_accuracy: 0.0349\n",
            "Epoch 2/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 10716.6631 - accuracy: 0.0141 - val_loss: 10431.7988 - val_accuracy: 0.0349\n",
            "Epoch 3/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 8326.1484 - accuracy: 0.0141 - val_loss: 8229.0996 - val_accuracy: 0.0349\n",
            "Epoch 4/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 6495.8535 - accuracy: 0.0127 - val_loss: 6156.0127 - val_accuracy: 0.0192\n",
            "Epoch 5/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4844.9990 - accuracy: 0.0117 - val_loss: 4881.9189 - val_accuracy: 0.0244\n",
            "Epoch 6/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3993.7329 - accuracy: 0.0128 - val_loss: 4081.3574 - val_accuracy: 0.0292\n",
            "Epoch 7/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3362.2986 - accuracy: 0.0161 - val_loss: 3478.9763 - val_accuracy: 0.0458\n",
            "Epoch 8/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2813.4094 - accuracy: 0.0298 - val_loss: 2856.1814 - val_accuracy: 0.0567\n",
            "Epoch 9/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2276.3665 - accuracy: 0.0193 - val_loss: 2376.7874 - val_accuracy: 0.0415\n",
            "Epoch 10/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 1898.0437 - accuracy: 0.0134 - val_loss: 1977.4308 - val_accuracy: 0.0179\n",
            "Epoch 11/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 1560.1816 - accuracy: 0.0073 - val_loss: 1648.5017 - val_accuracy: 0.0100\n",
            "Epoch 12/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 1313.6770 - accuracy: 0.0166 - val_loss: 1379.1926 - val_accuracy: 0.0113\n",
            "Epoch 13/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 1045.8468 - accuracy: 0.0259 - val_loss: 1067.2107 - val_accuracy: 0.0170\n",
            "Epoch 14/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 814.2770 - accuracy: 0.0327 - val_loss: 822.1376 - val_accuracy: 0.0192\n",
            "Epoch 15/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 626.1320 - accuracy: 0.0343 - val_loss: 645.8671 - val_accuracy: 0.0262\n",
            "Epoch 16/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 507.0272 - accuracy: 0.0571 - val_loss: 533.0496 - val_accuracy: 0.0332\n",
            "Epoch 17/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 416.9576 - accuracy: 0.0448 - val_loss: 438.1745 - val_accuracy: 0.0297\n",
            "Epoch 18/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 344.0955 - accuracy: 0.0401 - val_loss: 368.2575 - val_accuracy: 0.0192\n",
            "Epoch 19/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 294.9333 - accuracy: 0.0385 - val_loss: 320.2601 - val_accuracy: 0.0262\n",
            "Epoch 20/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 256.9940 - accuracy: 0.0443 - val_loss: 279.4677 - val_accuracy: 0.0122\n",
            "Epoch 21/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 210.8513 - accuracy: 0.0345 - val_loss: 217.1930 - val_accuracy: 0.0279\n",
            "Epoch 22/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 174.1314 - accuracy: 0.0426 - val_loss: 187.6147 - val_accuracy: 0.0179\n",
            "Epoch 23/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 149.1997 - accuracy: 0.0420 - val_loss: 161.0482 - val_accuracy: 0.0057\n",
            "Epoch 24/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 127.6647 - accuracy: 0.0466 - val_loss: 140.1378 - val_accuracy: 0.0192\n",
            "Epoch 25/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 112.7110 - accuracy: 0.0478 - val_loss: 124.3177 - val_accuracy: 0.0310\n",
            "Epoch 26/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 100.1901 - accuracy: 0.0535 - val_loss: 110.5753 - val_accuracy: 0.0162\n",
            "Epoch 27/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 88.8606 - accuracy: 0.0541 - val_loss: 97.8162 - val_accuracy: 0.0201\n",
            "Epoch 28/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 79.0659 - accuracy: 0.0485 - val_loss: 86.9586 - val_accuracy: 0.0074\n",
            "Epoch 29/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 70.6665 - accuracy: 0.0490 - val_loss: 78.3048 - val_accuracy: 0.0179\n",
            "Epoch 30/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 64.0250 - accuracy: 0.0570 - val_loss: 70.7893 - val_accuracy: 0.0166\n",
            "Epoch 31/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 58.0192 - accuracy: 0.0629 - val_loss: 64.1521 - val_accuracy: 0.0310\n",
            "Epoch 32/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 52.7131 - accuracy: 0.0699 - val_loss: 58.4921 - val_accuracy: 0.0170\n",
            "Epoch 33/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 47.9859 - accuracy: 0.0744 - val_loss: 53.1947 - val_accuracy: 0.0284\n",
            "Epoch 34/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 43.1874 - accuracy: 0.0745 - val_loss: 47.2986 - val_accuracy: 0.0292\n",
            "Epoch 35/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 38.7292 - accuracy: 0.0729 - val_loss: 42.7744 - val_accuracy: 0.0410\n",
            "Epoch 36/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 34.7956 - accuracy: 0.0793 - val_loss: 39.0279 - val_accuracy: 0.0223\n",
            "Epoch 37/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 31.3478 - accuracy: 0.0725 - val_loss: 35.4088 - val_accuracy: 0.0419\n",
            "Epoch 38/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 28.5085 - accuracy: 0.0727 - val_loss: 32.8635 - val_accuracy: 0.0358\n",
            "Epoch 39/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 25.9682 - accuracy: 0.0756 - val_loss: 30.1390 - val_accuracy: 0.0677\n",
            "Epoch 40/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 23.3913 - accuracy: 0.0907 - val_loss: 27.2029 - val_accuracy: 0.1139\n",
            "Epoch 41/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 21.1379 - accuracy: 0.1029 - val_loss: 25.1017 - val_accuracy: 0.1082\n",
            "Epoch 42/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 19.3473 - accuracy: 0.1049 - val_loss: 23.1265 - val_accuracy: 0.1104\n",
            "Epoch 43/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 17.8266 - accuracy: 0.1079 - val_loss: 21.3481 - val_accuracy: 0.0821\n",
            "Epoch 44/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 16.6108 - accuracy: 0.1040 - val_loss: 19.8701 - val_accuracy: 0.1244\n",
            "Epoch 45/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 15.5403 - accuracy: 0.1039 - val_loss: 18.6963 - val_accuracy: 0.0895\n",
            "Epoch 46/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 14.5406 - accuracy: 0.1020 - val_loss: 17.4561 - val_accuracy: 0.1174\n",
            "Epoch 47/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 13.6228 - accuracy: 0.1037 - val_loss: 16.2973 - val_accuracy: 0.1152\n",
            "Epoch 48/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 12.7717 - accuracy: 0.1040 - val_loss: 15.2681 - val_accuracy: 0.0773\n",
            "Epoch 49/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 11.9820 - accuracy: 0.1030 - val_loss: 14.4914 - val_accuracy: 0.0690\n",
            "Epoch 50/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 11.2591 - accuracy: 0.1031 - val_loss: 13.3796 - val_accuracy: 0.1192\n",
            "Epoch 51/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 10.6056 - accuracy: 0.1050 - val_loss: 12.6627 - val_accuracy: 0.0973\n",
            "Epoch 52/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 9.9999 - accuracy: 0.1074 - val_loss: 12.0957 - val_accuracy: 0.0528\n",
            "Epoch 53/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 9.4339 - accuracy: 0.1078 - val_loss: 11.2586 - val_accuracy: 0.0960\n",
            "Epoch 54/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 8.9074 - accuracy: 0.1108 - val_loss: 10.5997 - val_accuracy: 0.1056\n",
            "Epoch 55/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 8.4240 - accuracy: 0.1118 - val_loss: 9.9760 - val_accuracy: 0.1122\n",
            "Epoch 56/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 7.9817 - accuracy: 0.1142 - val_loss: 9.5560 - val_accuracy: 0.0781\n",
            "Epoch 57/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 7.6215 - accuracy: 0.1202 - val_loss: 9.1637 - val_accuracy: 0.0655\n",
            "Epoch 58/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 7.2987 - accuracy: 0.1277 - val_loss: 8.6937 - val_accuracy: 0.0938\n",
            "Epoch 59/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 6.9852 - accuracy: 0.1320 - val_loss: 8.3869 - val_accuracy: 0.0594\n",
            "Epoch 60/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 6.6887 - accuracy: 0.1427 - val_loss: 7.9878 - val_accuracy: 0.0930\n",
            "Epoch 61/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 6.4097 - accuracy: 0.1425 - val_loss: 7.7568 - val_accuracy: 0.0611\n",
            "Epoch 62/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 6.1607 - accuracy: 0.1407 - val_loss: 7.4029 - val_accuracy: 0.0812\n",
            "Epoch 63/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 5.9309 - accuracy: 0.1409 - val_loss: 7.0384 - val_accuracy: 0.0816\n",
            "Epoch 64/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 5.7092 - accuracy: 0.1404 - val_loss: 6.7685 - val_accuracy: 0.1026\n",
            "Epoch 65/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 5.5009 - accuracy: 0.1405 - val_loss: 6.5814 - val_accuracy: 0.1017\n",
            "Epoch 66/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 5.3075 - accuracy: 0.1397 - val_loss: 6.2536 - val_accuracy: 0.1087\n",
            "Epoch 67/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 5.1458 - accuracy: 0.1371 - val_loss: 6.1582 - val_accuracy: 0.0567\n",
            "Epoch 68/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.9703 - accuracy: 0.1377 - val_loss: 5.8584 - val_accuracy: 0.1008\n",
            "Epoch 69/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.8211 - accuracy: 0.1375 - val_loss: 5.5906 - val_accuracy: 0.1218\n",
            "Epoch 70/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.6782 - accuracy: 0.1369 - val_loss: 5.4237 - val_accuracy: 0.1113\n",
            "Epoch 71/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.5550 - accuracy: 0.1373 - val_loss: 5.3526 - val_accuracy: 0.0838\n",
            "Epoch 72/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.4164 - accuracy: 0.1373 - val_loss: 5.1049 - val_accuracy: 0.1078\n",
            "Epoch 73/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.3062 - accuracy: 0.1380 - val_loss: 4.9679 - val_accuracy: 0.0890\n",
            "Epoch 74/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.2047 - accuracy: 0.1340 - val_loss: 4.8266 - val_accuracy: 0.1039\n",
            "Epoch 75/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.0920 - accuracy: 0.1371 - val_loss: 4.7028 - val_accuracy: 0.1139\n",
            "Epoch 76/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 4.0045 - accuracy: 0.1375 - val_loss: 4.5483 - val_accuracy: 0.0973\n",
            "Epoch 77/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.9207 - accuracy: 0.1381 - val_loss: 4.4370 - val_accuracy: 0.0794\n",
            "Epoch 78/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.8385 - accuracy: 0.1355 - val_loss: 4.2723 - val_accuracy: 0.1213\n",
            "Epoch 79/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.7567 - accuracy: 0.1356 - val_loss: 4.3192 - val_accuracy: 0.0790\n",
            "Epoch 80/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.6984 - accuracy: 0.1319 - val_loss: 4.0999 - val_accuracy: 0.0973\n",
            "Epoch 81/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.6339 - accuracy: 0.1337 - val_loss: 4.0095 - val_accuracy: 0.1135\n",
            "Epoch 82/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.5670 - accuracy: 0.1347 - val_loss: 3.9267 - val_accuracy: 0.1039\n",
            "Epoch 83/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.5044 - accuracy: 0.1371 - val_loss: 3.9623 - val_accuracy: 0.0663\n",
            "Epoch 84/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.4645 - accuracy: 0.1300 - val_loss: 3.7641 - val_accuracy: 0.1170\n",
            "Epoch 85/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.4174 - accuracy: 0.1327 - val_loss: 3.8310 - val_accuracy: 0.0668\n",
            "Epoch 86/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.3754 - accuracy: 0.1324 - val_loss: 3.6771 - val_accuracy: 0.0904\n",
            "Epoch 87/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.3360 - accuracy: 0.1317 - val_loss: 3.6523 - val_accuracy: 0.0829\n",
            "Epoch 88/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.3067 - accuracy: 0.1309 - val_loss: 3.5760 - val_accuracy: 0.1013\n",
            "Epoch 89/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.2674 - accuracy: 0.1328 - val_loss: 3.5446 - val_accuracy: 0.0812\n",
            "Epoch 90/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.2435 - accuracy: 0.1316 - val_loss: 3.5180 - val_accuracy: 0.0768\n",
            "Epoch 91/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.2024 - accuracy: 0.1364 - val_loss: 3.7200 - val_accuracy: 0.0432\n",
            "Epoch 92/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.1948 - accuracy: 0.1301 - val_loss: 3.4223 - val_accuracy: 0.0925\n",
            "Epoch 93/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.1601 - accuracy: 0.1365 - val_loss: 3.3971 - val_accuracy: 0.0869\n",
            "Epoch 94/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.1379 - accuracy: 0.1331 - val_loss: 3.4090 - val_accuracy: 0.0917\n",
            "Epoch 95/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.1156 - accuracy: 0.1368 - val_loss: 3.3890 - val_accuracy: 0.0847\n",
            "Epoch 96/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.0898 - accuracy: 0.1351 - val_loss: 3.3540 - val_accuracy: 0.0912\n",
            "Epoch 97/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.0761 - accuracy: 0.1364 - val_loss: 3.3161 - val_accuracy: 0.0821\n",
            "Epoch 98/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.0682 - accuracy: 0.1347 - val_loss: 3.3470 - val_accuracy: 0.1069\n",
            "Epoch 99/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.0403 - accuracy: 0.1381 - val_loss: 3.2632 - val_accuracy: 0.0650\n",
            "Epoch 100/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.0332 - accuracy: 0.1377 - val_loss: 3.2227 - val_accuracy: 0.0899\n",
            "Epoch 101/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 3.0210 - accuracy: 0.1367 - val_loss: 3.2633 - val_accuracy: 0.0764\n",
            "Epoch 102/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 3.0115 - accuracy: 0.1368 - val_loss: 3.1806 - val_accuracy: 0.0899\n",
            "Epoch 103/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9955 - accuracy: 0.1389 - val_loss: 3.1868 - val_accuracy: 0.0882\n",
            "Epoch 104/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9875 - accuracy: 0.1385 - val_loss: 3.2450 - val_accuracy: 0.0890\n",
            "Epoch 105/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.9800 - accuracy: 0.1374 - val_loss: 3.1387 - val_accuracy: 0.1096\n",
            "Epoch 106/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9750 - accuracy: 0.1384 - val_loss: 3.1469 - val_accuracy: 0.0960\n",
            "Epoch 107/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.9594 - accuracy: 0.1404 - val_loss: 3.1622 - val_accuracy: 0.0711\n",
            "Epoch 108/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9519 - accuracy: 0.1414 - val_loss: 3.1455 - val_accuracy: 0.1100\n",
            "Epoch 109/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9532 - accuracy: 0.1381 - val_loss: 3.1225 - val_accuracy: 0.0794\n",
            "Epoch 110/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.9438 - accuracy: 0.1391 - val_loss: 3.2488 - val_accuracy: 0.0716\n",
            "Epoch 111/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9360 - accuracy: 0.1395 - val_loss: 3.1012 - val_accuracy: 0.0681\n",
            "Epoch 112/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.9250 - accuracy: 0.1417 - val_loss: 3.1206 - val_accuracy: 0.0834\n",
            "Epoch 113/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9270 - accuracy: 0.1379 - val_loss: 3.1798 - val_accuracy: 0.0816\n",
            "Epoch 114/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9119 - accuracy: 0.1417 - val_loss: 3.0992 - val_accuracy: 0.1139\n",
            "Epoch 115/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.9057 - accuracy: 0.1423 - val_loss: 3.0605 - val_accuracy: 0.0812\n",
            "Epoch 116/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.9028 - accuracy: 0.1409 - val_loss: 3.0748 - val_accuracy: 0.0864\n",
            "Epoch 117/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8960 - accuracy: 0.1415 - val_loss: 3.1705 - val_accuracy: 0.0851\n",
            "Epoch 118/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8917 - accuracy: 0.1425 - val_loss: 3.1985 - val_accuracy: 0.0808\n",
            "Epoch 119/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8875 - accuracy: 0.1412 - val_loss: 3.0879 - val_accuracy: 0.0777\n",
            "Epoch 120/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8828 - accuracy: 0.1432 - val_loss: 3.0476 - val_accuracy: 0.0790\n",
            "Epoch 121/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8762 - accuracy: 0.1444 - val_loss: 3.0364 - val_accuracy: 0.0759\n",
            "Epoch 122/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8754 - accuracy: 0.1432 - val_loss: 3.0538 - val_accuracy: 0.1131\n",
            "Epoch 123/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8603 - accuracy: 0.1468 - val_loss: 3.0118 - val_accuracy: 0.0973\n",
            "Epoch 124/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8591 - accuracy: 0.1459 - val_loss: 3.0303 - val_accuracy: 0.1104\n",
            "Epoch 125/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8539 - accuracy: 0.1459 - val_loss: 3.0461 - val_accuracy: 0.1135\n",
            "Epoch 126/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.8465 - accuracy: 0.1465 - val_loss: 3.0131 - val_accuracy: 0.0751\n",
            "Epoch 127/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.8438 - accuracy: 0.1470 - val_loss: 3.0362 - val_accuracy: 0.0681\n",
            "Epoch 128/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.8387 - accuracy: 0.1480 - val_loss: 2.9912 - val_accuracy: 0.1030\n",
            "Epoch 129/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.8414 - accuracy: 0.1469 - val_loss: 2.9908 - val_accuracy: 0.1100\n",
            "Epoch 130/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.8277 - accuracy: 0.1500 - val_loss: 2.9673 - val_accuracy: 0.1157\n",
            "Epoch 131/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.8338 - accuracy: 0.1476 - val_loss: 3.0082 - val_accuracy: 0.1061\n",
            "Epoch 132/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8230 - accuracy: 0.1516 - val_loss: 2.9521 - val_accuracy: 0.1122\n",
            "Epoch 133/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8151 - accuracy: 0.1512 - val_loss: 3.0537 - val_accuracy: 0.0952\n",
            "Epoch 134/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8118 - accuracy: 0.1502 - val_loss: 3.0129 - val_accuracy: 0.1008\n",
            "Epoch 135/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8113 - accuracy: 0.1522 - val_loss: 2.9726 - val_accuracy: 0.1179\n",
            "Epoch 136/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.8017 - accuracy: 0.1529 - val_loss: 2.9626 - val_accuracy: 0.1048\n",
            "Epoch 137/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7964 - accuracy: 0.1519 - val_loss: 2.9781 - val_accuracy: 0.1187\n",
            "Epoch 138/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7955 - accuracy: 0.1575 - val_loss: 2.9492 - val_accuracy: 0.1240\n",
            "Epoch 139/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7908 - accuracy: 0.1512 - val_loss: 2.9814 - val_accuracy: 0.1126\n",
            "Epoch 140/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7923 - accuracy: 0.1542 - val_loss: 2.9365 - val_accuracy: 0.1152\n",
            "Epoch 141/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7851 - accuracy: 0.1537 - val_loss: 2.9040 - val_accuracy: 0.1536\n",
            "Epoch 142/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7740 - accuracy: 0.1574 - val_loss: 2.9484 - val_accuracy: 0.0777\n",
            "Epoch 143/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7720 - accuracy: 0.1577 - val_loss: 3.0194 - val_accuracy: 0.1052\n",
            "Epoch 144/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7695 - accuracy: 0.1537 - val_loss: 2.9265 - val_accuracy: 0.1266\n",
            "Epoch 145/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7675 - accuracy: 0.1569 - val_loss: 2.8997 - val_accuracy: 0.1397\n",
            "Epoch 146/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7646 - accuracy: 0.1561 - val_loss: 2.9208 - val_accuracy: 0.1288\n",
            "Epoch 147/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7682 - accuracy: 0.1540 - val_loss: 2.8836 - val_accuracy: 0.1344\n",
            "Epoch 148/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7550 - accuracy: 0.1597 - val_loss: 2.9225 - val_accuracy: 0.1122\n",
            "Epoch 149/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7493 - accuracy: 0.1605 - val_loss: 3.0572 - val_accuracy: 0.0882\n",
            "Epoch 150/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7440 - accuracy: 0.1611 - val_loss: 2.9168 - val_accuracy: 0.1174\n",
            "Epoch 151/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.7440 - accuracy: 0.1598 - val_loss: 2.8684 - val_accuracy: 0.1349\n",
            "Epoch 152/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7404 - accuracy: 0.1609 - val_loss: 2.8923 - val_accuracy: 0.1292\n",
            "Epoch 153/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7343 - accuracy: 0.1612 - val_loss: 2.9201 - val_accuracy: 0.0934\n",
            "Epoch 154/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7363 - accuracy: 0.1591 - val_loss: 2.8930 - val_accuracy: 0.1301\n",
            "Epoch 155/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7300 - accuracy: 0.1622 - val_loss: 2.8855 - val_accuracy: 0.1388\n",
            "Epoch 156/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7243 - accuracy: 0.1649 - val_loss: 2.8797 - val_accuracy: 0.1183\n",
            "Epoch 157/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7204 - accuracy: 0.1621 - val_loss: 2.9198 - val_accuracy: 0.1174\n",
            "Epoch 158/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7282 - accuracy: 0.1571 - val_loss: 2.9221 - val_accuracy: 0.1200\n",
            "Epoch 159/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7198 - accuracy: 0.1618 - val_loss: 2.9178 - val_accuracy: 0.1235\n",
            "Epoch 160/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7149 - accuracy: 0.1625 - val_loss: 2.8664 - val_accuracy: 0.1244\n",
            "Epoch 161/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7140 - accuracy: 0.1639 - val_loss: 2.8809 - val_accuracy: 0.1301\n",
            "Epoch 162/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7053 - accuracy: 0.1630 - val_loss: 2.8635 - val_accuracy: 0.1248\n",
            "Epoch 163/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7035 - accuracy: 0.1633 - val_loss: 2.8451 - val_accuracy: 0.1227\n",
            "Epoch 164/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.7021 - accuracy: 0.1618 - val_loss: 2.8511 - val_accuracy: 0.1357\n",
            "Epoch 165/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6985 - accuracy: 0.1657 - val_loss: 2.8305 - val_accuracy: 0.1405\n",
            "Epoch 166/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.7002 - accuracy: 0.1624 - val_loss: 2.8314 - val_accuracy: 0.1440\n",
            "Epoch 167/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6888 - accuracy: 0.1678 - val_loss: 2.8715 - val_accuracy: 0.1231\n",
            "Epoch 168/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6826 - accuracy: 0.1693 - val_loss: 2.8154 - val_accuracy: 0.1471\n",
            "Epoch 169/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6915 - accuracy: 0.1652 - val_loss: 2.8719 - val_accuracy: 0.1196\n",
            "Epoch 170/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6864 - accuracy: 0.1648 - val_loss: 2.8555 - val_accuracy: 0.1222\n",
            "Epoch 171/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6856 - accuracy: 0.1634 - val_loss: 2.9015 - val_accuracy: 0.0917\n",
            "Epoch 172/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6877 - accuracy: 0.1625 - val_loss: 3.0667 - val_accuracy: 0.0611\n",
            "Epoch 173/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6840 - accuracy: 0.1641 - val_loss: 2.8208 - val_accuracy: 0.1419\n",
            "Epoch 174/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6700 - accuracy: 0.1671 - val_loss: 2.8697 - val_accuracy: 0.1292\n",
            "Epoch 175/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6801 - accuracy: 0.1639 - val_loss: 2.8490 - val_accuracy: 0.1283\n",
            "Epoch 176/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6660 - accuracy: 0.1677 - val_loss: 2.8191 - val_accuracy: 0.1292\n",
            "Epoch 177/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6674 - accuracy: 0.1674 - val_loss: 2.8199 - val_accuracy: 0.1205\n",
            "Epoch 178/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6661 - accuracy: 0.1658 - val_loss: 2.8426 - val_accuracy: 0.1209\n",
            "Epoch 179/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6607 - accuracy: 0.1675 - val_loss: 2.8473 - val_accuracy: 0.1144\n",
            "Epoch 180/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6589 - accuracy: 0.1677 - val_loss: 2.8401 - val_accuracy: 0.1279\n",
            "Epoch 181/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6590 - accuracy: 0.1674 - val_loss: 2.8220 - val_accuracy: 0.1275\n",
            "Epoch 182/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6498 - accuracy: 0.1663 - val_loss: 2.8025 - val_accuracy: 0.1301\n",
            "Epoch 183/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6602 - accuracy: 0.1661 - val_loss: 2.9657 - val_accuracy: 0.0685\n",
            "Epoch 184/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.6576 - accuracy: 0.1656 - val_loss: 2.8608 - val_accuracy: 0.1100\n",
            "Epoch 185/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6527 - accuracy: 0.1656 - val_loss: 2.8213 - val_accuracy: 0.1353\n",
            "Epoch 186/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6517 - accuracy: 0.1665 - val_loss: 2.7860 - val_accuracy: 0.1336\n",
            "Epoch 187/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6481 - accuracy: 0.1644 - val_loss: 2.9090 - val_accuracy: 0.0978\n",
            "Epoch 188/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6483 - accuracy: 0.1685 - val_loss: 2.8403 - val_accuracy: 0.1139\n",
            "Epoch 189/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6422 - accuracy: 0.1669 - val_loss: 2.8522 - val_accuracy: 0.1144\n",
            "Epoch 190/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6409 - accuracy: 0.1656 - val_loss: 2.7856 - val_accuracy: 0.1432\n",
            "Epoch 191/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6381 - accuracy: 0.1684 - val_loss: 2.8096 - val_accuracy: 0.1266\n",
            "Epoch 192/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6435 - accuracy: 0.1661 - val_loss: 2.7806 - val_accuracy: 0.1349\n",
            "Epoch 193/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6392 - accuracy: 0.1665 - val_loss: 2.7691 - val_accuracy: 0.1405\n",
            "Epoch 194/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6338 - accuracy: 0.1681 - val_loss: 2.7806 - val_accuracy: 0.1323\n",
            "Epoch 195/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6338 - accuracy: 0.1656 - val_loss: 2.7761 - val_accuracy: 0.1414\n",
            "Epoch 196/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6259 - accuracy: 0.1707 - val_loss: 2.7785 - val_accuracy: 0.1427\n",
            "Epoch 197/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6416 - accuracy: 0.1634 - val_loss: 2.7753 - val_accuracy: 0.1458\n",
            "Epoch 198/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.6310 - accuracy: 0.1682 - val_loss: 2.8179 - val_accuracy: 0.1336\n",
            "Epoch 199/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.6296 - accuracy: 0.1657 - val_loss: 2.7546 - val_accuracy: 0.1467\n",
            "Epoch 200/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6242 - accuracy: 0.1701 - val_loss: 2.7845 - val_accuracy: 0.1270\n",
            "Epoch 201/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6277 - accuracy: 0.1657 - val_loss: 2.7983 - val_accuracy: 0.1283\n",
            "Epoch 202/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6240 - accuracy: 0.1671 - val_loss: 2.8261 - val_accuracy: 0.1065\n",
            "Epoch 203/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6179 - accuracy: 0.1683 - val_loss: 2.7694 - val_accuracy: 0.1323\n",
            "Epoch 204/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6241 - accuracy: 0.1667 - val_loss: 2.7651 - val_accuracy: 0.1366\n",
            "Epoch 205/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6184 - accuracy: 0.1663 - val_loss: 2.8768 - val_accuracy: 0.0956\n",
            "Epoch 206/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6186 - accuracy: 0.1673 - val_loss: 2.7549 - val_accuracy: 0.1388\n",
            "Epoch 207/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6127 - accuracy: 0.1694 - val_loss: 2.7604 - val_accuracy: 0.1283\n",
            "Epoch 208/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6108 - accuracy: 0.1674 - val_loss: 2.7467 - val_accuracy: 0.1405\n",
            "Epoch 209/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.6130 - accuracy: 0.1675 - val_loss: 2.8055 - val_accuracy: 0.1179\n",
            "Epoch 210/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.6096 - accuracy: 0.1656 - val_loss: 2.7715 - val_accuracy: 0.1405\n",
            "Epoch 211/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.6057 - accuracy: 0.1697 - val_loss: 2.9882 - val_accuracy: 0.0786\n",
            "Epoch 212/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.6097 - accuracy: 0.1673 - val_loss: 2.7589 - val_accuracy: 0.1371\n",
            "Epoch 213/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.6033 - accuracy: 0.1692 - val_loss: 2.7289 - val_accuracy: 0.1432\n",
            "Epoch 214/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6053 - accuracy: 0.1690 - val_loss: 2.8253 - val_accuracy: 0.1187\n",
            "Epoch 215/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.6001 - accuracy: 0.1677 - val_loss: 2.7106 - val_accuracy: 0.1475\n",
            "Epoch 216/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.6092 - accuracy: 0.1667 - val_loss: 2.7513 - val_accuracy: 0.1257\n",
            "Epoch 217/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5983 - accuracy: 0.1679 - val_loss: 2.7419 - val_accuracy: 0.1279\n",
            "Epoch 218/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6024 - accuracy: 0.1676 - val_loss: 2.7135 - val_accuracy: 0.1423\n",
            "Epoch 219/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6047 - accuracy: 0.1676 - val_loss: 2.7282 - val_accuracy: 0.1475\n",
            "Epoch 220/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.6014 - accuracy: 0.1698 - val_loss: 2.7481 - val_accuracy: 0.1340\n",
            "Epoch 221/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5938 - accuracy: 0.1682 - val_loss: 2.7756 - val_accuracy: 0.1401\n",
            "Epoch 222/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5962 - accuracy: 0.1664 - val_loss: 2.7382 - val_accuracy: 0.1305\n",
            "Epoch 223/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5931 - accuracy: 0.1721 - val_loss: 2.8356 - val_accuracy: 0.1065\n",
            "Epoch 224/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5933 - accuracy: 0.1685 - val_loss: 2.7369 - val_accuracy: 0.1397\n",
            "Epoch 225/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5896 - accuracy: 0.1702 - val_loss: 2.7491 - val_accuracy: 0.1283\n",
            "Epoch 226/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5928 - accuracy: 0.1673 - val_loss: 2.7324 - val_accuracy: 0.1580\n",
            "Epoch 227/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5957 - accuracy: 0.1690 - val_loss: 2.7169 - val_accuracy: 0.1502\n",
            "Epoch 228/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5959 - accuracy: 0.1665 - val_loss: 2.7124 - val_accuracy: 0.1379\n",
            "Epoch 229/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5892 - accuracy: 0.1688 - val_loss: 2.7787 - val_accuracy: 0.1384\n",
            "Epoch 230/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5830 - accuracy: 0.1712 - val_loss: 2.7170 - val_accuracy: 0.1384\n",
            "Epoch 231/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5888 - accuracy: 0.1693 - val_loss: 2.7188 - val_accuracy: 0.1349\n",
            "Epoch 232/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5861 - accuracy: 0.1667 - val_loss: 2.7573 - val_accuracy: 0.1357\n",
            "Epoch 233/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5806 - accuracy: 0.1696 - val_loss: 2.7485 - val_accuracy: 0.1401\n",
            "Epoch 234/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5832 - accuracy: 0.1684 - val_loss: 2.7538 - val_accuracy: 0.1309\n",
            "Epoch 235/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5807 - accuracy: 0.1682 - val_loss: 2.7052 - val_accuracy: 0.1401\n",
            "Epoch 236/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5822 - accuracy: 0.1701 - val_loss: 2.7098 - val_accuracy: 0.1497\n",
            "Epoch 237/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5816 - accuracy: 0.1699 - val_loss: 2.7436 - val_accuracy: 0.1357\n",
            "Epoch 238/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5785 - accuracy: 0.1691 - val_loss: 2.6931 - val_accuracy: 0.1506\n",
            "Epoch 239/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5801 - accuracy: 0.1708 - val_loss: 2.7146 - val_accuracy: 0.1392\n",
            "Epoch 240/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5690 - accuracy: 0.1724 - val_loss: 2.7991 - val_accuracy: 0.1117\n",
            "Epoch 241/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5758 - accuracy: 0.1702 - val_loss: 2.6997 - val_accuracy: 0.1471\n",
            "Epoch 242/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5737 - accuracy: 0.1706 - val_loss: 2.7729 - val_accuracy: 0.1135\n",
            "Epoch 243/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5791 - accuracy: 0.1693 - val_loss: 2.7603 - val_accuracy: 0.1187\n",
            "Epoch 244/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5696 - accuracy: 0.1727 - val_loss: 2.7077 - val_accuracy: 0.1340\n",
            "Epoch 245/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5778 - accuracy: 0.1717 - val_loss: 2.7110 - val_accuracy: 0.1371\n",
            "Epoch 246/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5791 - accuracy: 0.1668 - val_loss: 2.7136 - val_accuracy: 0.1427\n",
            "Epoch 247/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5651 - accuracy: 0.1711 - val_loss: 2.7286 - val_accuracy: 0.1344\n",
            "Epoch 248/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5699 - accuracy: 0.1721 - val_loss: 2.6974 - val_accuracy: 0.1462\n",
            "Epoch 249/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5687 - accuracy: 0.1706 - val_loss: 2.6944 - val_accuracy: 0.1462\n",
            "Epoch 250/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5642 - accuracy: 0.1728 - val_loss: 2.6830 - val_accuracy: 0.1523\n",
            "Epoch 251/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5699 - accuracy: 0.1724 - val_loss: 2.8455 - val_accuracy: 0.1052\n",
            "Epoch 252/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5740 - accuracy: 0.1690 - val_loss: 2.8586 - val_accuracy: 0.1000\n",
            "Epoch 253/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5685 - accuracy: 0.1686 - val_loss: 2.7221 - val_accuracy: 0.1331\n",
            "Epoch 254/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5668 - accuracy: 0.1717 - val_loss: 2.6885 - val_accuracy: 0.1502\n",
            "Epoch 255/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5672 - accuracy: 0.1708 - val_loss: 2.6772 - val_accuracy: 0.1523\n",
            "Epoch 256/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5586 - accuracy: 0.1749 - val_loss: 2.7207 - val_accuracy: 0.1475\n",
            "Epoch 257/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5643 - accuracy: 0.1744 - val_loss: 2.7632 - val_accuracy: 0.1122\n",
            "Epoch 258/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5579 - accuracy: 0.1721 - val_loss: 2.6855 - val_accuracy: 0.1480\n",
            "Epoch 259/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5641 - accuracy: 0.1709 - val_loss: 2.7116 - val_accuracy: 0.1357\n",
            "Epoch 260/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5593 - accuracy: 0.1729 - val_loss: 2.6851 - val_accuracy: 0.1497\n",
            "Epoch 261/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5589 - accuracy: 0.1741 - val_loss: 2.6966 - val_accuracy: 0.1366\n",
            "Epoch 262/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5572 - accuracy: 0.1717 - val_loss: 2.7677 - val_accuracy: 0.1131\n",
            "Epoch 263/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5588 - accuracy: 0.1727 - val_loss: 2.6735 - val_accuracy: 0.1410\n",
            "Epoch 264/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.5526 - accuracy: 0.1744 - val_loss: 2.7138 - val_accuracy: 0.1261\n",
            "Epoch 265/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.5571 - accuracy: 0.1734 - val_loss: 2.6986 - val_accuracy: 0.1419\n",
            "Epoch 266/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5540 - accuracy: 0.1731 - val_loss: 2.7192 - val_accuracy: 0.1244\n",
            "Epoch 267/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5480 - accuracy: 0.1771 - val_loss: 2.7215 - val_accuracy: 0.1240\n",
            "Epoch 268/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5519 - accuracy: 0.1750 - val_loss: 2.6900 - val_accuracy: 0.1576\n",
            "Epoch 269/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5594 - accuracy: 0.1729 - val_loss: 2.7265 - val_accuracy: 0.1327\n",
            "Epoch 270/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5506 - accuracy: 0.1746 - val_loss: 2.7103 - val_accuracy: 0.1292\n",
            "Epoch 271/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5530 - accuracy: 0.1734 - val_loss: 2.7094 - val_accuracy: 0.1288\n",
            "Epoch 272/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5507 - accuracy: 0.1711 - val_loss: 2.6975 - val_accuracy: 0.1410\n",
            "Epoch 273/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5500 - accuracy: 0.1747 - val_loss: 2.6821 - val_accuracy: 0.1362\n",
            "Epoch 274/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5544 - accuracy: 0.1745 - val_loss: 2.7430 - val_accuracy: 0.1187\n",
            "Epoch 275/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5478 - accuracy: 0.1746 - val_loss: 2.6834 - val_accuracy: 0.1392\n",
            "Epoch 276/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5484 - accuracy: 0.1744 - val_loss: 2.7016 - val_accuracy: 0.1493\n",
            "Epoch 277/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5461 - accuracy: 0.1758 - val_loss: 2.7280 - val_accuracy: 0.1218\n",
            "Epoch 278/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5455 - accuracy: 0.1755 - val_loss: 2.6953 - val_accuracy: 0.1301\n",
            "Epoch 279/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5458 - accuracy: 0.1777 - val_loss: 2.6780 - val_accuracy: 0.1593\n",
            "Epoch 280/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5445 - accuracy: 0.1754 - val_loss: 2.7029 - val_accuracy: 0.1327\n",
            "Epoch 281/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5426 - accuracy: 0.1734 - val_loss: 2.7373 - val_accuracy: 0.1344\n",
            "Epoch 282/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5393 - accuracy: 0.1743 - val_loss: 2.7383 - val_accuracy: 0.1266\n",
            "Epoch 283/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5484 - accuracy: 0.1728 - val_loss: 2.6890 - val_accuracy: 0.1362\n",
            "Epoch 284/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5400 - accuracy: 0.1766 - val_loss: 2.6928 - val_accuracy: 0.1650\n",
            "Epoch 285/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5398 - accuracy: 0.1759 - val_loss: 2.7294 - val_accuracy: 0.1309\n",
            "Epoch 286/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5421 - accuracy: 0.1761 - val_loss: 2.6903 - val_accuracy: 0.1305\n",
            "Epoch 287/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5409 - accuracy: 0.1768 - val_loss: 2.6606 - val_accuracy: 0.1454\n",
            "Epoch 288/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5409 - accuracy: 0.1746 - val_loss: 2.8205 - val_accuracy: 0.0812\n",
            "Epoch 289/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5386 - accuracy: 0.1762 - val_loss: 2.7204 - val_accuracy: 0.1331\n",
            "Epoch 290/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5307 - accuracy: 0.1788 - val_loss: 2.6799 - val_accuracy: 0.1397\n",
            "Epoch 291/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5370 - accuracy: 0.1768 - val_loss: 2.6568 - val_accuracy: 0.1519\n",
            "Epoch 292/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5362 - accuracy: 0.1777 - val_loss: 2.7068 - val_accuracy: 0.1510\n",
            "Epoch 293/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5362 - accuracy: 0.1741 - val_loss: 2.6988 - val_accuracy: 0.1567\n",
            "Epoch 294/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5313 - accuracy: 0.1794 - val_loss: 2.6975 - val_accuracy: 0.1314\n",
            "Epoch 295/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5351 - accuracy: 0.1755 - val_loss: 2.6730 - val_accuracy: 0.1558\n",
            "Epoch 296/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5309 - accuracy: 0.1776 - val_loss: 2.6762 - val_accuracy: 0.1379\n",
            "Epoch 297/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5335 - accuracy: 0.1781 - val_loss: 2.6983 - val_accuracy: 0.1336\n",
            "Epoch 298/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5315 - accuracy: 0.1789 - val_loss: 2.6698 - val_accuracy: 0.1410\n",
            "Epoch 299/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5293 - accuracy: 0.1777 - val_loss: 2.6714 - val_accuracy: 0.1405\n",
            "Epoch 300/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5293 - accuracy: 0.1754 - val_loss: 2.6820 - val_accuracy: 0.1327\n",
            "Epoch 301/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5295 - accuracy: 0.1790 - val_loss: 2.6976 - val_accuracy: 0.1440\n",
            "Epoch 302/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5257 - accuracy: 0.1788 - val_loss: 2.6878 - val_accuracy: 0.1261\n",
            "Epoch 303/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5268 - accuracy: 0.1805 - val_loss: 2.6953 - val_accuracy: 0.1571\n",
            "Epoch 304/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5247 - accuracy: 0.1814 - val_loss: 2.6588 - val_accuracy: 0.1462\n",
            "Epoch 305/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5432 - accuracy: 0.1747 - val_loss: 2.6591 - val_accuracy: 0.1558\n",
            "Epoch 306/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5217 - accuracy: 0.1794 - val_loss: 2.7060 - val_accuracy: 0.1379\n",
            "Epoch 307/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5235 - accuracy: 0.1786 - val_loss: 2.7208 - val_accuracy: 0.1436\n",
            "Epoch 308/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5210 - accuracy: 0.1790 - val_loss: 2.6542 - val_accuracy: 0.1506\n",
            "Epoch 309/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5231 - accuracy: 0.1808 - val_loss: 2.7025 - val_accuracy: 0.1336\n",
            "Epoch 310/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5266 - accuracy: 0.1763 - val_loss: 2.6604 - val_accuracy: 0.1440\n",
            "Epoch 311/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5226 - accuracy: 0.1789 - val_loss: 2.7173 - val_accuracy: 0.1314\n",
            "Epoch 312/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5210 - accuracy: 0.1797 - val_loss: 2.7250 - val_accuracy: 0.1292\n",
            "Epoch 313/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5147 - accuracy: 0.1776 - val_loss: 2.6652 - val_accuracy: 0.1388\n",
            "Epoch 314/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5300 - accuracy: 0.1784 - val_loss: 2.6984 - val_accuracy: 0.1484\n",
            "Epoch 315/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5236 - accuracy: 0.1789 - val_loss: 2.6710 - val_accuracy: 0.1340\n",
            "Epoch 316/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5203 - accuracy: 0.1800 - val_loss: 2.6513 - val_accuracy: 0.1397\n",
            "Epoch 317/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5133 - accuracy: 0.1819 - val_loss: 2.6906 - val_accuracy: 0.1270\n",
            "Epoch 318/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5146 - accuracy: 0.1807 - val_loss: 2.6908 - val_accuracy: 0.1261\n",
            "Epoch 319/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5188 - accuracy: 0.1764 - val_loss: 2.6746 - val_accuracy: 0.1419\n",
            "Epoch 320/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.5157 - accuracy: 0.1823 - val_loss: 2.6512 - val_accuracy: 0.1454\n",
            "Epoch 321/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5164 - accuracy: 0.1795 - val_loss: 2.7039 - val_accuracy: 0.1253\n",
            "Epoch 322/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5169 - accuracy: 0.1795 - val_loss: 2.6907 - val_accuracy: 0.1357\n",
            "Epoch 323/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5175 - accuracy: 0.1786 - val_loss: 2.6748 - val_accuracy: 0.1484\n",
            "Epoch 324/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5152 - accuracy: 0.1809 - val_loss: 2.6433 - val_accuracy: 0.1536\n",
            "Epoch 325/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5135 - accuracy: 0.1834 - val_loss: 2.7018 - val_accuracy: 0.1296\n",
            "Epoch 326/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5089 - accuracy: 0.1822 - val_loss: 2.7042 - val_accuracy: 0.1419\n",
            "Epoch 327/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5124 - accuracy: 0.1793 - val_loss: 2.6683 - val_accuracy: 0.1375\n",
            "Epoch 328/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.5115 - accuracy: 0.1822 - val_loss: 2.6524 - val_accuracy: 0.1654\n",
            "Epoch 329/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.5058 - accuracy: 0.1820 - val_loss: 2.6500 - val_accuracy: 0.1580\n",
            "Epoch 330/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5121 - accuracy: 0.1794 - val_loss: 2.6794 - val_accuracy: 0.1523\n",
            "Epoch 331/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5124 - accuracy: 0.1819 - val_loss: 2.6906 - val_accuracy: 0.1475\n",
            "Epoch 332/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.5091 - accuracy: 0.1843 - val_loss: 2.6747 - val_accuracy: 0.1445\n",
            "Epoch 333/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5075 - accuracy: 0.1833 - val_loss: 2.7285 - val_accuracy: 0.1266\n",
            "Epoch 334/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5069 - accuracy: 0.1843 - val_loss: 2.6808 - val_accuracy: 0.1309\n",
            "Epoch 335/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5101 - accuracy: 0.1808 - val_loss: 2.7026 - val_accuracy: 0.1480\n",
            "Epoch 336/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5087 - accuracy: 0.1824 - val_loss: 2.6731 - val_accuracy: 0.1301\n",
            "Epoch 337/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5069 - accuracy: 0.1828 - val_loss: 2.6639 - val_accuracy: 0.1541\n",
            "Epoch 338/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5035 - accuracy: 0.1858 - val_loss: 2.6731 - val_accuracy: 0.1309\n",
            "Epoch 339/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5075 - accuracy: 0.1810 - val_loss: 2.7760 - val_accuracy: 0.1179\n",
            "Epoch 340/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5039 - accuracy: 0.1818 - val_loss: 2.6478 - val_accuracy: 0.1440\n",
            "Epoch 341/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5053 - accuracy: 0.1840 - val_loss: 2.6575 - val_accuracy: 0.1362\n",
            "Epoch 342/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5058 - accuracy: 0.1822 - val_loss: 2.6886 - val_accuracy: 0.1484\n",
            "Epoch 343/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5099 - accuracy: 0.1805 - val_loss: 2.6470 - val_accuracy: 0.1445\n",
            "Epoch 344/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5002 - accuracy: 0.1832 - val_loss: 2.6680 - val_accuracy: 0.1305\n",
            "Epoch 345/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.5051 - accuracy: 0.1829 - val_loss: 2.6545 - val_accuracy: 0.1641\n",
            "Epoch 346/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4984 - accuracy: 0.1852 - val_loss: 2.6404 - val_accuracy: 0.1619\n",
            "Epoch 347/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4970 - accuracy: 0.1857 - val_loss: 2.6443 - val_accuracy: 0.1458\n",
            "Epoch 348/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4968 - accuracy: 0.1864 - val_loss: 2.6802 - val_accuracy: 0.1275\n",
            "Epoch 349/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4993 - accuracy: 0.1852 - val_loss: 2.6337 - val_accuracy: 0.1545\n",
            "Epoch 350/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.5004 - accuracy: 0.1836 - val_loss: 2.6993 - val_accuracy: 0.1536\n",
            "Epoch 351/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.5018 - accuracy: 0.1828 - val_loss: 2.7034 - val_accuracy: 0.1405\n",
            "Epoch 352/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4918 - accuracy: 0.1857 - val_loss: 2.6296 - val_accuracy: 0.1659\n",
            "Epoch 353/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4996 - accuracy: 0.1864 - val_loss: 2.6592 - val_accuracy: 0.1449\n",
            "Epoch 354/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4995 - accuracy: 0.1840 - val_loss: 2.7827 - val_accuracy: 0.1039\n",
            "Epoch 355/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4965 - accuracy: 0.1839 - val_loss: 2.6555 - val_accuracy: 0.1440\n",
            "Epoch 356/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4952 - accuracy: 0.1871 - val_loss: 2.7097 - val_accuracy: 0.1471\n",
            "Epoch 357/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4950 - accuracy: 0.1846 - val_loss: 2.7358 - val_accuracy: 0.1309\n",
            "Epoch 358/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4947 - accuracy: 0.1883 - val_loss: 2.6646 - val_accuracy: 0.1471\n",
            "Epoch 359/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.4905 - accuracy: 0.1856 - val_loss: 2.6533 - val_accuracy: 0.1388\n",
            "Epoch 360/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4946 - accuracy: 0.1848 - val_loss: 2.6591 - val_accuracy: 0.1580\n",
            "Epoch 361/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4927 - accuracy: 0.1873 - val_loss: 2.7227 - val_accuracy: 0.1344\n",
            "Epoch 362/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4944 - accuracy: 0.1881 - val_loss: 2.6857 - val_accuracy: 0.1340\n",
            "Epoch 363/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4949 - accuracy: 0.1860 - val_loss: 2.6721 - val_accuracy: 0.1309\n",
            "Epoch 364/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4864 - accuracy: 0.1845 - val_loss: 2.6530 - val_accuracy: 0.1379\n",
            "Epoch 365/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4870 - accuracy: 0.1885 - val_loss: 2.6992 - val_accuracy: 0.1227\n",
            "Epoch 366/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4946 - accuracy: 0.1850 - val_loss: 2.7244 - val_accuracy: 0.1427\n",
            "Epoch 367/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4939 - accuracy: 0.1856 - val_loss: 2.6675 - val_accuracy: 0.1344\n",
            "Epoch 368/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4877 - accuracy: 0.1883 - val_loss: 2.6965 - val_accuracy: 0.1157\n",
            "Epoch 369/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4881 - accuracy: 0.1882 - val_loss: 2.6567 - val_accuracy: 0.1654\n",
            "Epoch 370/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4906 - accuracy: 0.1852 - val_loss: 2.6269 - val_accuracy: 0.1475\n",
            "Epoch 371/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4852 - accuracy: 0.1887 - val_loss: 2.6530 - val_accuracy: 0.1506\n",
            "Epoch 372/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4854 - accuracy: 0.1865 - val_loss: 2.6583 - val_accuracy: 0.1515\n",
            "Epoch 373/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4788 - accuracy: 0.1868 - val_loss: 2.6383 - val_accuracy: 0.1637\n",
            "Epoch 374/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4854 - accuracy: 0.1890 - val_loss: 2.6297 - val_accuracy: 0.1654\n",
            "Epoch 375/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4872 - accuracy: 0.1867 - val_loss: 2.6482 - val_accuracy: 0.1467\n",
            "Epoch 376/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4829 - accuracy: 0.1866 - val_loss: 2.6512 - val_accuracy: 0.1314\n",
            "Epoch 377/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4837 - accuracy: 0.1872 - val_loss: 2.7034 - val_accuracy: 0.1401\n",
            "Epoch 378/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4822 - accuracy: 0.1878 - val_loss: 2.6186 - val_accuracy: 0.1759\n",
            "Epoch 379/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4817 - accuracy: 0.1857 - val_loss: 2.6801 - val_accuracy: 0.1423\n",
            "Epoch 380/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4841 - accuracy: 0.1879 - val_loss: 2.6730 - val_accuracy: 0.1427\n",
            "Epoch 381/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4832 - accuracy: 0.1879 - val_loss: 2.6735 - val_accuracy: 0.1484\n",
            "Epoch 382/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4806 - accuracy: 0.1874 - val_loss: 2.6412 - val_accuracy: 0.1379\n",
            "Epoch 383/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4766 - accuracy: 0.1909 - val_loss: 2.6280 - val_accuracy: 0.1619\n",
            "Epoch 384/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4813 - accuracy: 0.1870 - val_loss: 2.6664 - val_accuracy: 0.1309\n",
            "Epoch 385/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4802 - accuracy: 0.1902 - val_loss: 2.6324 - val_accuracy: 0.1576\n",
            "Epoch 386/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4762 - accuracy: 0.1884 - val_loss: 2.6433 - val_accuracy: 0.1536\n",
            "Epoch 387/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4786 - accuracy: 0.1877 - val_loss: 2.6610 - val_accuracy: 0.1720\n",
            "Epoch 388/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4718 - accuracy: 0.1892 - val_loss: 2.6303 - val_accuracy: 0.1672\n",
            "Epoch 389/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4816 - accuracy: 0.1863 - val_loss: 2.6449 - val_accuracy: 0.1388\n",
            "Epoch 390/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4798 - accuracy: 0.1887 - val_loss: 2.6099 - val_accuracy: 0.1493\n",
            "Epoch 391/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.4748 - accuracy: 0.1900 - val_loss: 2.6823 - val_accuracy: 0.1227\n",
            "Epoch 392/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.4723 - accuracy: 0.1915 - val_loss: 2.6547 - val_accuracy: 0.1510\n",
            "Epoch 393/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.4746 - accuracy: 0.1932 - val_loss: 2.6285 - val_accuracy: 0.1445\n",
            "Epoch 394/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4750 - accuracy: 0.1897 - val_loss: 2.6315 - val_accuracy: 0.1388\n",
            "Epoch 395/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4711 - accuracy: 0.1889 - val_loss: 2.6613 - val_accuracy: 0.1309\n",
            "Epoch 396/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4711 - accuracy: 0.1919 - val_loss: 2.6663 - val_accuracy: 0.1314\n",
            "Epoch 397/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4722 - accuracy: 0.1935 - val_loss: 2.6477 - val_accuracy: 0.1366\n",
            "Epoch 398/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4664 - accuracy: 0.1942 - val_loss: 2.6164 - val_accuracy: 0.1541\n",
            "Epoch 399/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4701 - accuracy: 0.1915 - val_loss: 2.6189 - val_accuracy: 0.1497\n",
            "Epoch 400/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4698 - accuracy: 0.1924 - val_loss: 2.6179 - val_accuracy: 0.1733\n",
            "Epoch 401/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4716 - accuracy: 0.1915 - val_loss: 2.6343 - val_accuracy: 0.1606\n",
            "Epoch 402/10000\n",
            "453/453 [==============================] - 3s 6ms/step - loss: 2.4696 - accuracy: 0.1940 - val_loss: 2.6452 - val_accuracy: 0.1427\n",
            "Epoch 403/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4677 - accuracy: 0.1926 - val_loss: 2.6815 - val_accuracy: 0.1305\n",
            "Epoch 404/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4727 - accuracy: 0.1915 - val_loss: 2.6420 - val_accuracy: 0.1379\n",
            "Epoch 405/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4710 - accuracy: 0.1922 - val_loss: 2.6248 - val_accuracy: 0.1458\n",
            "Epoch 406/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4627 - accuracy: 0.1934 - val_loss: 2.6627 - val_accuracy: 0.1523\n",
            "Epoch 407/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4632 - accuracy: 0.1947 - val_loss: 2.6406 - val_accuracy: 0.1628\n",
            "Epoch 408/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4648 - accuracy: 0.1936 - val_loss: 2.6128 - val_accuracy: 0.1571\n",
            "Epoch 409/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4689 - accuracy: 0.1921 - val_loss: 2.6329 - val_accuracy: 0.1523\n",
            "Epoch 410/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4637 - accuracy: 0.1945 - val_loss: 2.6028 - val_accuracy: 0.1615\n",
            "Epoch 411/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4674 - accuracy: 0.1918 - val_loss: 2.6159 - val_accuracy: 0.1563\n",
            "Epoch 412/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4666 - accuracy: 0.1930 - val_loss: 2.6162 - val_accuracy: 0.1571\n",
            "Epoch 413/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4597 - accuracy: 0.1953 - val_loss: 2.5914 - val_accuracy: 0.1794\n",
            "Epoch 414/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4596 - accuracy: 0.1959 - val_loss: 2.5997 - val_accuracy: 0.1746\n",
            "Epoch 415/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4575 - accuracy: 0.1951 - val_loss: 2.6379 - val_accuracy: 0.1480\n",
            "Epoch 416/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4619 - accuracy: 0.1929 - val_loss: 2.6244 - val_accuracy: 0.1432\n",
            "Epoch 417/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4570 - accuracy: 0.1942 - val_loss: 2.5985 - val_accuracy: 0.1768\n",
            "Epoch 418/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4577 - accuracy: 0.1962 - val_loss: 2.6051 - val_accuracy: 0.1558\n",
            "Epoch 419/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4580 - accuracy: 0.1964 - val_loss: 2.6613 - val_accuracy: 0.1301\n",
            "Epoch 420/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4608 - accuracy: 0.1936 - val_loss: 2.6238 - val_accuracy: 0.1598\n",
            "Epoch 421/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4563 - accuracy: 0.1957 - val_loss: 2.6093 - val_accuracy: 0.1733\n",
            "Epoch 422/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4570 - accuracy: 0.1974 - val_loss: 2.5953 - val_accuracy: 0.1650\n",
            "Epoch 423/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4527 - accuracy: 0.1950 - val_loss: 2.5976 - val_accuracy: 0.1680\n",
            "Epoch 424/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4534 - accuracy: 0.1979 - val_loss: 2.5983 - val_accuracy: 0.1563\n",
            "Epoch 425/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4553 - accuracy: 0.1969 - val_loss: 2.6083 - val_accuracy: 0.1584\n",
            "Epoch 426/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4599 - accuracy: 0.1943 - val_loss: 2.5970 - val_accuracy: 0.1777\n",
            "Epoch 427/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4590 - accuracy: 0.1949 - val_loss: 2.5962 - val_accuracy: 0.1580\n",
            "Epoch 428/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.4527 - accuracy: 0.1970 - val_loss: 2.5929 - val_accuracy: 0.1777\n",
            "Epoch 429/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4547 - accuracy: 0.1974 - val_loss: 2.5939 - val_accuracy: 0.1694\n",
            "Epoch 430/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4550 - accuracy: 0.1948 - val_loss: 2.6012 - val_accuracy: 0.1676\n",
            "Epoch 431/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4556 - accuracy: 0.1980 - val_loss: 2.6103 - val_accuracy: 0.1611\n",
            "Epoch 432/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4500 - accuracy: 0.2002 - val_loss: 2.6207 - val_accuracy: 0.1436\n",
            "Epoch 433/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4512 - accuracy: 0.1995 - val_loss: 2.6260 - val_accuracy: 0.1571\n",
            "Epoch 434/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4503 - accuracy: 0.1993 - val_loss: 2.7136 - val_accuracy: 0.1336\n",
            "Epoch 435/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4483 - accuracy: 0.1982 - val_loss: 2.6275 - val_accuracy: 0.1357\n",
            "Epoch 436/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4479 - accuracy: 0.2003 - val_loss: 2.6125 - val_accuracy: 0.1523\n",
            "Epoch 437/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4465 - accuracy: 0.2016 - val_loss: 2.6137 - val_accuracy: 0.1646\n",
            "Epoch 438/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4511 - accuracy: 0.1979 - val_loss: 2.6280 - val_accuracy: 0.1458\n",
            "Epoch 439/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4490 - accuracy: 0.1971 - val_loss: 2.6006 - val_accuracy: 0.1676\n",
            "Epoch 440/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4462 - accuracy: 0.1992 - val_loss: 2.6077 - val_accuracy: 0.1506\n",
            "Epoch 441/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4482 - accuracy: 0.2002 - val_loss: 2.6524 - val_accuracy: 0.1432\n",
            "Epoch 442/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4420 - accuracy: 0.2033 - val_loss: 2.6099 - val_accuracy: 0.1593\n",
            "Epoch 443/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4438 - accuracy: 0.1995 - val_loss: 2.5908 - val_accuracy: 0.1589\n",
            "Epoch 444/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4430 - accuracy: 0.2003 - val_loss: 2.5786 - val_accuracy: 0.1746\n",
            "Epoch 445/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4382 - accuracy: 0.2033 - val_loss: 2.6130 - val_accuracy: 0.1698\n",
            "Epoch 446/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4445 - accuracy: 0.1998 - val_loss: 2.5972 - val_accuracy: 0.1729\n",
            "Epoch 447/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4447 - accuracy: 0.2000 - val_loss: 2.6290 - val_accuracy: 0.1449\n",
            "Epoch 448/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4428 - accuracy: 0.2007 - val_loss: 2.6003 - val_accuracy: 0.1523\n",
            "Epoch 449/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4441 - accuracy: 0.2014 - val_loss: 2.6422 - val_accuracy: 0.1414\n",
            "Epoch 450/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4419 - accuracy: 0.2004 - val_loss: 2.5865 - val_accuracy: 0.1969\n",
            "Epoch 451/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4430 - accuracy: 0.2016 - val_loss: 2.6521 - val_accuracy: 0.1502\n",
            "Epoch 452/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.4392 - accuracy: 0.1997 - val_loss: 2.6024 - val_accuracy: 0.1659\n",
            "Epoch 453/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.4393 - accuracy: 0.2045 - val_loss: 2.6156 - val_accuracy: 0.1558\n",
            "Epoch 454/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4394 - accuracy: 0.2030 - val_loss: 2.6635 - val_accuracy: 0.1357\n",
            "Epoch 455/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4379 - accuracy: 0.2003 - val_loss: 2.5659 - val_accuracy: 0.1763\n",
            "Epoch 456/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4366 - accuracy: 0.2037 - val_loss: 2.6021 - val_accuracy: 0.1580\n",
            "Epoch 457/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4375 - accuracy: 0.2047 - val_loss: 2.5813 - val_accuracy: 0.1702\n",
            "Epoch 458/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4424 - accuracy: 0.2011 - val_loss: 2.5894 - val_accuracy: 0.1680\n",
            "Epoch 459/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4412 - accuracy: 0.2041 - val_loss: 2.5684 - val_accuracy: 0.1667\n",
            "Epoch 460/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4346 - accuracy: 0.2033 - val_loss: 2.5944 - val_accuracy: 0.1550\n",
            "Epoch 461/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4387 - accuracy: 0.2047 - val_loss: 2.6240 - val_accuracy: 0.1467\n",
            "Epoch 462/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4354 - accuracy: 0.2048 - val_loss: 2.5993 - val_accuracy: 0.1676\n",
            "Epoch 463/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4323 - accuracy: 0.2049 - val_loss: 2.5900 - val_accuracy: 0.1567\n",
            "Epoch 464/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4320 - accuracy: 0.2076 - val_loss: 2.5807 - val_accuracy: 0.1698\n",
            "Epoch 465/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4341 - accuracy: 0.2054 - val_loss: 2.6064 - val_accuracy: 0.1510\n",
            "Epoch 466/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4318 - accuracy: 0.2059 - val_loss: 2.6123 - val_accuracy: 0.1554\n",
            "Epoch 467/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4337 - accuracy: 0.2058 - val_loss: 2.6579 - val_accuracy: 0.1440\n",
            "Epoch 468/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4367 - accuracy: 0.2015 - val_loss: 2.5822 - val_accuracy: 0.1650\n",
            "Epoch 469/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4353 - accuracy: 0.2030 - val_loss: 2.5686 - val_accuracy: 0.1715\n",
            "Epoch 470/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4316 - accuracy: 0.2048 - val_loss: 2.5947 - val_accuracy: 0.1563\n",
            "Epoch 471/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4335 - accuracy: 0.2062 - val_loss: 2.5890 - val_accuracy: 0.1829\n",
            "Epoch 472/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4285 - accuracy: 0.2061 - val_loss: 2.5902 - val_accuracy: 0.1672\n",
            "Epoch 473/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4334 - accuracy: 0.2076 - val_loss: 2.5782 - val_accuracy: 0.1724\n",
            "Epoch 474/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4283 - accuracy: 0.2080 - val_loss: 2.5766 - val_accuracy: 0.1667\n",
            "Epoch 475/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4271 - accuracy: 0.2097 - val_loss: 2.5720 - val_accuracy: 0.1855\n",
            "Epoch 476/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4213 - accuracy: 0.2067 - val_loss: 2.6109 - val_accuracy: 0.1432\n",
            "Epoch 477/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4238 - accuracy: 0.2082 - val_loss: 2.5891 - val_accuracy: 0.1541\n",
            "Epoch 478/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4293 - accuracy: 0.2066 - val_loss: 2.5676 - val_accuracy: 0.1763\n",
            "Epoch 479/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4309 - accuracy: 0.2067 - val_loss: 2.5610 - val_accuracy: 0.1873\n",
            "Epoch 480/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4269 - accuracy: 0.2072 - val_loss: 2.5750 - val_accuracy: 0.1598\n",
            "Epoch 481/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4281 - accuracy: 0.2082 - val_loss: 2.6108 - val_accuracy: 0.1580\n",
            "Epoch 482/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4222 - accuracy: 0.2083 - val_loss: 2.6311 - val_accuracy: 0.1567\n",
            "Epoch 483/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4275 - accuracy: 0.2081 - val_loss: 2.5723 - val_accuracy: 0.1855\n",
            "Epoch 484/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4275 - accuracy: 0.2086 - val_loss: 2.5746 - val_accuracy: 0.1663\n",
            "Epoch 485/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4191 - accuracy: 0.2097 - val_loss: 2.5839 - val_accuracy: 0.1711\n",
            "Epoch 486/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4224 - accuracy: 0.2104 - val_loss: 2.5625 - val_accuracy: 0.1903\n",
            "Epoch 487/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4218 - accuracy: 0.2104 - val_loss: 2.5430 - val_accuracy: 0.1934\n",
            "Epoch 488/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4174 - accuracy: 0.2116 - val_loss: 2.6524 - val_accuracy: 0.1340\n",
            "Epoch 489/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4241 - accuracy: 0.2133 - val_loss: 2.5893 - val_accuracy: 0.1659\n",
            "Epoch 490/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4177 - accuracy: 0.2122 - val_loss: 2.6174 - val_accuracy: 0.1602\n",
            "Epoch 491/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4236 - accuracy: 0.2107 - val_loss: 2.5759 - val_accuracy: 0.1659\n",
            "Epoch 492/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4177 - accuracy: 0.2106 - val_loss: 2.5980 - val_accuracy: 0.1541\n",
            "Epoch 493/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4199 - accuracy: 0.2096 - val_loss: 2.5897 - val_accuracy: 0.1580\n",
            "Epoch 494/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4242 - accuracy: 0.2102 - val_loss: 2.6386 - val_accuracy: 0.1318\n",
            "Epoch 495/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4141 - accuracy: 0.2125 - val_loss: 2.5887 - val_accuracy: 0.1768\n",
            "Epoch 496/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4174 - accuracy: 0.2120 - val_loss: 2.5850 - val_accuracy: 0.1563\n",
            "Epoch 497/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4169 - accuracy: 0.2130 - val_loss: 2.7008 - val_accuracy: 0.1305\n",
            "Epoch 498/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4199 - accuracy: 0.2113 - val_loss: 2.5950 - val_accuracy: 0.1624\n",
            "Epoch 499/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4128 - accuracy: 0.2119 - val_loss: 2.5664 - val_accuracy: 0.1676\n",
            "Epoch 500/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4146 - accuracy: 0.2155 - val_loss: 2.5823 - val_accuracy: 0.1593\n",
            "Epoch 501/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4170 - accuracy: 0.2133 - val_loss: 2.5747 - val_accuracy: 0.1807\n",
            "Epoch 502/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4187 - accuracy: 0.2073 - val_loss: 2.5767 - val_accuracy: 0.1602\n",
            "Epoch 503/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4179 - accuracy: 0.2109 - val_loss: 2.6006 - val_accuracy: 0.1584\n",
            "Epoch 504/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4170 - accuracy: 0.2103 - val_loss: 2.5573 - val_accuracy: 0.1676\n",
            "Epoch 505/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4165 - accuracy: 0.2143 - val_loss: 2.6209 - val_accuracy: 0.1510\n",
            "Epoch 506/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4185 - accuracy: 0.2102 - val_loss: 2.5704 - val_accuracy: 0.1659\n",
            "Epoch 507/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4131 - accuracy: 0.2121 - val_loss: 2.5645 - val_accuracy: 0.1737\n",
            "Epoch 508/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4149 - accuracy: 0.2133 - val_loss: 2.5371 - val_accuracy: 0.1868\n",
            "Epoch 509/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4127 - accuracy: 0.2130 - val_loss: 2.5503 - val_accuracy: 0.1816\n",
            "Epoch 510/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4175 - accuracy: 0.2120 - val_loss: 2.5526 - val_accuracy: 0.1820\n",
            "Epoch 511/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4118 - accuracy: 0.2125 - val_loss: 2.6248 - val_accuracy: 0.1458\n",
            "Epoch 512/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4094 - accuracy: 0.2123 - val_loss: 2.5441 - val_accuracy: 0.1951\n",
            "Epoch 513/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4095 - accuracy: 0.2142 - val_loss: 2.5668 - val_accuracy: 0.1820\n",
            "Epoch 514/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.4081 - accuracy: 0.2162 - val_loss: 2.6015 - val_accuracy: 0.1558\n",
            "Epoch 515/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.4083 - accuracy: 0.2144 - val_loss: 2.5694 - val_accuracy: 0.1650\n",
            "Epoch 516/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.4074 - accuracy: 0.2181 - val_loss: 2.5563 - val_accuracy: 0.1763\n",
            "Epoch 517/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4063 - accuracy: 0.2148 - val_loss: 2.6105 - val_accuracy: 0.1480\n",
            "Epoch 518/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4090 - accuracy: 0.2164 - val_loss: 2.5585 - val_accuracy: 0.1820\n",
            "Epoch 519/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4036 - accuracy: 0.2175 - val_loss: 2.6002 - val_accuracy: 0.1558\n",
            "Epoch 520/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4046 - accuracy: 0.2164 - val_loss: 2.5622 - val_accuracy: 0.1715\n",
            "Epoch 521/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4068 - accuracy: 0.2159 - val_loss: 2.5504 - val_accuracy: 0.1807\n",
            "Epoch 522/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4031 - accuracy: 0.2166 - val_loss: 2.5610 - val_accuracy: 0.1859\n",
            "Epoch 523/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4082 - accuracy: 0.2124 - val_loss: 2.5347 - val_accuracy: 0.1816\n",
            "Epoch 524/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4043 - accuracy: 0.2167 - val_loss: 2.5575 - val_accuracy: 0.1768\n",
            "Epoch 525/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4022 - accuracy: 0.2172 - val_loss: 2.5400 - val_accuracy: 0.1881\n",
            "Epoch 526/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4076 - accuracy: 0.2145 - val_loss: 2.5734 - val_accuracy: 0.1593\n",
            "Epoch 527/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4059 - accuracy: 0.2162 - val_loss: 2.5482 - val_accuracy: 0.1746\n",
            "Epoch 528/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3990 - accuracy: 0.2162 - val_loss: 2.5872 - val_accuracy: 0.1602\n",
            "Epoch 529/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4041 - accuracy: 0.2168 - val_loss: 2.5442 - val_accuracy: 0.1925\n",
            "Epoch 530/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4023 - accuracy: 0.2175 - val_loss: 2.5957 - val_accuracy: 0.1502\n",
            "Epoch 531/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4043 - accuracy: 0.2152 - val_loss: 2.6029 - val_accuracy: 0.1462\n",
            "Epoch 532/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4014 - accuracy: 0.2167 - val_loss: 2.5435 - val_accuracy: 0.1873\n",
            "Epoch 533/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4016 - accuracy: 0.2174 - val_loss: 2.5816 - val_accuracy: 0.1593\n",
            "Epoch 534/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.4032 - accuracy: 0.2196 - val_loss: 2.5973 - val_accuracy: 0.1707\n",
            "Epoch 535/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3937 - accuracy: 0.2186 - val_loss: 2.5236 - val_accuracy: 0.2073\n",
            "Epoch 536/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3976 - accuracy: 0.2203 - val_loss: 2.6317 - val_accuracy: 0.1550\n",
            "Epoch 537/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3979 - accuracy: 0.2188 - val_loss: 2.5358 - val_accuracy: 0.1816\n",
            "Epoch 538/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3946 - accuracy: 0.2188 - val_loss: 2.5272 - val_accuracy: 0.1921\n",
            "Epoch 539/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3968 - accuracy: 0.2191 - val_loss: 2.5682 - val_accuracy: 0.1558\n",
            "Epoch 540/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.4002 - accuracy: 0.2163 - val_loss: 2.5360 - val_accuracy: 0.1995\n",
            "Epoch 541/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.4027 - accuracy: 0.2148 - val_loss: 2.5642 - val_accuracy: 0.1593\n",
            "Epoch 542/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3951 - accuracy: 0.2204 - val_loss: 2.5664 - val_accuracy: 0.1641\n",
            "Epoch 543/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3927 - accuracy: 0.2190 - val_loss: 2.5616 - val_accuracy: 0.2052\n",
            "Epoch 544/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3980 - accuracy: 0.2187 - val_loss: 2.5485 - val_accuracy: 0.1772\n",
            "Epoch 545/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3930 - accuracy: 0.2200 - val_loss: 2.5421 - val_accuracy: 0.1825\n",
            "Epoch 546/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3920 - accuracy: 0.2207 - val_loss: 2.5520 - val_accuracy: 0.1851\n",
            "Epoch 547/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3957 - accuracy: 0.2186 - val_loss: 2.5508 - val_accuracy: 0.1742\n",
            "Epoch 548/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3982 - accuracy: 0.2180 - val_loss: 2.5439 - val_accuracy: 0.1929\n",
            "Epoch 549/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3925 - accuracy: 0.2198 - val_loss: 2.5621 - val_accuracy: 0.1676\n",
            "Epoch 550/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3924 - accuracy: 0.2206 - val_loss: 2.5532 - val_accuracy: 0.1694\n",
            "Epoch 551/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3949 - accuracy: 0.2186 - val_loss: 2.5571 - val_accuracy: 0.1759\n",
            "Epoch 552/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3918 - accuracy: 0.2207 - val_loss: 2.5376 - val_accuracy: 0.1855\n",
            "Epoch 553/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3916 - accuracy: 0.2183 - val_loss: 2.5224 - val_accuracy: 0.1938\n",
            "Epoch 554/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3948 - accuracy: 0.2161 - val_loss: 2.5625 - val_accuracy: 0.1947\n",
            "Epoch 555/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3852 - accuracy: 0.2224 - val_loss: 2.5370 - val_accuracy: 0.1777\n",
            "Epoch 556/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3930 - accuracy: 0.2178 - val_loss: 2.5449 - val_accuracy: 0.1777\n",
            "Epoch 557/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3921 - accuracy: 0.2187 - val_loss: 2.5257 - val_accuracy: 0.2034\n",
            "Epoch 558/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3867 - accuracy: 0.2196 - val_loss: 2.5887 - val_accuracy: 0.1772\n",
            "Epoch 559/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3867 - accuracy: 0.2222 - val_loss: 2.5357 - val_accuracy: 0.1746\n",
            "Epoch 560/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3892 - accuracy: 0.2208 - val_loss: 2.5506 - val_accuracy: 0.1702\n",
            "Epoch 561/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3903 - accuracy: 0.2183 - val_loss: 2.5690 - val_accuracy: 0.1729\n",
            "Epoch 562/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3874 - accuracy: 0.2215 - val_loss: 2.5521 - val_accuracy: 0.1654\n",
            "Epoch 563/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3875 - accuracy: 0.2216 - val_loss: 2.6352 - val_accuracy: 0.1440\n",
            "Epoch 564/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3836 - accuracy: 0.2232 - val_loss: 2.5714 - val_accuracy: 0.1628\n",
            "Epoch 565/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3849 - accuracy: 0.2202 - val_loss: 2.5267 - val_accuracy: 0.2008\n",
            "Epoch 566/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3850 - accuracy: 0.2250 - val_loss: 2.5708 - val_accuracy: 0.1672\n",
            "Epoch 567/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3819 - accuracy: 0.2200 - val_loss: 2.5250 - val_accuracy: 0.1990\n",
            "Epoch 568/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3917 - accuracy: 0.2207 - val_loss: 2.6574 - val_accuracy: 0.1462\n",
            "Epoch 569/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3890 - accuracy: 0.2205 - val_loss: 2.5710 - val_accuracy: 0.1624\n",
            "Epoch 570/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3859 - accuracy: 0.2223 - val_loss: 2.5123 - val_accuracy: 0.1990\n",
            "Epoch 571/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3858 - accuracy: 0.2222 - val_loss: 2.5137 - val_accuracy: 0.1934\n",
            "Epoch 572/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3889 - accuracy: 0.2186 - val_loss: 2.5616 - val_accuracy: 0.1877\n",
            "Epoch 573/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3793 - accuracy: 0.2250 - val_loss: 2.5184 - val_accuracy: 0.2117\n",
            "Epoch 574/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.3831 - accuracy: 0.2235 - val_loss: 2.5089 - val_accuracy: 0.2043\n",
            "Epoch 575/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3767 - accuracy: 0.2266 - val_loss: 2.5057 - val_accuracy: 0.2073\n",
            "Epoch 576/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3776 - accuracy: 0.2254 - val_loss: 2.5134 - val_accuracy: 0.2130\n",
            "Epoch 577/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3781 - accuracy: 0.2256 - val_loss: 2.5240 - val_accuracy: 0.1942\n",
            "Epoch 578/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3835 - accuracy: 0.2231 - val_loss: 2.5530 - val_accuracy: 0.1855\n",
            "Epoch 579/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3789 - accuracy: 0.2230 - val_loss: 2.5330 - val_accuracy: 0.1785\n",
            "Epoch 580/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3775 - accuracy: 0.2250 - val_loss: 2.5407 - val_accuracy: 0.1729\n",
            "Epoch 581/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3809 - accuracy: 0.2227 - val_loss: 2.5507 - val_accuracy: 0.1720\n",
            "Epoch 582/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3783 - accuracy: 0.2249 - val_loss: 2.5505 - val_accuracy: 0.1829\n",
            "Epoch 583/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3785 - accuracy: 0.2247 - val_loss: 2.5289 - val_accuracy: 0.1925\n",
            "Epoch 584/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3804 - accuracy: 0.2235 - val_loss: 2.5524 - val_accuracy: 0.1803\n",
            "Epoch 585/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3790 - accuracy: 0.2238 - val_loss: 2.5420 - val_accuracy: 0.1676\n",
            "Epoch 586/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3760 - accuracy: 0.2277 - val_loss: 2.5444 - val_accuracy: 0.1711\n",
            "Epoch 587/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3778 - accuracy: 0.2242 - val_loss: 2.5682 - val_accuracy: 0.1694\n",
            "Epoch 588/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3753 - accuracy: 0.2271 - val_loss: 2.5053 - val_accuracy: 0.2056\n",
            "Epoch 589/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3717 - accuracy: 0.2275 - val_loss: 2.5514 - val_accuracy: 0.1685\n",
            "Epoch 590/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3722 - accuracy: 0.2274 - val_loss: 2.5426 - val_accuracy: 0.2126\n",
            "Epoch 591/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3752 - accuracy: 0.2254 - val_loss: 2.5423 - val_accuracy: 0.1772\n",
            "Epoch 592/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3744 - accuracy: 0.2248 - val_loss: 2.5963 - val_accuracy: 0.1541\n",
            "Epoch 593/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3712 - accuracy: 0.2294 - val_loss: 2.5794 - val_accuracy: 0.1598\n",
            "Epoch 594/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3725 - accuracy: 0.2258 - val_loss: 2.5288 - val_accuracy: 0.2169\n",
            "Epoch 595/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3747 - accuracy: 0.2256 - val_loss: 2.5171 - val_accuracy: 0.1851\n",
            "Epoch 596/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3739 - accuracy: 0.2247 - val_loss: 2.5208 - val_accuracy: 0.1951\n",
            "Epoch 597/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3722 - accuracy: 0.2237 - val_loss: 2.5069 - val_accuracy: 0.1969\n",
            "Epoch 598/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3735 - accuracy: 0.2265 - val_loss: 2.5183 - val_accuracy: 0.2126\n",
            "Epoch 599/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3740 - accuracy: 0.2249 - val_loss: 2.5744 - val_accuracy: 0.1659\n",
            "Epoch 600/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3736 - accuracy: 0.2268 - val_loss: 2.5347 - val_accuracy: 0.1816\n",
            "Epoch 601/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3696 - accuracy: 0.2262 - val_loss: 2.5112 - val_accuracy: 0.2025\n",
            "Epoch 602/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3718 - accuracy: 0.2260 - val_loss: 2.5101 - val_accuracy: 0.1942\n",
            "Epoch 603/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3728 - accuracy: 0.2266 - val_loss: 2.5099 - val_accuracy: 0.1938\n",
            "Epoch 604/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3715 - accuracy: 0.2257 - val_loss: 2.5327 - val_accuracy: 0.1702\n",
            "Epoch 605/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3762 - accuracy: 0.2224 - val_loss: 2.5541 - val_accuracy: 0.2073\n",
            "Epoch 606/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3757 - accuracy: 0.2267 - val_loss: 2.6333 - val_accuracy: 0.1362\n",
            "Epoch 607/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3667 - accuracy: 0.2282 - val_loss: 2.5919 - val_accuracy: 0.1986\n",
            "Epoch 608/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3667 - accuracy: 0.2270 - val_loss: 2.5045 - val_accuracy: 0.2025\n",
            "Epoch 609/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3665 - accuracy: 0.2273 - val_loss: 2.5239 - val_accuracy: 0.2065\n",
            "Epoch 610/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3706 - accuracy: 0.2244 - val_loss: 2.5463 - val_accuracy: 0.1589\n",
            "Epoch 611/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3695 - accuracy: 0.2268 - val_loss: 2.5132 - val_accuracy: 0.1912\n",
            "Epoch 612/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3696 - accuracy: 0.2236 - val_loss: 2.5311 - val_accuracy: 0.1811\n",
            "Epoch 613/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3681 - accuracy: 0.2282 - val_loss: 2.5066 - val_accuracy: 0.2108\n",
            "Epoch 614/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3639 - accuracy: 0.2246 - val_loss: 2.5201 - val_accuracy: 0.1833\n",
            "Epoch 615/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3639 - accuracy: 0.2300 - val_loss: 2.6179 - val_accuracy: 0.1484\n",
            "Epoch 616/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3645 - accuracy: 0.2297 - val_loss: 2.5115 - val_accuracy: 0.1903\n",
            "Epoch 617/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3679 - accuracy: 0.2271 - val_loss: 2.4884 - val_accuracy: 0.2126\n",
            "Epoch 618/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3615 - accuracy: 0.2319 - val_loss: 2.5085 - val_accuracy: 0.1894\n",
            "Epoch 619/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3676 - accuracy: 0.2282 - val_loss: 2.5091 - val_accuracy: 0.2003\n",
            "Epoch 620/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3720 - accuracy: 0.2266 - val_loss: 2.4926 - val_accuracy: 0.2034\n",
            "Epoch 621/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3647 - accuracy: 0.2271 - val_loss: 2.5134 - val_accuracy: 0.2169\n",
            "Epoch 622/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3695 - accuracy: 0.2251 - val_loss: 2.5192 - val_accuracy: 0.1894\n",
            "Epoch 623/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3628 - accuracy: 0.2293 - val_loss: 2.5706 - val_accuracy: 0.1375\n",
            "Epoch 624/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3607 - accuracy: 0.2290 - val_loss: 2.5189 - val_accuracy: 0.2030\n",
            "Epoch 625/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3665 - accuracy: 0.2252 - val_loss: 2.5316 - val_accuracy: 0.1807\n",
            "Epoch 626/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3673 - accuracy: 0.2253 - val_loss: 2.5227 - val_accuracy: 0.1742\n",
            "Epoch 627/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3586 - accuracy: 0.2284 - val_loss: 2.5148 - val_accuracy: 0.2130\n",
            "Epoch 628/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3638 - accuracy: 0.2253 - val_loss: 2.5449 - val_accuracy: 0.1886\n",
            "Epoch 629/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3582 - accuracy: 0.2285 - val_loss: 2.5153 - val_accuracy: 0.1768\n",
            "Epoch 630/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.3667 - accuracy: 0.2285 - val_loss: 2.5347 - val_accuracy: 0.1894\n",
            "Epoch 631/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3585 - accuracy: 0.2296 - val_loss: 2.5253 - val_accuracy: 0.1859\n",
            "Epoch 632/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3662 - accuracy: 0.2261 - val_loss: 2.5253 - val_accuracy: 0.1868\n",
            "Epoch 633/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3666 - accuracy: 0.2270 - val_loss: 2.4890 - val_accuracy: 0.2056\n",
            "Epoch 634/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3577 - accuracy: 0.2291 - val_loss: 2.5389 - val_accuracy: 0.1798\n",
            "Epoch 635/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3615 - accuracy: 0.2287 - val_loss: 2.5629 - val_accuracy: 0.1886\n",
            "Epoch 636/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3544 - accuracy: 0.2331 - val_loss: 2.4892 - val_accuracy: 0.2200\n",
            "Epoch 637/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3585 - accuracy: 0.2296 - val_loss: 2.5051 - val_accuracy: 0.2038\n",
            "Epoch 638/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3570 - accuracy: 0.2298 - val_loss: 2.4967 - val_accuracy: 0.1986\n",
            "Epoch 639/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3563 - accuracy: 0.2284 - val_loss: 2.5657 - val_accuracy: 0.1632\n",
            "Epoch 640/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3562 - accuracy: 0.2302 - val_loss: 2.5023 - val_accuracy: 0.1881\n",
            "Epoch 641/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3567 - accuracy: 0.2276 - val_loss: 2.4997 - val_accuracy: 0.1942\n",
            "Epoch 642/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3574 - accuracy: 0.2298 - val_loss: 2.5137 - val_accuracy: 0.1986\n",
            "Epoch 643/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3610 - accuracy: 0.2287 - val_loss: 2.5206 - val_accuracy: 0.1720\n",
            "Epoch 644/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3584 - accuracy: 0.2304 - val_loss: 2.5213 - val_accuracy: 0.1881\n",
            "Epoch 645/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3593 - accuracy: 0.2302 - val_loss: 2.5313 - val_accuracy: 0.2117\n",
            "Epoch 646/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3590 - accuracy: 0.2284 - val_loss: 2.5974 - val_accuracy: 0.1707\n",
            "Epoch 647/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3567 - accuracy: 0.2268 - val_loss: 2.6219 - val_accuracy: 0.1536\n",
            "Epoch 648/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3601 - accuracy: 0.2268 - val_loss: 2.5033 - val_accuracy: 0.2060\n",
            "Epoch 649/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3537 - accuracy: 0.2304 - val_loss: 2.6130 - val_accuracy: 0.1541\n",
            "Epoch 650/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3583 - accuracy: 0.2278 - val_loss: 2.4755 - val_accuracy: 0.2261\n",
            "Epoch 651/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3516 - accuracy: 0.2315 - val_loss: 2.5442 - val_accuracy: 0.1755\n",
            "Epoch 652/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3541 - accuracy: 0.2307 - val_loss: 2.4865 - val_accuracy: 0.1973\n",
            "Epoch 653/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3506 - accuracy: 0.2324 - val_loss: 2.4903 - val_accuracy: 0.2200\n",
            "Epoch 654/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3525 - accuracy: 0.2301 - val_loss: 2.5002 - val_accuracy: 0.1899\n",
            "Epoch 655/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3545 - accuracy: 0.2329 - val_loss: 2.5277 - val_accuracy: 0.1742\n",
            "Epoch 656/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3535 - accuracy: 0.2317 - val_loss: 2.5002 - val_accuracy: 0.2056\n",
            "Epoch 657/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3558 - accuracy: 0.2295 - val_loss: 2.4730 - val_accuracy: 0.2130\n",
            "Epoch 658/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3540 - accuracy: 0.2306 - val_loss: 2.4854 - val_accuracy: 0.2017\n",
            "Epoch 659/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3498 - accuracy: 0.2327 - val_loss: 2.4887 - val_accuracy: 0.2008\n",
            "Epoch 660/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3515 - accuracy: 0.2325 - val_loss: 2.4858 - val_accuracy: 0.1929\n",
            "Epoch 661/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3491 - accuracy: 0.2313 - val_loss: 2.4756 - val_accuracy: 0.2078\n",
            "Epoch 662/10000\n",
            "453/453 [==============================] - 3s 7ms/step - loss: 2.3544 - accuracy: 0.2297 - val_loss: 2.5749 - val_accuracy: 0.1646\n",
            "Epoch 663/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3492 - accuracy: 0.2342 - val_loss: 2.4896 - val_accuracy: 0.1982\n",
            "Epoch 664/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3526 - accuracy: 0.2286 - val_loss: 2.5140 - val_accuracy: 0.1846\n",
            "Epoch 665/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3508 - accuracy: 0.2330 - val_loss: 2.4851 - val_accuracy: 0.2104\n",
            "Epoch 666/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3466 - accuracy: 0.2336 - val_loss: 2.5018 - val_accuracy: 0.1912\n",
            "Epoch 667/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3485 - accuracy: 0.2311 - val_loss: 2.4928 - val_accuracy: 0.1886\n",
            "Epoch 668/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3470 - accuracy: 0.2318 - val_loss: 2.4896 - val_accuracy: 0.2095\n",
            "Epoch 669/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3463 - accuracy: 0.2314 - val_loss: 2.5448 - val_accuracy: 0.1637\n",
            "Epoch 670/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3522 - accuracy: 0.2296 - val_loss: 2.5229 - val_accuracy: 0.1711\n",
            "Epoch 671/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3457 - accuracy: 0.2332 - val_loss: 2.5142 - val_accuracy: 0.1881\n",
            "Epoch 672/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3461 - accuracy: 0.2324 - val_loss: 2.5719 - val_accuracy: 0.1536\n",
            "Epoch 673/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3465 - accuracy: 0.2329 - val_loss: 2.4614 - val_accuracy: 0.2265\n",
            "Epoch 674/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3484 - accuracy: 0.2315 - val_loss: 2.5206 - val_accuracy: 0.1794\n",
            "Epoch 675/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3495 - accuracy: 0.2311 - val_loss: 2.5781 - val_accuracy: 0.1646\n",
            "Epoch 676/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3491 - accuracy: 0.2314 - val_loss: 2.5442 - val_accuracy: 0.1702\n",
            "Epoch 677/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3494 - accuracy: 0.2310 - val_loss: 2.4802 - val_accuracy: 0.2274\n",
            "Epoch 678/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3428 - accuracy: 0.2342 - val_loss: 2.4893 - val_accuracy: 0.2086\n",
            "Epoch 679/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3457 - accuracy: 0.2315 - val_loss: 2.5341 - val_accuracy: 0.1886\n",
            "Epoch 680/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3440 - accuracy: 0.2336 - val_loss: 2.5111 - val_accuracy: 0.1746\n",
            "Epoch 681/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3456 - accuracy: 0.2294 - val_loss: 2.4940 - val_accuracy: 0.2052\n",
            "Epoch 682/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3444 - accuracy: 0.2339 - val_loss: 2.5113 - val_accuracy: 0.1785\n",
            "Epoch 683/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3457 - accuracy: 0.2313 - val_loss: 2.4972 - val_accuracy: 0.1960\n",
            "Epoch 684/10000\n",
            "453/453 [==============================] - 7s 15ms/step - loss: 2.3436 - accuracy: 0.2309 - val_loss: 2.4741 - val_accuracy: 0.2082\n",
            "Epoch 685/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3438 - accuracy: 0.2334 - val_loss: 2.5160 - val_accuracy: 0.1859\n",
            "Epoch 686/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3485 - accuracy: 0.2326 - val_loss: 2.4897 - val_accuracy: 0.2030\n",
            "Epoch 687/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3386 - accuracy: 0.2334 - val_loss: 2.4672 - val_accuracy: 0.2121\n",
            "Epoch 688/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3463 - accuracy: 0.2304 - val_loss: 2.5104 - val_accuracy: 0.1973\n",
            "Epoch 689/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3465 - accuracy: 0.2294 - val_loss: 2.5033 - val_accuracy: 0.1890\n",
            "Epoch 690/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3426 - accuracy: 0.2321 - val_loss: 2.5560 - val_accuracy: 0.1781\n",
            "Epoch 691/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3432 - accuracy: 0.2300 - val_loss: 2.4808 - val_accuracy: 0.2187\n",
            "Epoch 692/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3422 - accuracy: 0.2326 - val_loss: 2.5232 - val_accuracy: 0.1864\n",
            "Epoch 693/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3408 - accuracy: 0.2338 - val_loss: 2.5756 - val_accuracy: 0.1772\n",
            "Epoch 694/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3435 - accuracy: 0.2319 - val_loss: 2.5116 - val_accuracy: 0.1955\n",
            "Epoch 695/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3416 - accuracy: 0.2339 - val_loss: 2.4841 - val_accuracy: 0.2030\n",
            "Epoch 696/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3371 - accuracy: 0.2364 - val_loss: 2.4672 - val_accuracy: 0.2209\n",
            "Epoch 697/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3381 - accuracy: 0.2363 - val_loss: 2.5187 - val_accuracy: 0.1777\n",
            "Epoch 698/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3449 - accuracy: 0.2303 - val_loss: 2.4874 - val_accuracy: 0.1916\n",
            "Epoch 699/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3420 - accuracy: 0.2321 - val_loss: 2.5229 - val_accuracy: 0.1925\n",
            "Epoch 700/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3360 - accuracy: 0.2354 - val_loss: 2.4967 - val_accuracy: 0.2078\n",
            "Epoch 701/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3415 - accuracy: 0.2318 - val_loss: 2.4821 - val_accuracy: 0.1999\n",
            "Epoch 702/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3379 - accuracy: 0.2345 - val_loss: 2.5223 - val_accuracy: 0.1781\n",
            "Epoch 703/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3443 - accuracy: 0.2305 - val_loss: 2.5530 - val_accuracy: 0.1694\n",
            "Epoch 704/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3368 - accuracy: 0.2334 - val_loss: 2.4679 - val_accuracy: 0.2187\n",
            "Epoch 705/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3385 - accuracy: 0.2341 - val_loss: 2.4596 - val_accuracy: 0.2287\n",
            "Epoch 706/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3384 - accuracy: 0.2332 - val_loss: 2.4745 - val_accuracy: 0.2047\n",
            "Epoch 707/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3373 - accuracy: 0.2354 - val_loss: 2.4761 - val_accuracy: 0.2060\n",
            "Epoch 708/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3355 - accuracy: 0.2330 - val_loss: 2.5589 - val_accuracy: 0.1999\n",
            "Epoch 709/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3380 - accuracy: 0.2323 - val_loss: 2.4561 - val_accuracy: 0.2204\n",
            "Epoch 710/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3372 - accuracy: 0.2329 - val_loss: 2.4789 - val_accuracy: 0.2134\n",
            "Epoch 711/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3379 - accuracy: 0.2352 - val_loss: 2.5136 - val_accuracy: 0.1816\n",
            "Epoch 712/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3375 - accuracy: 0.2325 - val_loss: 2.4671 - val_accuracy: 0.2270\n",
            "Epoch 713/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3368 - accuracy: 0.2355 - val_loss: 2.5220 - val_accuracy: 0.1798\n",
            "Epoch 714/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3327 - accuracy: 0.2363 - val_loss: 2.4677 - val_accuracy: 0.2082\n",
            "Epoch 715/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3323 - accuracy: 0.2360 - val_loss: 2.5755 - val_accuracy: 0.1759\n",
            "Epoch 716/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3388 - accuracy: 0.2314 - val_loss: 2.4987 - val_accuracy: 0.2121\n",
            "Epoch 717/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3362 - accuracy: 0.2356 - val_loss: 2.4734 - val_accuracy: 0.2117\n",
            "Epoch 718/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3328 - accuracy: 0.2337 - val_loss: 2.4904 - val_accuracy: 0.2043\n",
            "Epoch 719/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3338 - accuracy: 0.2360 - val_loss: 2.4853 - val_accuracy: 0.1925\n",
            "Epoch 720/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3336 - accuracy: 0.2343 - val_loss: 2.4947 - val_accuracy: 0.1733\n",
            "Epoch 721/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3327 - accuracy: 0.2333 - val_loss: 2.4807 - val_accuracy: 0.2038\n",
            "Epoch 722/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3308 - accuracy: 0.2379 - val_loss: 2.4878 - val_accuracy: 0.1964\n",
            "Epoch 723/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3305 - accuracy: 0.2342 - val_loss: 2.4985 - val_accuracy: 0.1942\n",
            "Epoch 724/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3331 - accuracy: 0.2353 - val_loss: 2.5479 - val_accuracy: 0.1798\n",
            "Epoch 725/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3285 - accuracy: 0.2358 - val_loss: 2.5035 - val_accuracy: 0.1733\n",
            "Epoch 726/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3352 - accuracy: 0.2327 - val_loss: 2.4704 - val_accuracy: 0.2065\n",
            "Epoch 727/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3331 - accuracy: 0.2343 - val_loss: 2.4699 - val_accuracy: 0.2148\n",
            "Epoch 728/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3347 - accuracy: 0.2332 - val_loss: 2.4999 - val_accuracy: 0.2030\n",
            "Epoch 729/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3323 - accuracy: 0.2361 - val_loss: 2.4779 - val_accuracy: 0.2073\n",
            "Epoch 730/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3280 - accuracy: 0.2387 - val_loss: 2.4629 - val_accuracy: 0.2305\n",
            "Epoch 731/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3309 - accuracy: 0.2350 - val_loss: 2.5282 - val_accuracy: 0.1934\n",
            "Epoch 732/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3305 - accuracy: 0.2354 - val_loss: 2.4880 - val_accuracy: 0.2008\n",
            "Epoch 733/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3279 - accuracy: 0.2330 - val_loss: 2.5463 - val_accuracy: 0.1742\n",
            "Epoch 734/10000\n",
            "453/453 [==============================] - 3s 8ms/step - loss: 2.3242 - accuracy: 0.2368 - val_loss: 2.4782 - val_accuracy: 0.2017\n",
            "Epoch 735/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3313 - accuracy: 0.2361 - val_loss: 2.4738 - val_accuracy: 0.2130\n",
            "Epoch 736/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3311 - accuracy: 0.2343 - val_loss: 2.4843 - val_accuracy: 0.2156\n",
            "Epoch 737/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3261 - accuracy: 0.2356 - val_loss: 2.4905 - val_accuracy: 0.1938\n",
            "Epoch 738/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3262 - accuracy: 0.2352 - val_loss: 2.5061 - val_accuracy: 0.1798\n",
            "Epoch 739/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3230 - accuracy: 0.2383 - val_loss: 2.4805 - val_accuracy: 0.2161\n",
            "Epoch 740/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3257 - accuracy: 0.2357 - val_loss: 2.5212 - val_accuracy: 0.1772\n",
            "Epoch 741/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3312 - accuracy: 0.2336 - val_loss: 2.4898 - val_accuracy: 0.2021\n",
            "Epoch 742/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3296 - accuracy: 0.2358 - val_loss: 2.5688 - val_accuracy: 0.1724\n",
            "Epoch 743/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3339 - accuracy: 0.2338 - val_loss: 2.4535 - val_accuracy: 0.2143\n",
            "Epoch 744/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.3238 - accuracy: 0.2367 - val_loss: 2.4896 - val_accuracy: 0.2003\n",
            "Epoch 745/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3213 - accuracy: 0.2381 - val_loss: 2.4680 - val_accuracy: 0.2073\n",
            "Epoch 746/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.3221 - accuracy: 0.2381 - val_loss: 2.4601 - val_accuracy: 0.2178\n",
            "Epoch 747/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3253 - accuracy: 0.2369 - val_loss: 2.4611 - val_accuracy: 0.2117\n",
            "Epoch 748/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3198 - accuracy: 0.2378 - val_loss: 2.4517 - val_accuracy: 0.2174\n",
            "Epoch 749/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3191 - accuracy: 0.2378 - val_loss: 2.5406 - val_accuracy: 0.1846\n",
            "Epoch 750/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3269 - accuracy: 0.2359 - val_loss: 2.4523 - val_accuracy: 0.2065\n",
            "Epoch 751/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3245 - accuracy: 0.2354 - val_loss: 2.4479 - val_accuracy: 0.2230\n",
            "Epoch 752/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3228 - accuracy: 0.2348 - val_loss: 2.4463 - val_accuracy: 0.2261\n",
            "Epoch 753/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3234 - accuracy: 0.2356 - val_loss: 2.5215 - val_accuracy: 0.1798\n",
            "Epoch 754/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3301 - accuracy: 0.2336 - val_loss: 2.4496 - val_accuracy: 0.2161\n",
            "Epoch 755/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3205 - accuracy: 0.2375 - val_loss: 2.4774 - val_accuracy: 0.2008\n",
            "Epoch 756/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3241 - accuracy: 0.2359 - val_loss: 2.4460 - val_accuracy: 0.2252\n",
            "Epoch 757/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3219 - accuracy: 0.2359 - val_loss: 2.4815 - val_accuracy: 0.1942\n",
            "Epoch 758/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3210 - accuracy: 0.2343 - val_loss: 2.4828 - val_accuracy: 0.1977\n",
            "Epoch 759/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3191 - accuracy: 0.2357 - val_loss: 2.4616 - val_accuracy: 0.2038\n",
            "Epoch 760/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3286 - accuracy: 0.2358 - val_loss: 2.4475 - val_accuracy: 0.2130\n",
            "Epoch 761/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3261 - accuracy: 0.2348 - val_loss: 2.5008 - val_accuracy: 0.2121\n",
            "Epoch 762/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3227 - accuracy: 0.2356 - val_loss: 2.4526 - val_accuracy: 0.2148\n",
            "Epoch 763/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3180 - accuracy: 0.2382 - val_loss: 2.4694 - val_accuracy: 0.1986\n",
            "Epoch 764/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3201 - accuracy: 0.2331 - val_loss: 2.4460 - val_accuracy: 0.2169\n",
            "Epoch 765/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3180 - accuracy: 0.2388 - val_loss: 2.4426 - val_accuracy: 0.2274\n",
            "Epoch 766/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3190 - accuracy: 0.2378 - val_loss: 2.4984 - val_accuracy: 0.1851\n",
            "Epoch 767/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3176 - accuracy: 0.2390 - val_loss: 2.4517 - val_accuracy: 0.2292\n",
            "Epoch 768/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3183 - accuracy: 0.2339 - val_loss: 2.4672 - val_accuracy: 0.2130\n",
            "Epoch 769/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3161 - accuracy: 0.2370 - val_loss: 2.4546 - val_accuracy: 0.2047\n",
            "Epoch 770/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3159 - accuracy: 0.2388 - val_loss: 2.4723 - val_accuracy: 0.2091\n",
            "Epoch 771/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3182 - accuracy: 0.2382 - val_loss: 2.4692 - val_accuracy: 0.2008\n",
            "Epoch 772/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3169 - accuracy: 0.2364 - val_loss: 2.4516 - val_accuracy: 0.2196\n",
            "Epoch 773/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3198 - accuracy: 0.2374 - val_loss: 2.4407 - val_accuracy: 0.2082\n",
            "Epoch 774/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3227 - accuracy: 0.2381 - val_loss: 2.4436 - val_accuracy: 0.1995\n",
            "Epoch 775/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3160 - accuracy: 0.2369 - val_loss: 2.4485 - val_accuracy: 0.2169\n",
            "Epoch 776/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3173 - accuracy: 0.2387 - val_loss: 2.6021 - val_accuracy: 0.1554\n",
            "Epoch 777/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3183 - accuracy: 0.2360 - val_loss: 2.4507 - val_accuracy: 0.2235\n",
            "Epoch 778/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3180 - accuracy: 0.2363 - val_loss: 2.4835 - val_accuracy: 0.2052\n",
            "Epoch 779/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3065 - accuracy: 0.2425 - val_loss: 2.5009 - val_accuracy: 0.1999\n",
            "Epoch 780/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3146 - accuracy: 0.2389 - val_loss: 2.4802 - val_accuracy: 0.2047\n",
            "Epoch 781/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3149 - accuracy: 0.2379 - val_loss: 2.5203 - val_accuracy: 0.1724\n",
            "Epoch 782/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3177 - accuracy: 0.2343 - val_loss: 2.4293 - val_accuracy: 0.2187\n",
            "Epoch 783/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3203 - accuracy: 0.2383 - val_loss: 2.4335 - val_accuracy: 0.2169\n",
            "Epoch 784/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3127 - accuracy: 0.2381 - val_loss: 2.4935 - val_accuracy: 0.2082\n",
            "Epoch 785/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3103 - accuracy: 0.2382 - val_loss: 2.4356 - val_accuracy: 0.2296\n",
            "Epoch 786/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3123 - accuracy: 0.2388 - val_loss: 2.4824 - val_accuracy: 0.1925\n",
            "Epoch 787/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3164 - accuracy: 0.2373 - val_loss: 2.4594 - val_accuracy: 0.2008\n",
            "Epoch 788/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.3167 - accuracy: 0.2355 - val_loss: 2.4191 - val_accuracy: 0.2344\n",
            "Epoch 789/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.3110 - accuracy: 0.2370 - val_loss: 2.4315 - val_accuracy: 0.2235\n",
            "Epoch 790/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.3106 - accuracy: 0.2398 - val_loss: 2.4262 - val_accuracy: 0.2235\n",
            "Epoch 791/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3113 - accuracy: 0.2369 - val_loss: 2.4464 - val_accuracy: 0.2069\n",
            "Epoch 792/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3162 - accuracy: 0.2345 - val_loss: 2.4398 - val_accuracy: 0.2169\n",
            "Epoch 793/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3185 - accuracy: 0.2358 - val_loss: 2.4703 - val_accuracy: 0.2209\n",
            "Epoch 794/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3115 - accuracy: 0.2381 - val_loss: 2.5008 - val_accuracy: 0.1807\n",
            "Epoch 795/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3125 - accuracy: 0.2393 - val_loss: 2.4312 - val_accuracy: 0.2287\n",
            "Epoch 796/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3063 - accuracy: 0.2401 - val_loss: 2.4821 - val_accuracy: 0.2104\n",
            "Epoch 797/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3051 - accuracy: 0.2384 - val_loss: 2.4842 - val_accuracy: 0.1977\n",
            "Epoch 798/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3075 - accuracy: 0.2391 - val_loss: 2.4332 - val_accuracy: 0.2261\n",
            "Epoch 799/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3102 - accuracy: 0.2383 - val_loss: 2.4696 - val_accuracy: 0.2012\n",
            "Epoch 800/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3124 - accuracy: 0.2387 - val_loss: 2.5516 - val_accuracy: 0.1663\n",
            "Epoch 801/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3077 - accuracy: 0.2406 - val_loss: 2.4518 - val_accuracy: 0.2300\n",
            "Epoch 802/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3076 - accuracy: 0.2416 - val_loss: 2.4302 - val_accuracy: 0.2261\n",
            "Epoch 803/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3069 - accuracy: 0.2398 - val_loss: 2.4361 - val_accuracy: 0.2169\n",
            "Epoch 804/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3119 - accuracy: 0.2354 - val_loss: 2.5073 - val_accuracy: 0.1964\n",
            "Epoch 805/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3155 - accuracy: 0.2375 - val_loss: 2.4596 - val_accuracy: 0.2169\n",
            "Epoch 806/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3069 - accuracy: 0.2378 - val_loss: 2.4752 - val_accuracy: 0.1951\n",
            "Epoch 807/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3073 - accuracy: 0.2385 - val_loss: 2.4175 - val_accuracy: 0.2230\n",
            "Epoch 808/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3016 - accuracy: 0.2422 - val_loss: 2.5025 - val_accuracy: 0.2095\n",
            "Epoch 809/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.3072 - accuracy: 0.2376 - val_loss: 2.4567 - val_accuracy: 0.1851\n",
            "Epoch 810/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3103 - accuracy: 0.2385 - val_loss: 2.4290 - val_accuracy: 0.2204\n",
            "Epoch 811/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3032 - accuracy: 0.2395 - val_loss: 2.4365 - val_accuracy: 0.2156\n",
            "Epoch 812/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3076 - accuracy: 0.2416 - val_loss: 2.4594 - val_accuracy: 0.2156\n",
            "Epoch 813/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3029 - accuracy: 0.2397 - val_loss: 2.4137 - val_accuracy: 0.2370\n",
            "Epoch 814/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3074 - accuracy: 0.2383 - val_loss: 2.4284 - val_accuracy: 0.2265\n",
            "Epoch 815/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3081 - accuracy: 0.2374 - val_loss: 2.4336 - val_accuracy: 0.2244\n",
            "Epoch 816/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3072 - accuracy: 0.2378 - val_loss: 2.4850 - val_accuracy: 0.1907\n",
            "Epoch 817/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3029 - accuracy: 0.2427 - val_loss: 2.4837 - val_accuracy: 0.1995\n",
            "Epoch 818/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3038 - accuracy: 0.2395 - val_loss: 2.4220 - val_accuracy: 0.2261\n",
            "Epoch 819/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3013 - accuracy: 0.2407 - val_loss: 2.4299 - val_accuracy: 0.2335\n",
            "Epoch 820/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3062 - accuracy: 0.2401 - val_loss: 2.4440 - val_accuracy: 0.2283\n",
            "Epoch 821/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3041 - accuracy: 0.2394 - val_loss: 2.4769 - val_accuracy: 0.2082\n",
            "Epoch 822/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3065 - accuracy: 0.2360 - val_loss: 2.4567 - val_accuracy: 0.2038\n",
            "Epoch 823/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.3076 - accuracy: 0.2386 - val_loss: 2.5611 - val_accuracy: 0.1742\n",
            "Epoch 824/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3028 - accuracy: 0.2406 - val_loss: 2.4513 - val_accuracy: 0.2161\n",
            "Epoch 825/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3105 - accuracy: 0.2368 - val_loss: 2.4832 - val_accuracy: 0.1934\n",
            "Epoch 826/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3016 - accuracy: 0.2402 - val_loss: 2.4660 - val_accuracy: 0.2043\n",
            "Epoch 827/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3033 - accuracy: 0.2429 - val_loss: 2.4664 - val_accuracy: 0.2235\n",
            "Epoch 828/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3049 - accuracy: 0.2399 - val_loss: 2.4422 - val_accuracy: 0.2126\n",
            "Epoch 829/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3011 - accuracy: 0.2412 - val_loss: 2.4569 - val_accuracy: 0.2165\n",
            "Epoch 830/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2983 - accuracy: 0.2424 - val_loss: 2.4356 - val_accuracy: 0.2156\n",
            "Epoch 831/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3033 - accuracy: 0.2418 - val_loss: 2.4572 - val_accuracy: 0.2030\n",
            "Epoch 832/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3028 - accuracy: 0.2396 - val_loss: 2.4554 - val_accuracy: 0.2187\n",
            "Epoch 833/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2985 - accuracy: 0.2423 - val_loss: 2.4209 - val_accuracy: 0.2261\n",
            "Epoch 834/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2995 - accuracy: 0.2402 - val_loss: 2.4334 - val_accuracy: 0.2143\n",
            "Epoch 835/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2998 - accuracy: 0.2438 - val_loss: 2.5489 - val_accuracy: 0.1689\n",
            "Epoch 836/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.2397 - val_loss: 2.4471 - val_accuracy: 0.2187\n",
            "Epoch 837/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3042 - accuracy: 0.2369 - val_loss: 2.4124 - val_accuracy: 0.2405\n",
            "Epoch 838/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2976 - accuracy: 0.2409 - val_loss: 2.4373 - val_accuracy: 0.2296\n",
            "Epoch 839/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.3010 - accuracy: 0.2423 - val_loss: 2.4476 - val_accuracy: 0.2191\n",
            "Epoch 840/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2995 - accuracy: 0.2400 - val_loss: 2.4249 - val_accuracy: 0.2318\n",
            "Epoch 841/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3037 - accuracy: 0.2402 - val_loss: 2.4497 - val_accuracy: 0.2182\n",
            "Epoch 842/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2981 - accuracy: 0.2421 - val_loss: 2.4388 - val_accuracy: 0.2165\n",
            "Epoch 843/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2980 - accuracy: 0.2427 - val_loss: 2.5346 - val_accuracy: 0.1921\n",
            "Epoch 844/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2986 - accuracy: 0.2424 - val_loss: 2.4291 - val_accuracy: 0.2091\n",
            "Epoch 845/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3031 - accuracy: 0.2408 - val_loss: 2.4520 - val_accuracy: 0.2108\n",
            "Epoch 846/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2960 - accuracy: 0.2403 - val_loss: 2.4246 - val_accuracy: 0.2283\n",
            "Epoch 847/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3024 - accuracy: 0.2400 - val_loss: 2.4624 - val_accuracy: 0.2182\n",
            "Epoch 848/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3017 - accuracy: 0.2390 - val_loss: 2.4428 - val_accuracy: 0.2121\n",
            "Epoch 849/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2975 - accuracy: 0.2411 - val_loss: 2.4232 - val_accuracy: 0.2169\n",
            "Epoch 850/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3025 - accuracy: 0.2397 - val_loss: 2.4416 - val_accuracy: 0.2108\n",
            "Epoch 851/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2952 - accuracy: 0.2429 - val_loss: 2.4433 - val_accuracy: 0.2222\n",
            "Epoch 852/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2923 - accuracy: 0.2443 - val_loss: 2.4734 - val_accuracy: 0.2191\n",
            "Epoch 853/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3104 - accuracy: 0.2361 - val_loss: 2.4107 - val_accuracy: 0.2375\n",
            "Epoch 854/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2991 - accuracy: 0.2406 - val_loss: 2.4381 - val_accuracy: 0.2213\n",
            "Epoch 855/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2968 - accuracy: 0.2412 - val_loss: 2.4222 - val_accuracy: 0.2261\n",
            "Epoch 856/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2986 - accuracy: 0.2396 - val_loss: 2.4134 - val_accuracy: 0.2148\n",
            "Epoch 857/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2943 - accuracy: 0.2414 - val_loss: 2.4081 - val_accuracy: 0.2423\n",
            "Epoch 858/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2990 - accuracy: 0.2411 - val_loss: 2.4162 - val_accuracy: 0.2361\n",
            "Epoch 859/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2946 - accuracy: 0.2417 - val_loss: 2.4392 - val_accuracy: 0.2213\n",
            "Epoch 860/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.3036 - accuracy: 0.2389 - val_loss: 2.4256 - val_accuracy: 0.2222\n",
            "Epoch 861/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2913 - accuracy: 0.2446 - val_loss: 2.4725 - val_accuracy: 0.2182\n",
            "Epoch 862/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2942 - accuracy: 0.2437 - val_loss: 2.4269 - val_accuracy: 0.2296\n",
            "Epoch 863/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2914 - accuracy: 0.2434 - val_loss: 2.4386 - val_accuracy: 0.2117\n",
            "Epoch 864/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2972 - accuracy: 0.2381 - val_loss: 2.4199 - val_accuracy: 0.2361\n",
            "Epoch 865/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2944 - accuracy: 0.2425 - val_loss: 2.4326 - val_accuracy: 0.2318\n",
            "Epoch 866/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2972 - accuracy: 0.2418 - val_loss: 2.4388 - val_accuracy: 0.2226\n",
            "Epoch 867/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2995 - accuracy: 0.2401 - val_loss: 2.4044 - val_accuracy: 0.2209\n",
            "Epoch 868/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.3011 - accuracy: 0.2412 - val_loss: 2.4296 - val_accuracy: 0.2239\n",
            "Epoch 869/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2992 - accuracy: 0.2403 - val_loss: 2.4874 - val_accuracy: 0.1907\n",
            "Epoch 870/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2925 - accuracy: 0.2421 - val_loss: 2.4202 - val_accuracy: 0.2257\n",
            "Epoch 871/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2930 - accuracy: 0.2429 - val_loss: 2.4348 - val_accuracy: 0.2152\n",
            "Epoch 872/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2927 - accuracy: 0.2410 - val_loss: 2.4802 - val_accuracy: 0.1899\n",
            "Epoch 873/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2947 - accuracy: 0.2415 - val_loss: 2.4054 - val_accuracy: 0.2383\n",
            "Epoch 874/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3037 - accuracy: 0.2393 - val_loss: 2.4495 - val_accuracy: 0.2003\n",
            "Epoch 875/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2969 - accuracy: 0.2412 - val_loss: 2.4459 - val_accuracy: 0.2065\n",
            "Epoch 876/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2983 - accuracy: 0.2392 - val_loss: 2.4172 - val_accuracy: 0.2226\n",
            "Epoch 877/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2940 - accuracy: 0.2428 - val_loss: 2.4362 - val_accuracy: 0.2174\n",
            "Epoch 878/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2921 - accuracy: 0.2411 - val_loss: 2.4495 - val_accuracy: 0.2178\n",
            "Epoch 879/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2919 - accuracy: 0.2418 - val_loss: 2.4443 - val_accuracy: 0.2209\n",
            "Epoch 880/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2966 - accuracy: 0.2422 - val_loss: 2.4185 - val_accuracy: 0.2274\n",
            "Epoch 881/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2931 - accuracy: 0.2396 - val_loss: 2.4191 - val_accuracy: 0.2134\n",
            "Epoch 882/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2872 - accuracy: 0.2442 - val_loss: 2.4357 - val_accuracy: 0.2204\n",
            "Epoch 883/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2869 - accuracy: 0.2430 - val_loss: 2.4303 - val_accuracy: 0.2261\n",
            "Epoch 884/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2887 - accuracy: 0.2447 - val_loss: 2.4469 - val_accuracy: 0.2252\n",
            "Epoch 885/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2911 - accuracy: 0.2441 - val_loss: 2.4081 - val_accuracy: 0.2252\n",
            "Epoch 886/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2909 - accuracy: 0.2435 - val_loss: 2.4459 - val_accuracy: 0.2261\n",
            "Epoch 887/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2919 - accuracy: 0.2401 - val_loss: 2.4267 - val_accuracy: 0.2165\n",
            "Epoch 888/10000\n",
            "453/453 [==============================] - 7s 16ms/step - loss: 2.2874 - accuracy: 0.2442 - val_loss: 2.4106 - val_accuracy: 0.2401\n",
            "Epoch 889/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2872 - accuracy: 0.2411 - val_loss: 2.4795 - val_accuracy: 0.2069\n",
            "Epoch 890/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2906 - accuracy: 0.2400 - val_loss: 2.5344 - val_accuracy: 0.1838\n",
            "Epoch 891/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2909 - accuracy: 0.2415 - val_loss: 2.4159 - val_accuracy: 0.2226\n",
            "Epoch 892/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2975 - accuracy: 0.2403 - val_loss: 2.4340 - val_accuracy: 0.2261\n",
            "Epoch 893/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2858 - accuracy: 0.2444 - val_loss: 2.4237 - val_accuracy: 0.2230\n",
            "Epoch 894/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2837 - accuracy: 0.2452 - val_loss: 2.5301 - val_accuracy: 0.1925\n",
            "Epoch 895/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2889 - accuracy: 0.2457 - val_loss: 2.4296 - val_accuracy: 0.2156\n",
            "Epoch 896/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2858 - accuracy: 0.2444 - val_loss: 2.4255 - val_accuracy: 0.2292\n",
            "Epoch 897/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2880 - accuracy: 0.2422 - val_loss: 2.4642 - val_accuracy: 0.1960\n",
            "Epoch 898/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.2364 - val_loss: 2.4031 - val_accuracy: 0.2292\n",
            "Epoch 899/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2911 - accuracy: 0.2435 - val_loss: 2.5614 - val_accuracy: 0.1846\n",
            "Epoch 900/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2853 - accuracy: 0.2440 - val_loss: 2.4770 - val_accuracy: 0.2152\n",
            "Epoch 901/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2916 - accuracy: 0.2422 - val_loss: 2.4623 - val_accuracy: 0.2152\n",
            "Epoch 902/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2859 - accuracy: 0.2433 - val_loss: 2.4109 - val_accuracy: 0.2388\n",
            "Epoch 903/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2856 - accuracy: 0.2434 - val_loss: 2.4098 - val_accuracy: 0.2283\n",
            "Epoch 904/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2882 - accuracy: 0.2404 - val_loss: 2.4112 - val_accuracy: 0.2283\n",
            "Epoch 905/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2902 - accuracy: 0.2421 - val_loss: 2.4223 - val_accuracy: 0.2396\n",
            "Epoch 906/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2812 - accuracy: 0.2450 - val_loss: 2.4121 - val_accuracy: 0.2244\n",
            "Epoch 907/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2875 - accuracy: 0.2429 - val_loss: 2.4241 - val_accuracy: 0.2191\n",
            "Epoch 908/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2873 - accuracy: 0.2396 - val_loss: 2.4218 - val_accuracy: 0.2230\n",
            "Epoch 909/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2857 - accuracy: 0.2423 - val_loss: 2.4025 - val_accuracy: 0.2257\n",
            "Epoch 910/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2869 - accuracy: 0.2429 - val_loss: 2.4607 - val_accuracy: 0.2200\n",
            "Epoch 911/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2863 - accuracy: 0.2450 - val_loss: 2.4102 - val_accuracy: 0.2318\n",
            "Epoch 912/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2834 - accuracy: 0.2429 - val_loss: 2.4393 - val_accuracy: 0.2143\n",
            "Epoch 913/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2913 - accuracy: 0.2421 - val_loss: 2.4263 - val_accuracy: 0.2182\n",
            "Epoch 914/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2793 - accuracy: 0.2458 - val_loss: 2.4261 - val_accuracy: 0.2335\n",
            "Epoch 915/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2884 - accuracy: 0.2422 - val_loss: 2.4362 - val_accuracy: 0.2091\n",
            "Epoch 916/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2867 - accuracy: 0.2438 - val_loss: 2.4424 - val_accuracy: 0.2165\n",
            "Epoch 917/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2827 - accuracy: 0.2442 - val_loss: 2.4825 - val_accuracy: 0.2069\n",
            "Epoch 918/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2882 - accuracy: 0.2418 - val_loss: 2.4687 - val_accuracy: 0.1955\n",
            "Epoch 919/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2947 - accuracy: 0.2409 - val_loss: 2.4646 - val_accuracy: 0.2152\n",
            "Epoch 920/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2863 - accuracy: 0.2437 - val_loss: 2.4178 - val_accuracy: 0.2165\n",
            "Epoch 921/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2814 - accuracy: 0.2434 - val_loss: 2.4371 - val_accuracy: 0.2257\n",
            "Epoch 922/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2839 - accuracy: 0.2436 - val_loss: 2.3996 - val_accuracy: 0.2340\n",
            "Epoch 923/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2863 - accuracy: 0.2427 - val_loss: 2.4157 - val_accuracy: 0.2178\n",
            "Epoch 924/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2812 - accuracy: 0.2458 - val_loss: 2.4355 - val_accuracy: 0.2252\n",
            "Epoch 925/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2840 - accuracy: 0.2418 - val_loss: 2.4320 - val_accuracy: 0.2318\n",
            "Epoch 926/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2819 - accuracy: 0.2456 - val_loss: 2.4254 - val_accuracy: 0.2152\n",
            "Epoch 927/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2823 - accuracy: 0.2444 - val_loss: 2.5317 - val_accuracy: 0.1890\n",
            "Epoch 928/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2809 - accuracy: 0.2431 - val_loss: 2.4309 - val_accuracy: 0.2108\n",
            "Epoch 929/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2830 - accuracy: 0.2426 - val_loss: 2.3978 - val_accuracy: 0.2340\n",
            "Epoch 930/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2856 - accuracy: 0.2415 - val_loss: 2.4169 - val_accuracy: 0.2274\n",
            "Epoch 931/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2893 - accuracy: 0.2419 - val_loss: 2.4143 - val_accuracy: 0.2222\n",
            "Epoch 932/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2780 - accuracy: 0.2468 - val_loss: 2.4412 - val_accuracy: 0.2121\n",
            "Epoch 933/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2861 - accuracy: 0.2387 - val_loss: 2.3856 - val_accuracy: 0.2431\n",
            "Epoch 934/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2864 - accuracy: 0.2405 - val_loss: 2.4114 - val_accuracy: 0.2309\n",
            "Epoch 935/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2830 - accuracy: 0.2441 - val_loss: 2.4075 - val_accuracy: 0.2326\n",
            "Epoch 936/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2822 - accuracy: 0.2436 - val_loss: 2.4098 - val_accuracy: 0.2353\n",
            "Epoch 937/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2792 - accuracy: 0.2467 - val_loss: 2.4101 - val_accuracy: 0.2309\n",
            "Epoch 938/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2765 - accuracy: 0.2463 - val_loss: 2.3944 - val_accuracy: 0.2335\n",
            "Epoch 939/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2880 - accuracy: 0.2408 - val_loss: 2.3910 - val_accuracy: 0.2462\n",
            "Epoch 940/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2803 - accuracy: 0.2444 - val_loss: 2.4226 - val_accuracy: 0.2235\n",
            "Epoch 941/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2754 - accuracy: 0.2457 - val_loss: 2.3986 - val_accuracy: 0.2449\n",
            "Epoch 942/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2833 - accuracy: 0.2423 - val_loss: 2.4380 - val_accuracy: 0.2038\n",
            "Epoch 943/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2800 - accuracy: 0.2437 - val_loss: 2.4502 - val_accuracy: 0.2196\n",
            "Epoch 944/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2826 - accuracy: 0.2432 - val_loss: 2.4470 - val_accuracy: 0.2143\n",
            "Epoch 945/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2856 - accuracy: 0.2398 - val_loss: 2.4066 - val_accuracy: 0.2178\n",
            "Epoch 946/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2746 - accuracy: 0.2459 - val_loss: 2.4381 - val_accuracy: 0.2012\n",
            "Epoch 947/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2779 - accuracy: 0.2451 - val_loss: 2.3947 - val_accuracy: 0.2462\n",
            "Epoch 948/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2799 - accuracy: 0.2444 - val_loss: 2.4138 - val_accuracy: 0.2318\n",
            "Epoch 949/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2835 - accuracy: 0.2421 - val_loss: 2.3860 - val_accuracy: 0.2396\n",
            "Epoch 950/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2802 - accuracy: 0.2452 - val_loss: 2.4112 - val_accuracy: 0.2292\n",
            "Epoch 951/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2760 - accuracy: 0.2473 - val_loss: 2.4694 - val_accuracy: 0.2060\n",
            "Epoch 952/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2831 - accuracy: 0.2439 - val_loss: 2.4576 - val_accuracy: 0.2182\n",
            "Epoch 953/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2823 - accuracy: 0.2454 - val_loss: 2.4353 - val_accuracy: 0.2191\n",
            "Epoch 954/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2745 - accuracy: 0.2454 - val_loss: 2.4425 - val_accuracy: 0.2182\n",
            "Epoch 955/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2889 - accuracy: 0.2404 - val_loss: 2.3974 - val_accuracy: 0.2375\n",
            "Epoch 956/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2850 - accuracy: 0.2423 - val_loss: 2.4090 - val_accuracy: 0.2213\n",
            "Epoch 957/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2795 - accuracy: 0.2441 - val_loss: 2.3948 - val_accuracy: 0.2366\n",
            "Epoch 958/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2791 - accuracy: 0.2441 - val_loss: 2.4904 - val_accuracy: 0.1951\n",
            "Epoch 959/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2794 - accuracy: 0.2453 - val_loss: 2.4146 - val_accuracy: 0.2235\n",
            "Epoch 960/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2779 - accuracy: 0.2424 - val_loss: 2.3900 - val_accuracy: 0.2409\n",
            "Epoch 961/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2828 - accuracy: 0.2432 - val_loss: 2.4005 - val_accuracy: 0.2357\n",
            "Epoch 962/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2769 - accuracy: 0.2421 - val_loss: 2.4367 - val_accuracy: 0.2091\n",
            "Epoch 963/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2769 - accuracy: 0.2442 - val_loss: 2.3959 - val_accuracy: 0.2344\n",
            "Epoch 964/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2751 - accuracy: 0.2479 - val_loss: 2.4118 - val_accuracy: 0.2148\n",
            "Epoch 965/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2777 - accuracy: 0.2441 - val_loss: 2.4058 - val_accuracy: 0.2274\n",
            "Epoch 966/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2806 - accuracy: 0.2447 - val_loss: 2.4865 - val_accuracy: 0.1916\n",
            "Epoch 967/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2765 - accuracy: 0.2462 - val_loss: 2.4421 - val_accuracy: 0.2017\n",
            "Epoch 968/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2742 - accuracy: 0.2472 - val_loss: 2.4142 - val_accuracy: 0.2100\n",
            "Epoch 969/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2802 - accuracy: 0.2414 - val_loss: 2.4593 - val_accuracy: 0.2278\n",
            "Epoch 970/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2771 - accuracy: 0.2457 - val_loss: 2.4190 - val_accuracy: 0.2296\n",
            "Epoch 971/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2708 - accuracy: 0.2486 - val_loss: 2.4224 - val_accuracy: 0.2200\n",
            "Epoch 972/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2748 - accuracy: 0.2453 - val_loss: 2.4109 - val_accuracy: 0.2309\n",
            "Epoch 973/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2716 - accuracy: 0.2432 - val_loss: 2.4526 - val_accuracy: 0.2322\n",
            "Epoch 974/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2792 - accuracy: 0.2439 - val_loss: 2.4075 - val_accuracy: 0.2436\n",
            "Epoch 975/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2735 - accuracy: 0.2460 - val_loss: 2.4136 - val_accuracy: 0.2239\n",
            "Epoch 976/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2756 - accuracy: 0.2457 - val_loss: 2.4029 - val_accuracy: 0.2300\n",
            "Epoch 977/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2802 - accuracy: 0.2444 - val_loss: 2.4809 - val_accuracy: 0.2174\n",
            "Epoch 978/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2732 - accuracy: 0.2475 - val_loss: 2.4380 - val_accuracy: 0.1990\n",
            "Epoch 979/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2793 - accuracy: 0.2422 - val_loss: 2.4479 - val_accuracy: 0.2257\n",
            "Epoch 980/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2716 - accuracy: 0.2456 - val_loss: 2.3990 - val_accuracy: 0.2287\n",
            "Epoch 981/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2763 - accuracy: 0.2432 - val_loss: 2.4188 - val_accuracy: 0.2239\n",
            "Epoch 982/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2791 - accuracy: 0.2437 - val_loss: 2.4324 - val_accuracy: 0.2196\n",
            "Epoch 983/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2719 - accuracy: 0.2476 - val_loss: 2.4634 - val_accuracy: 0.2003\n",
            "Epoch 984/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2712 - accuracy: 0.2460 - val_loss: 2.4135 - val_accuracy: 0.2200\n",
            "Epoch 985/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2750 - accuracy: 0.2444 - val_loss: 2.4699 - val_accuracy: 0.2012\n",
            "Epoch 986/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2714 - accuracy: 0.2488 - val_loss: 2.4506 - val_accuracy: 0.2003\n",
            "Epoch 987/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2794 - accuracy: 0.2401 - val_loss: 2.4035 - val_accuracy: 0.2292\n",
            "Epoch 988/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2758 - accuracy: 0.2439 - val_loss: 2.3949 - val_accuracy: 0.2383\n",
            "Epoch 989/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2708 - accuracy: 0.2462 - val_loss: 2.4459 - val_accuracy: 0.2152\n",
            "Epoch 990/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2751 - accuracy: 0.2443 - val_loss: 2.4028 - val_accuracy: 0.2265\n",
            "Epoch 991/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2774 - accuracy: 0.2439 - val_loss: 2.4223 - val_accuracy: 0.2073\n",
            "Epoch 992/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2728 - accuracy: 0.2459 - val_loss: 2.4184 - val_accuracy: 0.2152\n",
            "Epoch 993/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2689 - accuracy: 0.2465 - val_loss: 2.4202 - val_accuracy: 0.2174\n",
            "Epoch 994/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2745 - accuracy: 0.2432 - val_loss: 2.4585 - val_accuracy: 0.2047\n",
            "Epoch 995/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2776 - accuracy: 0.2441 - val_loss: 2.4265 - val_accuracy: 0.2204\n",
            "Epoch 996/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2679 - accuracy: 0.2469 - val_loss: 2.3980 - val_accuracy: 0.2182\n",
            "Epoch 997/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2732 - accuracy: 0.2447 - val_loss: 2.5626 - val_accuracy: 0.1742\n",
            "Epoch 998/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2721 - accuracy: 0.2439 - val_loss: 2.3995 - val_accuracy: 0.2305\n",
            "Epoch 999/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2662 - accuracy: 0.2494 - val_loss: 2.4053 - val_accuracy: 0.2252\n",
            "Epoch 1000/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2727 - accuracy: 0.2448 - val_loss: 2.4246 - val_accuracy: 0.2292\n",
            "Epoch 1001/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2660 - accuracy: 0.2473 - val_loss: 2.4002 - val_accuracy: 0.2344\n",
            "Epoch 1002/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2673 - accuracy: 0.2480 - val_loss: 2.4074 - val_accuracy: 0.2265\n",
            "Epoch 1003/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2723 - accuracy: 0.2449 - val_loss: 2.3925 - val_accuracy: 0.2244\n",
            "Epoch 1004/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2665 - accuracy: 0.2469 - val_loss: 2.3981 - val_accuracy: 0.2274\n",
            "Epoch 1005/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2756 - accuracy: 0.2453 - val_loss: 2.4545 - val_accuracy: 0.2017\n",
            "Epoch 1006/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2729 - accuracy: 0.2458 - val_loss: 2.3783 - val_accuracy: 0.2431\n",
            "Epoch 1007/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2722 - accuracy: 0.2455 - val_loss: 2.4546 - val_accuracy: 0.2217\n",
            "Epoch 1008/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2688 - accuracy: 0.2458 - val_loss: 2.4099 - val_accuracy: 0.2318\n",
            "Epoch 1009/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2722 - accuracy: 0.2436 - val_loss: 2.4018 - val_accuracy: 0.2418\n",
            "Epoch 1010/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2726 - accuracy: 0.2448 - val_loss: 2.4221 - val_accuracy: 0.2209\n",
            "Epoch 1011/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2695 - accuracy: 0.2446 - val_loss: 2.3920 - val_accuracy: 0.2335\n",
            "Epoch 1012/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2675 - accuracy: 0.2461 - val_loss: 2.4178 - val_accuracy: 0.2178\n",
            "Epoch 1013/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2731 - accuracy: 0.2444 - val_loss: 2.4814 - val_accuracy: 0.1899\n",
            "Epoch 1014/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2735 - accuracy: 0.2427 - val_loss: 2.4092 - val_accuracy: 0.2375\n",
            "Epoch 1015/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2669 - accuracy: 0.2478 - val_loss: 2.4544 - val_accuracy: 0.2060\n",
            "Epoch 1016/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2711 - accuracy: 0.2467 - val_loss: 2.4389 - val_accuracy: 0.2073\n",
            "Epoch 1017/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2660 - accuracy: 0.2465 - val_loss: 2.3848 - val_accuracy: 0.2401\n",
            "Epoch 1018/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2694 - accuracy: 0.2456 - val_loss: 2.3982 - val_accuracy: 0.2226\n",
            "Epoch 1019/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2640 - accuracy: 0.2466 - val_loss: 2.4013 - val_accuracy: 0.2248\n",
            "Epoch 1020/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2700 - accuracy: 0.2459 - val_loss: 2.4017 - val_accuracy: 0.2196\n",
            "Epoch 1021/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2685 - accuracy: 0.2456 - val_loss: 2.4058 - val_accuracy: 0.2296\n",
            "Epoch 1022/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2670 - accuracy: 0.2483 - val_loss: 2.4095 - val_accuracy: 0.2305\n",
            "Epoch 1023/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2694 - accuracy: 0.2450 - val_loss: 2.3896 - val_accuracy: 0.2497\n",
            "Epoch 1024/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2685 - accuracy: 0.2463 - val_loss: 2.4078 - val_accuracy: 0.2244\n",
            "Epoch 1025/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2723 - accuracy: 0.2455 - val_loss: 2.3917 - val_accuracy: 0.2278\n",
            "Epoch 1026/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2647 - accuracy: 0.2463 - val_loss: 2.3990 - val_accuracy: 0.2209\n",
            "Epoch 1027/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2675 - accuracy: 0.2462 - val_loss: 2.4518 - val_accuracy: 0.2134\n",
            "Epoch 1028/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2662 - accuracy: 0.2473 - val_loss: 2.3913 - val_accuracy: 0.2287\n",
            "Epoch 1029/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2703 - accuracy: 0.2457 - val_loss: 2.3806 - val_accuracy: 0.2361\n",
            "Epoch 1030/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2712 - accuracy: 0.2441 - val_loss: 2.4023 - val_accuracy: 0.2353\n",
            "Epoch 1031/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2668 - accuracy: 0.2468 - val_loss: 2.3940 - val_accuracy: 0.2278\n",
            "Epoch 1032/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2653 - accuracy: 0.2465 - val_loss: 2.3827 - val_accuracy: 0.2492\n",
            "Epoch 1033/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2663 - accuracy: 0.2468 - val_loss: 2.4017 - val_accuracy: 0.2292\n",
            "Epoch 1034/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2664 - accuracy: 0.2465 - val_loss: 2.4483 - val_accuracy: 0.2069\n",
            "Epoch 1035/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2646 - accuracy: 0.2471 - val_loss: 2.4374 - val_accuracy: 0.2313\n",
            "Epoch 1036/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2722 - accuracy: 0.2441 - val_loss: 2.4236 - val_accuracy: 0.2152\n",
            "Epoch 1037/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2674 - accuracy: 0.2457 - val_loss: 2.4151 - val_accuracy: 0.2292\n",
            "Epoch 1038/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2683 - accuracy: 0.2434 - val_loss: 2.3888 - val_accuracy: 0.2287\n",
            "Epoch 1039/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2702 - accuracy: 0.2469 - val_loss: 2.4147 - val_accuracy: 0.2305\n",
            "Epoch 1040/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2653 - accuracy: 0.2455 - val_loss: 2.3907 - val_accuracy: 0.2300\n",
            "Epoch 1041/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2610 - accuracy: 0.2508 - val_loss: 2.3825 - val_accuracy: 0.2414\n",
            "Epoch 1042/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2693 - accuracy: 0.2439 - val_loss: 2.4076 - val_accuracy: 0.2396\n",
            "Epoch 1043/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2771 - accuracy: 0.2427 - val_loss: 2.4001 - val_accuracy: 0.2270\n",
            "Epoch 1044/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2662 - accuracy: 0.2472 - val_loss: 2.4143 - val_accuracy: 0.2252\n",
            "Epoch 1045/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2649 - accuracy: 0.2489 - val_loss: 2.4046 - val_accuracy: 0.2261\n",
            "Epoch 1046/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2629 - accuracy: 0.2472 - val_loss: 2.4155 - val_accuracy: 0.2235\n",
            "Epoch 1047/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2698 - accuracy: 0.2466 - val_loss: 2.3975 - val_accuracy: 0.2257\n",
            "Epoch 1048/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2635 - accuracy: 0.2480 - val_loss: 2.4045 - val_accuracy: 0.2331\n",
            "Epoch 1049/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2672 - accuracy: 0.2457 - val_loss: 2.4293 - val_accuracy: 0.2178\n",
            "Epoch 1050/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2644 - accuracy: 0.2465 - val_loss: 2.3954 - val_accuracy: 0.2274\n",
            "Epoch 1051/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2647 - accuracy: 0.2482 - val_loss: 2.4674 - val_accuracy: 0.2113\n",
            "Epoch 1052/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2626 - accuracy: 0.2467 - val_loss: 2.4605 - val_accuracy: 0.2021\n",
            "Epoch 1053/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2680 - accuracy: 0.2459 - val_loss: 2.4058 - val_accuracy: 0.2278\n",
            "Epoch 1054/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2654 - accuracy: 0.2433 - val_loss: 2.4761 - val_accuracy: 0.2069\n",
            "Epoch 1055/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2614 - accuracy: 0.2486 - val_loss: 2.4227 - val_accuracy: 0.2348\n",
            "Epoch 1056/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2591 - accuracy: 0.2482 - val_loss: 2.3840 - val_accuracy: 0.2274\n",
            "Epoch 1057/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2634 - accuracy: 0.2468 - val_loss: 2.3798 - val_accuracy: 0.2375\n",
            "Epoch 1058/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2665 - accuracy: 0.2474 - val_loss: 2.3906 - val_accuracy: 0.2484\n",
            "Epoch 1059/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2713 - accuracy: 0.2446 - val_loss: 2.4023 - val_accuracy: 0.2313\n",
            "Epoch 1060/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2577 - accuracy: 0.2480 - val_loss: 2.4097 - val_accuracy: 0.2265\n",
            "Epoch 1061/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2662 - accuracy: 0.2470 - val_loss: 2.3855 - val_accuracy: 0.2296\n",
            "Epoch 1062/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2602 - accuracy: 0.2487 - val_loss: 2.4696 - val_accuracy: 0.2025\n",
            "Epoch 1063/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2671 - accuracy: 0.2471 - val_loss: 2.4120 - val_accuracy: 0.2200\n",
            "Epoch 1064/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2600 - accuracy: 0.2491 - val_loss: 2.3738 - val_accuracy: 0.2366\n",
            "Epoch 1065/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2618 - accuracy: 0.2492 - val_loss: 2.3857 - val_accuracy: 0.2274\n",
            "Epoch 1066/10000\n",
            "453/453 [==============================] - 4s 8ms/step - loss: 2.2630 - accuracy: 0.2474 - val_loss: 2.4410 - val_accuracy: 0.2152\n",
            "Epoch 1067/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2587 - accuracy: 0.2489 - val_loss: 2.4784 - val_accuracy: 0.1912\n",
            "Epoch 1068/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2577 - accuracy: 0.2484 - val_loss: 2.4010 - val_accuracy: 0.2200\n",
            "Epoch 1069/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2599 - accuracy: 0.2481 - val_loss: 2.3942 - val_accuracy: 0.2309\n",
            "Epoch 1070/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2602 - accuracy: 0.2494 - val_loss: 2.3984 - val_accuracy: 0.2100\n",
            "Epoch 1071/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2632 - accuracy: 0.2469 - val_loss: 2.4180 - val_accuracy: 0.2300\n",
            "Epoch 1072/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2634 - accuracy: 0.2475 - val_loss: 2.4011 - val_accuracy: 0.2126\n",
            "Epoch 1073/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2573 - accuracy: 0.2479 - val_loss: 2.3866 - val_accuracy: 0.2235\n",
            "Epoch 1074/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2615 - accuracy: 0.2475 - val_loss: 2.3911 - val_accuracy: 0.2274\n",
            "Epoch 1075/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2644 - accuracy: 0.2460 - val_loss: 2.4267 - val_accuracy: 0.2230\n",
            "Epoch 1076/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2647 - accuracy: 0.2458 - val_loss: 2.4152 - val_accuracy: 0.2248\n",
            "Epoch 1077/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2659 - accuracy: 0.2450 - val_loss: 2.4220 - val_accuracy: 0.2117\n",
            "Epoch 1078/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2596 - accuracy: 0.2465 - val_loss: 2.3846 - val_accuracy: 0.2331\n",
            "Epoch 1079/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2572 - accuracy: 0.2482 - val_loss: 2.4131 - val_accuracy: 0.2283\n",
            "Epoch 1080/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2595 - accuracy: 0.2462 - val_loss: 2.3905 - val_accuracy: 0.2331\n",
            "Epoch 1081/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2744 - accuracy: 0.2410 - val_loss: 2.4141 - val_accuracy: 0.2361\n",
            "Epoch 1082/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2552 - accuracy: 0.2476 - val_loss: 2.3810 - val_accuracy: 0.2436\n",
            "Epoch 1083/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2689 - accuracy: 0.2426 - val_loss: 2.4082 - val_accuracy: 0.2217\n",
            "Epoch 1084/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2593 - accuracy: 0.2472 - val_loss: 2.3882 - val_accuracy: 0.2353\n",
            "Epoch 1085/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2570 - accuracy: 0.2473 - val_loss: 2.4149 - val_accuracy: 0.2296\n",
            "Epoch 1086/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2563 - accuracy: 0.2504 - val_loss: 2.4087 - val_accuracy: 0.2283\n",
            "Epoch 1087/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2589 - accuracy: 0.2499 - val_loss: 2.4185 - val_accuracy: 0.2174\n",
            "Epoch 1088/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2584 - accuracy: 0.2495 - val_loss: 2.3965 - val_accuracy: 0.2331\n",
            "Epoch 1089/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2648 - accuracy: 0.2471 - val_loss: 2.4283 - val_accuracy: 0.2313\n",
            "Epoch 1090/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2599 - accuracy: 0.2476 - val_loss: 2.3973 - val_accuracy: 0.2383\n",
            "Epoch 1091/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2626 - accuracy: 0.2470 - val_loss: 2.4283 - val_accuracy: 0.2265\n",
            "Epoch 1092/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2587 - accuracy: 0.2477 - val_loss: 2.3678 - val_accuracy: 0.2484\n",
            "Epoch 1093/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2577 - accuracy: 0.2484 - val_loss: 2.4569 - val_accuracy: 0.1947\n",
            "Epoch 1094/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2604 - accuracy: 0.2470 - val_loss: 2.3884 - val_accuracy: 0.2375\n",
            "Epoch 1095/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2588 - accuracy: 0.2485 - val_loss: 2.4127 - val_accuracy: 0.2287\n",
            "Epoch 1096/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2574 - accuracy: 0.2485 - val_loss: 2.4027 - val_accuracy: 0.2300\n",
            "Epoch 1097/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2587 - accuracy: 0.2474 - val_loss: 2.3901 - val_accuracy: 0.2340\n",
            "Epoch 1098/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2642 - accuracy: 0.2463 - val_loss: 2.3831 - val_accuracy: 0.2331\n",
            "Epoch 1099/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2583 - accuracy: 0.2487 - val_loss: 2.4125 - val_accuracy: 0.2226\n",
            "Epoch 1100/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2604 - accuracy: 0.2456 - val_loss: 2.3716 - val_accuracy: 0.2318\n",
            "Epoch 1101/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2553 - accuracy: 0.2471 - val_loss: 2.4025 - val_accuracy: 0.2423\n",
            "Epoch 1102/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2636 - accuracy: 0.2488 - val_loss: 2.4273 - val_accuracy: 0.2292\n",
            "Epoch 1103/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2623 - accuracy: 0.2438 - val_loss: 2.5684 - val_accuracy: 0.1663\n",
            "Epoch 1104/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2574 - accuracy: 0.2478 - val_loss: 2.3692 - val_accuracy: 0.2501\n",
            "Epoch 1105/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2584 - accuracy: 0.2461 - val_loss: 2.4820 - val_accuracy: 0.2043\n",
            "Epoch 1106/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2593 - accuracy: 0.2470 - val_loss: 2.4214 - val_accuracy: 0.2108\n",
            "Epoch 1107/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2551 - accuracy: 0.2490 - val_loss: 2.3962 - val_accuracy: 0.2340\n",
            "Epoch 1108/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2586 - accuracy: 0.2456 - val_loss: 2.4090 - val_accuracy: 0.2143\n",
            "Epoch 1109/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2531 - accuracy: 0.2495 - val_loss: 2.3981 - val_accuracy: 0.2366\n",
            "Epoch 1110/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2583 - accuracy: 0.2461 - val_loss: 2.3736 - val_accuracy: 0.2357\n",
            "Epoch 1111/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2603 - accuracy: 0.2464 - val_loss: 2.3664 - val_accuracy: 0.2396\n",
            "Epoch 1112/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2577 - accuracy: 0.2456 - val_loss: 2.3795 - val_accuracy: 0.2318\n",
            "Epoch 1113/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2552 - accuracy: 0.2479 - val_loss: 2.3859 - val_accuracy: 0.2265\n",
            "Epoch 1114/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2594 - accuracy: 0.2481 - val_loss: 2.3824 - val_accuracy: 0.2335\n",
            "Epoch 1115/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2578 - accuracy: 0.2476 - val_loss: 2.4161 - val_accuracy: 0.2209\n",
            "Epoch 1116/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2566 - accuracy: 0.2459 - val_loss: 2.3752 - val_accuracy: 0.2510\n",
            "Epoch 1117/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2556 - accuracy: 0.2495 - val_loss: 2.4341 - val_accuracy: 0.2200\n",
            "Epoch 1118/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2533 - accuracy: 0.2472 - val_loss: 2.3705 - val_accuracy: 0.2466\n",
            "Epoch 1119/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2524 - accuracy: 0.2479 - val_loss: 2.3853 - val_accuracy: 0.2326\n",
            "Epoch 1120/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2570 - accuracy: 0.2475 - val_loss: 2.3897 - val_accuracy: 0.2370\n",
            "Epoch 1121/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2560 - accuracy: 0.2478 - val_loss: 2.3680 - val_accuracy: 0.2414\n",
            "Epoch 1122/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2615 - accuracy: 0.2469 - val_loss: 2.3912 - val_accuracy: 0.2357\n",
            "Epoch 1123/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2519 - accuracy: 0.2502 - val_loss: 2.3918 - val_accuracy: 0.2204\n",
            "Epoch 1124/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2527 - accuracy: 0.2485 - val_loss: 2.4007 - val_accuracy: 0.2182\n",
            "Epoch 1125/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2626 - accuracy: 0.2481 - val_loss: 2.4484 - val_accuracy: 0.2078\n",
            "Epoch 1126/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2568 - accuracy: 0.2485 - val_loss: 2.3951 - val_accuracy: 0.2326\n",
            "Epoch 1127/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2523 - accuracy: 0.2488 - val_loss: 2.3672 - val_accuracy: 0.2440\n",
            "Epoch 1128/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2532 - accuracy: 0.2489 - val_loss: 2.3926 - val_accuracy: 0.2366\n",
            "Epoch 1129/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2616 - accuracy: 0.2454 - val_loss: 2.3858 - val_accuracy: 0.2200\n",
            "Epoch 1130/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2587 - accuracy: 0.2460 - val_loss: 2.3892 - val_accuracy: 0.2270\n",
            "Epoch 1131/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2576 - accuracy: 0.2475 - val_loss: 2.3815 - val_accuracy: 0.2375\n",
            "Epoch 1132/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2578 - accuracy: 0.2487 - val_loss: 2.4063 - val_accuracy: 0.2191\n",
            "Epoch 1133/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2542 - accuracy: 0.2477 - val_loss: 2.3933 - val_accuracy: 0.2296\n",
            "Epoch 1134/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2601 - accuracy: 0.2478 - val_loss: 2.3981 - val_accuracy: 0.2348\n",
            "Epoch 1135/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2529 - accuracy: 0.2476 - val_loss: 2.3798 - val_accuracy: 0.2270\n",
            "Epoch 1136/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2553 - accuracy: 0.2477 - val_loss: 2.3689 - val_accuracy: 0.2471\n",
            "Epoch 1137/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2550 - accuracy: 0.2485 - val_loss: 2.4530 - val_accuracy: 0.2052\n",
            "Epoch 1138/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2488 - accuracy: 0.2505 - val_loss: 2.3697 - val_accuracy: 0.2440\n",
            "Epoch 1139/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2576 - accuracy: 0.2442 - val_loss: 2.3780 - val_accuracy: 0.2335\n",
            "Epoch 1140/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2535 - accuracy: 0.2493 - val_loss: 2.3707 - val_accuracy: 0.2344\n",
            "Epoch 1141/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2526 - accuracy: 0.2487 - val_loss: 2.4208 - val_accuracy: 0.2331\n",
            "Epoch 1142/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2503 - accuracy: 0.2478 - val_loss: 2.3869 - val_accuracy: 0.2204\n",
            "Epoch 1143/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2598 - accuracy: 0.2464 - val_loss: 2.3663 - val_accuracy: 0.2366\n",
            "Epoch 1144/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2521 - accuracy: 0.2491 - val_loss: 2.4016 - val_accuracy: 0.2182\n",
            "Epoch 1145/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2538 - accuracy: 0.2469 - val_loss: 2.4169 - val_accuracy: 0.2217\n",
            "Epoch 1146/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2539 - accuracy: 0.2486 - val_loss: 2.4218 - val_accuracy: 0.2344\n",
            "Epoch 1147/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2536 - accuracy: 0.2494 - val_loss: 2.3886 - val_accuracy: 0.2383\n",
            "Epoch 1148/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2532 - accuracy: 0.2494 - val_loss: 2.3736 - val_accuracy: 0.2357\n",
            "Epoch 1149/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2517 - accuracy: 0.2478 - val_loss: 2.4581 - val_accuracy: 0.1986\n",
            "Epoch 1150/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2520 - accuracy: 0.2483 - val_loss: 2.3772 - val_accuracy: 0.2283\n",
            "Epoch 1151/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2578 - accuracy: 0.2491 - val_loss: 2.3821 - val_accuracy: 0.2348\n",
            "Epoch 1152/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2534 - accuracy: 0.2488 - val_loss: 2.4565 - val_accuracy: 0.2086\n",
            "Epoch 1153/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2537 - accuracy: 0.2489 - val_loss: 2.4591 - val_accuracy: 0.2082\n",
            "Epoch 1154/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2512 - accuracy: 0.2474 - val_loss: 2.4511 - val_accuracy: 0.2091\n",
            "Epoch 1155/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2536 - accuracy: 0.2461 - val_loss: 2.3709 - val_accuracy: 0.2296\n",
            "Epoch 1156/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2587 - accuracy: 0.2466 - val_loss: 2.4044 - val_accuracy: 0.2204\n",
            "Epoch 1157/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2527 - accuracy: 0.2481 - val_loss: 2.3790 - val_accuracy: 0.2292\n",
            "Epoch 1158/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2484 - accuracy: 0.2488 - val_loss: 2.3792 - val_accuracy: 0.2300\n",
            "Epoch 1159/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2491 - accuracy: 0.2488 - val_loss: 2.3698 - val_accuracy: 0.2405\n",
            "Epoch 1160/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2536 - accuracy: 0.2474 - val_loss: 2.3972 - val_accuracy: 0.2292\n",
            "Epoch 1161/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2521 - accuracy: 0.2490 - val_loss: 2.4609 - val_accuracy: 0.2169\n",
            "Epoch 1162/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2569 - accuracy: 0.2486 - val_loss: 2.3699 - val_accuracy: 0.2318\n",
            "Epoch 1163/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2527 - accuracy: 0.2494 - val_loss: 2.3683 - val_accuracy: 0.2313\n",
            "Epoch 1164/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2544 - accuracy: 0.2482 - val_loss: 2.3952 - val_accuracy: 0.2134\n",
            "Epoch 1165/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2475 - accuracy: 0.2485 - val_loss: 2.3724 - val_accuracy: 0.2270\n",
            "Epoch 1166/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2527 - accuracy: 0.2464 - val_loss: 2.3727 - val_accuracy: 0.2348\n",
            "Epoch 1167/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2535 - accuracy: 0.2485 - val_loss: 2.3805 - val_accuracy: 0.2274\n",
            "Epoch 1168/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2509 - accuracy: 0.2479 - val_loss: 2.3730 - val_accuracy: 0.2313\n",
            "Epoch 1169/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2520 - accuracy: 0.2482 - val_loss: 2.3966 - val_accuracy: 0.2204\n",
            "Epoch 1170/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2519 - accuracy: 0.2492 - val_loss: 2.4995 - val_accuracy: 0.1916\n",
            "Epoch 1171/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2542 - accuracy: 0.2486 - val_loss: 2.4214 - val_accuracy: 0.2108\n",
            "Epoch 1172/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2472 - accuracy: 0.2492 - val_loss: 2.3976 - val_accuracy: 0.2340\n",
            "Epoch 1173/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2503 - accuracy: 0.2485 - val_loss: 2.3770 - val_accuracy: 0.2396\n",
            "Epoch 1174/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2546 - accuracy: 0.2462 - val_loss: 2.3778 - val_accuracy: 0.2169\n",
            "Epoch 1175/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2466 - accuracy: 0.2494 - val_loss: 2.3964 - val_accuracy: 0.2244\n",
            "Epoch 1176/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2473 - accuracy: 0.2478 - val_loss: 2.3765 - val_accuracy: 0.2283\n",
            "Epoch 1177/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2492 - accuracy: 0.2479 - val_loss: 2.4208 - val_accuracy: 0.2082\n",
            "Epoch 1178/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2534 - accuracy: 0.2489 - val_loss: 2.3695 - val_accuracy: 0.2370\n",
            "Epoch 1179/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2475 - accuracy: 0.2504 - val_loss: 2.3964 - val_accuracy: 0.2353\n",
            "Epoch 1180/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2508 - accuracy: 0.2470 - val_loss: 2.3878 - val_accuracy: 0.2187\n",
            "Epoch 1181/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2465 - accuracy: 0.2504 - val_loss: 2.3743 - val_accuracy: 0.2300\n",
            "Epoch 1182/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2484 - accuracy: 0.2496 - val_loss: 2.3655 - val_accuracy: 0.2375\n",
            "Epoch 1183/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2551 - accuracy: 0.2474 - val_loss: 2.4053 - val_accuracy: 0.2169\n",
            "Epoch 1184/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2459 - accuracy: 0.2520 - val_loss: 2.3844 - val_accuracy: 0.2353\n",
            "Epoch 1185/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2509 - accuracy: 0.2475 - val_loss: 2.5318 - val_accuracy: 0.1851\n",
            "Epoch 1186/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2536 - accuracy: 0.2459 - val_loss: 2.3759 - val_accuracy: 0.2409\n",
            "Epoch 1187/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2492 - accuracy: 0.2498 - val_loss: 2.3739 - val_accuracy: 0.2440\n",
            "Epoch 1188/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2481 - accuracy: 0.2455 - val_loss: 2.3808 - val_accuracy: 0.2252\n",
            "Epoch 1189/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2473 - accuracy: 0.2489 - val_loss: 2.3811 - val_accuracy: 0.2187\n",
            "Epoch 1190/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2468 - accuracy: 0.2481 - val_loss: 2.3868 - val_accuracy: 0.2331\n",
            "Epoch 1191/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2539 - accuracy: 0.2451 - val_loss: 2.3883 - val_accuracy: 0.2326\n",
            "Epoch 1192/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2442 - accuracy: 0.2514 - val_loss: 2.4298 - val_accuracy: 0.2156\n",
            "Epoch 1193/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2450 - accuracy: 0.2492 - val_loss: 2.4007 - val_accuracy: 0.2230\n",
            "Epoch 1194/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2547 - accuracy: 0.2472 - val_loss: 2.4442 - val_accuracy: 0.2244\n",
            "Epoch 1195/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2489 - accuracy: 0.2483 - val_loss: 2.3583 - val_accuracy: 0.2427\n",
            "Epoch 1196/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2501 - accuracy: 0.2483 - val_loss: 2.3846 - val_accuracy: 0.2322\n",
            "Epoch 1197/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2420 - accuracy: 0.2515 - val_loss: 2.3670 - val_accuracy: 0.2379\n",
            "Epoch 1198/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2508 - accuracy: 0.2453 - val_loss: 2.3864 - val_accuracy: 0.2252\n",
            "Epoch 1199/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2467 - accuracy: 0.2505 - val_loss: 2.4061 - val_accuracy: 0.2239\n",
            "Epoch 1200/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2497 - accuracy: 0.2463 - val_loss: 2.4136 - val_accuracy: 0.2034\n",
            "Epoch 1201/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2495 - accuracy: 0.2504 - val_loss: 2.4473 - val_accuracy: 0.2143\n",
            "Epoch 1202/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2461 - accuracy: 0.2490 - val_loss: 2.3866 - val_accuracy: 0.2126\n",
            "Epoch 1203/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2448 - accuracy: 0.2506 - val_loss: 2.3660 - val_accuracy: 0.2366\n",
            "Epoch 1204/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2458 - accuracy: 0.2490 - val_loss: 2.3752 - val_accuracy: 0.2239\n",
            "Epoch 1205/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2448 - accuracy: 0.2483 - val_loss: 2.3721 - val_accuracy: 0.2257\n",
            "Epoch 1206/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2489 - accuracy: 0.2486 - val_loss: 2.3956 - val_accuracy: 0.2239\n",
            "Epoch 1207/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2488 - accuracy: 0.2472 - val_loss: 2.3783 - val_accuracy: 0.2335\n",
            "Epoch 1208/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2406 - accuracy: 0.2503 - val_loss: 2.3709 - val_accuracy: 0.2383\n",
            "Epoch 1209/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2511 - accuracy: 0.2481 - val_loss: 2.3842 - val_accuracy: 0.2392\n",
            "Epoch 1210/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2453 - accuracy: 0.2475 - val_loss: 2.3622 - val_accuracy: 0.2379\n",
            "Epoch 1211/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2531 - accuracy: 0.2459 - val_loss: 2.3660 - val_accuracy: 0.2466\n",
            "Epoch 1212/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2463 - accuracy: 0.2495 - val_loss: 2.3637 - val_accuracy: 0.2401\n",
            "Epoch 1213/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2397 - accuracy: 0.2499 - val_loss: 2.3605 - val_accuracy: 0.2440\n",
            "Epoch 1214/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2419 - accuracy: 0.2491 - val_loss: 2.3897 - val_accuracy: 0.2331\n",
            "Epoch 1215/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2464 - accuracy: 0.2488 - val_loss: 2.3846 - val_accuracy: 0.2252\n",
            "Epoch 1216/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2444 - accuracy: 0.2489 - val_loss: 2.3887 - val_accuracy: 0.2222\n",
            "Epoch 1217/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2484 - accuracy: 0.2479 - val_loss: 2.3878 - val_accuracy: 0.2292\n",
            "Epoch 1218/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2433 - accuracy: 0.2509 - val_loss: 2.3893 - val_accuracy: 0.2278\n",
            "Epoch 1219/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2461 - accuracy: 0.2478 - val_loss: 2.3906 - val_accuracy: 0.2423\n",
            "Epoch 1220/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2448 - accuracy: 0.2486 - val_loss: 2.3740 - val_accuracy: 0.2270\n",
            "Epoch 1221/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2438 - accuracy: 0.2499 - val_loss: 2.3607 - val_accuracy: 0.2514\n",
            "Epoch 1222/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2429 - accuracy: 0.2521 - val_loss: 2.3834 - val_accuracy: 0.2313\n",
            "Epoch 1223/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2454 - accuracy: 0.2469 - val_loss: 2.3880 - val_accuracy: 0.2287\n",
            "Epoch 1224/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2413 - accuracy: 0.2515 - val_loss: 2.3830 - val_accuracy: 0.2340\n",
            "Epoch 1225/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2458 - accuracy: 0.2501 - val_loss: 2.4108 - val_accuracy: 0.2230\n",
            "Epoch 1226/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2433 - accuracy: 0.2508 - val_loss: 2.3692 - val_accuracy: 0.2344\n",
            "Epoch 1227/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2403 - accuracy: 0.2497 - val_loss: 2.3778 - val_accuracy: 0.2401\n",
            "Epoch 1228/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2455 - accuracy: 0.2478 - val_loss: 2.3587 - val_accuracy: 0.2405\n",
            "Epoch 1229/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2441 - accuracy: 0.2497 - val_loss: 2.3669 - val_accuracy: 0.2300\n",
            "Epoch 1230/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2424 - accuracy: 0.2494 - val_loss: 2.3597 - val_accuracy: 0.2340\n",
            "Epoch 1231/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2438 - accuracy: 0.2476 - val_loss: 2.3709 - val_accuracy: 0.2326\n",
            "Epoch 1232/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2438 - accuracy: 0.2477 - val_loss: 2.3583 - val_accuracy: 0.2375\n",
            "Epoch 1233/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2565 - accuracy: 0.2428 - val_loss: 2.3631 - val_accuracy: 0.2370\n",
            "Epoch 1234/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2454 - accuracy: 0.2509 - val_loss: 2.4069 - val_accuracy: 0.2187\n",
            "Epoch 1235/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2453 - accuracy: 0.2477 - val_loss: 2.3738 - val_accuracy: 0.2344\n",
            "Epoch 1236/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2374 - accuracy: 0.2517 - val_loss: 2.3682 - val_accuracy: 0.2388\n",
            "Epoch 1237/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2478 - accuracy: 0.2456 - val_loss: 2.3732 - val_accuracy: 0.2396\n",
            "Epoch 1238/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2439 - accuracy: 0.2506 - val_loss: 2.3623 - val_accuracy: 0.2348\n",
            "Epoch 1239/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2410 - accuracy: 0.2487 - val_loss: 2.3515 - val_accuracy: 0.2427\n",
            "Epoch 1240/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2424 - accuracy: 0.2503 - val_loss: 2.3801 - val_accuracy: 0.2283\n",
            "Epoch 1241/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2451 - accuracy: 0.2485 - val_loss: 2.3540 - val_accuracy: 0.2383\n",
            "Epoch 1242/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2431 - accuracy: 0.2491 - val_loss: 2.3585 - val_accuracy: 0.2357\n",
            "Epoch 1243/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2449 - accuracy: 0.2484 - val_loss: 2.3748 - val_accuracy: 0.2300\n",
            "Epoch 1244/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2405 - accuracy: 0.2496 - val_loss: 2.3693 - val_accuracy: 0.2414\n",
            "Epoch 1245/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2394 - accuracy: 0.2499 - val_loss: 2.5139 - val_accuracy: 0.1947\n",
            "Epoch 1246/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2471 - accuracy: 0.2494 - val_loss: 2.3619 - val_accuracy: 0.2366\n",
            "Epoch 1247/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2408 - accuracy: 0.2506 - val_loss: 2.4490 - val_accuracy: 0.2165\n",
            "Epoch 1248/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2437 - accuracy: 0.2499 - val_loss: 2.3669 - val_accuracy: 0.2318\n",
            "Epoch 1249/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2460 - accuracy: 0.2487 - val_loss: 2.4323 - val_accuracy: 0.2222\n",
            "Epoch 1250/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2407 - accuracy: 0.2506 - val_loss: 2.3689 - val_accuracy: 0.2388\n",
            "Epoch 1251/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2427 - accuracy: 0.2490 - val_loss: 2.3795 - val_accuracy: 0.2418\n",
            "Epoch 1252/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2443 - accuracy: 0.2483 - val_loss: 2.3885 - val_accuracy: 0.2230\n",
            "Epoch 1253/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2440 - accuracy: 0.2495 - val_loss: 2.3763 - val_accuracy: 0.2383\n",
            "Epoch 1254/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2412 - accuracy: 0.2520 - val_loss: 2.3949 - val_accuracy: 0.2292\n",
            "Epoch 1255/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2400 - accuracy: 0.2498 - val_loss: 2.4044 - val_accuracy: 0.2318\n",
            "Epoch 1256/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2369 - accuracy: 0.2496 - val_loss: 2.3687 - val_accuracy: 0.2326\n",
            "Epoch 1257/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2440 - accuracy: 0.2508 - val_loss: 2.3968 - val_accuracy: 0.2287\n",
            "Epoch 1258/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2418 - accuracy: 0.2496 - val_loss: 2.3766 - val_accuracy: 0.2191\n",
            "Epoch 1259/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2411 - accuracy: 0.2502 - val_loss: 2.4159 - val_accuracy: 0.2204\n",
            "Epoch 1260/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2446 - accuracy: 0.2489 - val_loss: 2.4647 - val_accuracy: 0.2012\n",
            "Epoch 1261/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2384 - accuracy: 0.2491 - val_loss: 2.3801 - val_accuracy: 0.2357\n",
            "Epoch 1262/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2475 - accuracy: 0.2501 - val_loss: 2.5325 - val_accuracy: 0.1890\n",
            "Epoch 1263/10000\n",
            "453/453 [==============================] - 7s 14ms/step - loss: 2.2428 - accuracy: 0.2503 - val_loss: 2.3772 - val_accuracy: 0.2248\n",
            "Epoch 1264/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2368 - accuracy: 0.2504 - val_loss: 2.3692 - val_accuracy: 0.2353\n",
            "Epoch 1265/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2387 - accuracy: 0.2512 - val_loss: 2.4283 - val_accuracy: 0.2287\n",
            "Epoch 1266/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2411 - accuracy: 0.2494 - val_loss: 2.3782 - val_accuracy: 0.2182\n",
            "Epoch 1267/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2381 - accuracy: 0.2502 - val_loss: 2.3698 - val_accuracy: 0.2322\n",
            "Epoch 1268/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2421 - accuracy: 0.2496 - val_loss: 2.3671 - val_accuracy: 0.2326\n",
            "Epoch 1269/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2397 - accuracy: 0.2491 - val_loss: 2.4317 - val_accuracy: 0.2100\n",
            "Epoch 1270/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2421 - accuracy: 0.2471 - val_loss: 2.4241 - val_accuracy: 0.2169\n",
            "Epoch 1271/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2436 - accuracy: 0.2491 - val_loss: 2.3581 - val_accuracy: 0.2388\n",
            "Epoch 1272/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2398 - accuracy: 0.2511 - val_loss: 2.3908 - val_accuracy: 0.2230\n",
            "Epoch 1273/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2398 - accuracy: 0.2491 - val_loss: 2.3718 - val_accuracy: 0.2405\n",
            "Epoch 1274/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2428 - accuracy: 0.2501 - val_loss: 2.3995 - val_accuracy: 0.2296\n",
            "Epoch 1275/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2429 - accuracy: 0.2508 - val_loss: 2.3527 - val_accuracy: 0.2536\n",
            "Epoch 1276/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2462 - accuracy: 0.2477 - val_loss: 2.3777 - val_accuracy: 0.2230\n",
            "Epoch 1277/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2385 - accuracy: 0.2488 - val_loss: 2.3557 - val_accuracy: 0.2414\n",
            "Epoch 1278/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2358 - accuracy: 0.2525 - val_loss: 2.3942 - val_accuracy: 0.2257\n",
            "Epoch 1279/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2394 - accuracy: 0.2510 - val_loss: 2.3759 - val_accuracy: 0.2309\n",
            "Epoch 1280/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2383 - accuracy: 0.2489 - val_loss: 2.3473 - val_accuracy: 0.2475\n",
            "Epoch 1281/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2410 - accuracy: 0.2478 - val_loss: 2.3931 - val_accuracy: 0.2283\n",
            "Epoch 1282/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2357 - accuracy: 0.2507 - val_loss: 2.3644 - val_accuracy: 0.2366\n",
            "Epoch 1283/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2404 - accuracy: 0.2524 - val_loss: 2.4056 - val_accuracy: 0.2239\n",
            "Epoch 1284/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2329 - accuracy: 0.2536 - val_loss: 2.3782 - val_accuracy: 0.2396\n",
            "Epoch 1285/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2431 - accuracy: 0.2471 - val_loss: 2.3730 - val_accuracy: 0.2318\n",
            "Epoch 1286/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2398 - accuracy: 0.2491 - val_loss: 2.4139 - val_accuracy: 0.2261\n",
            "Epoch 1287/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2318 - accuracy: 0.2537 - val_loss: 2.3852 - val_accuracy: 0.2274\n",
            "Epoch 1288/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2384 - accuracy: 0.2495 - val_loss: 2.3477 - val_accuracy: 0.2488\n",
            "Epoch 1289/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2429 - accuracy: 0.2475 - val_loss: 2.4021 - val_accuracy: 0.2143\n",
            "Epoch 1290/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2380 - accuracy: 0.2470 - val_loss: 2.3674 - val_accuracy: 0.2401\n",
            "Epoch 1291/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2391 - accuracy: 0.2503 - val_loss: 2.3975 - val_accuracy: 0.2300\n",
            "Epoch 1292/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2339 - accuracy: 0.2516 - val_loss: 2.4004 - val_accuracy: 0.2248\n",
            "Epoch 1293/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2362 - accuracy: 0.2508 - val_loss: 2.4549 - val_accuracy: 0.2056\n",
            "Epoch 1294/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2353 - accuracy: 0.2499 - val_loss: 2.3651 - val_accuracy: 0.2366\n",
            "Epoch 1295/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2356 - accuracy: 0.2496 - val_loss: 2.4964 - val_accuracy: 0.2052\n",
            "Epoch 1296/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2367 - accuracy: 0.2489 - val_loss: 2.3481 - val_accuracy: 0.2488\n",
            "Epoch 1297/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2367 - accuracy: 0.2483 - val_loss: 2.4354 - val_accuracy: 0.2143\n",
            "Epoch 1298/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2355 - accuracy: 0.2484 - val_loss: 2.3669 - val_accuracy: 0.2379\n",
            "Epoch 1299/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2338 - accuracy: 0.2509 - val_loss: 2.4945 - val_accuracy: 0.1929\n",
            "Epoch 1300/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2392 - accuracy: 0.2501 - val_loss: 2.4726 - val_accuracy: 0.2082\n",
            "Epoch 1301/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2416 - accuracy: 0.2464 - val_loss: 2.3789 - val_accuracy: 0.2292\n",
            "Epoch 1302/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2377 - accuracy: 0.2512 - val_loss: 2.3735 - val_accuracy: 0.2418\n",
            "Epoch 1303/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2413 - accuracy: 0.2494 - val_loss: 2.3554 - val_accuracy: 0.2440\n",
            "Epoch 1304/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2368 - accuracy: 0.2498 - val_loss: 2.3615 - val_accuracy: 0.2540\n",
            "Epoch 1305/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2331 - accuracy: 0.2500 - val_loss: 2.3723 - val_accuracy: 0.2318\n",
            "Epoch 1306/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2444 - accuracy: 0.2460 - val_loss: 2.4154 - val_accuracy: 0.2305\n",
            "Epoch 1307/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2348 - accuracy: 0.2518 - val_loss: 2.3652 - val_accuracy: 0.2388\n",
            "Epoch 1308/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2399 - accuracy: 0.2485 - val_loss: 2.4921 - val_accuracy: 0.1960\n",
            "Epoch 1309/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2369 - accuracy: 0.2485 - val_loss: 2.4355 - val_accuracy: 0.2134\n",
            "Epoch 1310/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2347 - accuracy: 0.2504 - val_loss: 2.3533 - val_accuracy: 0.2492\n",
            "Epoch 1311/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2438 - accuracy: 0.2488 - val_loss: 2.4130 - val_accuracy: 0.2261\n",
            "Epoch 1312/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2444 - accuracy: 0.2464 - val_loss: 2.3498 - val_accuracy: 0.2549\n",
            "Epoch 1313/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2374 - accuracy: 0.2502 - val_loss: 2.3519 - val_accuracy: 0.2414\n",
            "Epoch 1314/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2362 - accuracy: 0.2505 - val_loss: 2.3830 - val_accuracy: 0.2361\n",
            "Epoch 1315/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2361 - accuracy: 0.2515 - val_loss: 2.3812 - val_accuracy: 0.2300\n",
            "Epoch 1316/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2322 - accuracy: 0.2545 - val_loss: 2.4524 - val_accuracy: 0.2047\n",
            "Epoch 1317/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2410 - accuracy: 0.2486 - val_loss: 2.3578 - val_accuracy: 0.2340\n",
            "Epoch 1318/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2349 - accuracy: 0.2516 - val_loss: 2.4725 - val_accuracy: 0.2047\n",
            "Epoch 1319/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2346 - accuracy: 0.2525 - val_loss: 2.3775 - val_accuracy: 0.2396\n",
            "Epoch 1320/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2438 - accuracy: 0.2489 - val_loss: 2.3936 - val_accuracy: 0.2318\n",
            "Epoch 1321/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2342 - accuracy: 0.2507 - val_loss: 2.3782 - val_accuracy: 0.2370\n",
            "Epoch 1322/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2323 - accuracy: 0.2516 - val_loss: 2.3712 - val_accuracy: 0.2331\n",
            "Epoch 1323/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2384 - accuracy: 0.2507 - val_loss: 2.3713 - val_accuracy: 0.2348\n",
            "Epoch 1324/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2329 - accuracy: 0.2511 - val_loss: 2.3771 - val_accuracy: 0.2305\n",
            "Epoch 1325/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2310 - accuracy: 0.2540 - val_loss: 2.4051 - val_accuracy: 0.2156\n",
            "Epoch 1326/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2426 - accuracy: 0.2487 - val_loss: 2.3906 - val_accuracy: 0.2235\n",
            "Epoch 1327/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2304 - accuracy: 0.2506 - val_loss: 2.4008 - val_accuracy: 0.2143\n",
            "Epoch 1328/10000\n",
            "453/453 [==============================] - 4s 9ms/step - loss: 2.2383 - accuracy: 0.2478 - val_loss: 2.3920 - val_accuracy: 0.2187\n",
            "Epoch 1329/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2306 - accuracy: 0.2514 - val_loss: 2.3660 - val_accuracy: 0.2396\n",
            "Epoch 1330/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2385 - accuracy: 0.2492 - val_loss: 2.4485 - val_accuracy: 0.2148\n",
            "Epoch 1331/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2359 - accuracy: 0.2513 - val_loss: 2.3635 - val_accuracy: 0.2466\n",
            "Epoch 1332/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2332 - accuracy: 0.2490 - val_loss: 2.5077 - val_accuracy: 0.1894\n",
            "Epoch 1333/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2379 - accuracy: 0.2499 - val_loss: 2.3845 - val_accuracy: 0.2388\n",
            "Epoch 1334/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2338 - accuracy: 0.2506 - val_loss: 2.3793 - val_accuracy: 0.2409\n",
            "Epoch 1335/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2373 - accuracy: 0.2511 - val_loss: 2.3634 - val_accuracy: 0.2344\n",
            "Epoch 1336/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2324 - accuracy: 0.2509 - val_loss: 2.3930 - val_accuracy: 0.2318\n",
            "Epoch 1337/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2309 - accuracy: 0.2514 - val_loss: 2.4410 - val_accuracy: 0.2108\n",
            "Epoch 1338/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2297 - accuracy: 0.2547 - val_loss: 2.3493 - val_accuracy: 0.2388\n",
            "Epoch 1339/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2432 - accuracy: 0.2482 - val_loss: 2.4113 - val_accuracy: 0.2217\n",
            "Epoch 1340/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2373 - accuracy: 0.2485 - val_loss: 2.3678 - val_accuracy: 0.2366\n",
            "Epoch 1341/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2398 - accuracy: 0.2463 - val_loss: 2.4508 - val_accuracy: 0.2060\n",
            "Epoch 1342/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2313 - accuracy: 0.2505 - val_loss: 2.3491 - val_accuracy: 0.2497\n",
            "Epoch 1343/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2346 - accuracy: 0.2490 - val_loss: 2.3518 - val_accuracy: 0.2444\n",
            "Epoch 1344/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2394 - accuracy: 0.2478 - val_loss: 2.3716 - val_accuracy: 0.2213\n",
            "Epoch 1345/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2334 - accuracy: 0.2517 - val_loss: 2.3532 - val_accuracy: 0.2353\n",
            "Epoch 1346/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2386 - accuracy: 0.2484 - val_loss: 2.4042 - val_accuracy: 0.2196\n",
            "Epoch 1347/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2409 - accuracy: 0.2482 - val_loss: 2.3498 - val_accuracy: 0.2453\n",
            "Epoch 1348/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2311 - accuracy: 0.2547 - val_loss: 2.4089 - val_accuracy: 0.2239\n",
            "Epoch 1349/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2301 - accuracy: 0.2546 - val_loss: 2.3466 - val_accuracy: 0.2409\n",
            "Epoch 1350/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2304 - accuracy: 0.2512 - val_loss: 2.4273 - val_accuracy: 0.2222\n",
            "Epoch 1351/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2288 - accuracy: 0.2501 - val_loss: 2.3812 - val_accuracy: 0.2427\n",
            "Epoch 1352/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2292 - accuracy: 0.2523 - val_loss: 2.3613 - val_accuracy: 0.2353\n",
            "Epoch 1353/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2355 - accuracy: 0.2502 - val_loss: 2.3659 - val_accuracy: 0.2261\n",
            "Epoch 1354/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2311 - accuracy: 0.2525 - val_loss: 2.3562 - val_accuracy: 0.2471\n",
            "Epoch 1355/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2360 - accuracy: 0.2491 - val_loss: 2.3544 - val_accuracy: 0.2436\n",
            "Epoch 1356/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2296 - accuracy: 0.2520 - val_loss: 2.3559 - val_accuracy: 0.2414\n",
            "Epoch 1357/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2304 - accuracy: 0.2515 - val_loss: 2.3753 - val_accuracy: 0.2379\n",
            "Epoch 1358/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2329 - accuracy: 0.2497 - val_loss: 2.3752 - val_accuracy: 0.2287\n",
            "Epoch 1359/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2366 - accuracy: 0.2487 - val_loss: 2.3814 - val_accuracy: 0.2187\n",
            "Epoch 1360/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2355 - accuracy: 0.2493 - val_loss: 2.3971 - val_accuracy: 0.2104\n",
            "Epoch 1361/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2304 - accuracy: 0.2508 - val_loss: 2.3889 - val_accuracy: 0.2213\n",
            "Epoch 1362/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2333 - accuracy: 0.2506 - val_loss: 2.3733 - val_accuracy: 0.2471\n",
            "Epoch 1363/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2332 - accuracy: 0.2502 - val_loss: 2.3550 - val_accuracy: 0.2409\n",
            "Epoch 1364/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2311 - accuracy: 0.2532 - val_loss: 2.3915 - val_accuracy: 0.2139\n",
            "Epoch 1365/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2359 - accuracy: 0.2486 - val_loss: 2.4233 - val_accuracy: 0.2182\n",
            "Epoch 1366/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2284 - accuracy: 0.2518 - val_loss: 2.4044 - val_accuracy: 0.2230\n",
            "Epoch 1367/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2290 - accuracy: 0.2514 - val_loss: 2.3592 - val_accuracy: 0.2375\n",
            "Epoch 1368/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2328 - accuracy: 0.2512 - val_loss: 2.4488 - val_accuracy: 0.2082\n",
            "Epoch 1369/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2350 - accuracy: 0.2509 - val_loss: 2.3911 - val_accuracy: 0.2261\n",
            "Epoch 1370/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2328 - accuracy: 0.2522 - val_loss: 2.3696 - val_accuracy: 0.2274\n",
            "Epoch 1371/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2297 - accuracy: 0.2508 - val_loss: 2.3672 - val_accuracy: 0.2331\n",
            "Epoch 1372/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2310 - accuracy: 0.2503 - val_loss: 2.3663 - val_accuracy: 0.2292\n",
            "Epoch 1373/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2290 - accuracy: 0.2518 - val_loss: 2.3660 - val_accuracy: 0.2414\n",
            "Epoch 1374/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2357 - accuracy: 0.2497 - val_loss: 2.3901 - val_accuracy: 0.2335\n",
            "Epoch 1375/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2351 - accuracy: 0.2491 - val_loss: 2.3742 - val_accuracy: 0.2152\n",
            "Epoch 1376/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2352 - accuracy: 0.2505 - val_loss: 2.4513 - val_accuracy: 0.2104\n",
            "Epoch 1377/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2298 - accuracy: 0.2483 - val_loss: 2.3583 - val_accuracy: 0.2536\n",
            "Epoch 1378/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2345 - accuracy: 0.2501 - val_loss: 2.3602 - val_accuracy: 0.2401\n",
            "Epoch 1379/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2329 - accuracy: 0.2510 - val_loss: 2.3495 - val_accuracy: 0.2300\n",
            "Epoch 1380/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2345 - accuracy: 0.2493 - val_loss: 2.4076 - val_accuracy: 0.2230\n",
            "Epoch 1381/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2290 - accuracy: 0.2518 - val_loss: 2.3713 - val_accuracy: 0.2270\n",
            "Epoch 1382/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2388 - accuracy: 0.2491 - val_loss: 2.3864 - val_accuracy: 0.2292\n",
            "Epoch 1383/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2330 - accuracy: 0.2533 - val_loss: 2.3603 - val_accuracy: 0.2261\n",
            "Epoch 1384/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2283 - accuracy: 0.2514 - val_loss: 2.3611 - val_accuracy: 0.2353\n",
            "Epoch 1385/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2345 - accuracy: 0.2529 - val_loss: 2.3517 - val_accuracy: 0.2392\n",
            "Epoch 1386/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2349 - accuracy: 0.2509 - val_loss: 2.4736 - val_accuracy: 0.1973\n",
            "Epoch 1387/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2306 - accuracy: 0.2502 - val_loss: 2.3599 - val_accuracy: 0.2414\n",
            "Epoch 1388/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2315 - accuracy: 0.2526 - val_loss: 2.3728 - val_accuracy: 0.2379\n",
            "Epoch 1389/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2265 - accuracy: 0.2530 - val_loss: 2.3652 - val_accuracy: 0.2335\n",
            "Epoch 1390/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2322 - accuracy: 0.2521 - val_loss: 2.3584 - val_accuracy: 0.2344\n",
            "Epoch 1391/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2289 - accuracy: 0.2506 - val_loss: 2.4330 - val_accuracy: 0.2161\n",
            "Epoch 1392/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2340 - accuracy: 0.2496 - val_loss: 2.4020 - val_accuracy: 0.2209\n",
            "Epoch 1393/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2310 - accuracy: 0.2509 - val_loss: 2.3865 - val_accuracy: 0.2283\n",
            "Epoch 1394/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2303 - accuracy: 0.2511 - val_loss: 2.3439 - val_accuracy: 0.2449\n",
            "Epoch 1395/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2300 - accuracy: 0.2541 - val_loss: 2.3613 - val_accuracy: 0.2335\n",
            "Epoch 1396/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2264 - accuracy: 0.2528 - val_loss: 2.3689 - val_accuracy: 0.2165\n",
            "Epoch 1397/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2321 - accuracy: 0.2516 - val_loss: 2.3547 - val_accuracy: 0.2335\n",
            "Epoch 1398/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2310 - accuracy: 0.2509 - val_loss: 2.3717 - val_accuracy: 0.2283\n",
            "Epoch 1399/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2277 - accuracy: 0.2527 - val_loss: 2.3814 - val_accuracy: 0.2388\n",
            "Epoch 1400/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2293 - accuracy: 0.2527 - val_loss: 2.4021 - val_accuracy: 0.2156\n",
            "Epoch 1401/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2339 - accuracy: 0.2493 - val_loss: 2.4495 - val_accuracy: 0.1964\n",
            "Epoch 1402/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2260 - accuracy: 0.2517 - val_loss: 2.3683 - val_accuracy: 0.2248\n",
            "Epoch 1403/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2271 - accuracy: 0.2508 - val_loss: 2.3625 - val_accuracy: 0.2318\n",
            "Epoch 1404/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2260 - accuracy: 0.2544 - val_loss: 2.4191 - val_accuracy: 0.2230\n",
            "Epoch 1405/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2285 - accuracy: 0.2514 - val_loss: 2.3918 - val_accuracy: 0.2244\n",
            "Epoch 1406/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2338 - accuracy: 0.2483 - val_loss: 2.3750 - val_accuracy: 0.2287\n",
            "Epoch 1407/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2344 - accuracy: 0.2505 - val_loss: 2.3708 - val_accuracy: 0.2313\n",
            "Epoch 1408/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2222 - accuracy: 0.2551 - val_loss: 2.4089 - val_accuracy: 0.2326\n",
            "Epoch 1409/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2286 - accuracy: 0.2529 - val_loss: 2.3739 - val_accuracy: 0.2479\n",
            "Epoch 1410/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2314 - accuracy: 0.2493 - val_loss: 2.4057 - val_accuracy: 0.2134\n",
            "Epoch 1411/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2334 - accuracy: 0.2501 - val_loss: 2.3426 - val_accuracy: 0.2514\n",
            "Epoch 1412/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2309 - accuracy: 0.2534 - val_loss: 2.4064 - val_accuracy: 0.2230\n",
            "Epoch 1413/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2287 - accuracy: 0.2533 - val_loss: 2.3830 - val_accuracy: 0.2130\n",
            "Epoch 1414/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2357 - accuracy: 0.2486 - val_loss: 2.4013 - val_accuracy: 0.2257\n",
            "Epoch 1415/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2242 - accuracy: 0.2510 - val_loss: 2.3792 - val_accuracy: 0.2313\n",
            "Epoch 1416/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2264 - accuracy: 0.2510 - val_loss: 2.3601 - val_accuracy: 0.2353\n",
            "Epoch 1417/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2203 - accuracy: 0.2557 - val_loss: 2.4097 - val_accuracy: 0.2130\n",
            "Epoch 1418/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2286 - accuracy: 0.2511 - val_loss: 2.3687 - val_accuracy: 0.2261\n",
            "Epoch 1419/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2280 - accuracy: 0.2513 - val_loss: 2.3666 - val_accuracy: 0.2431\n",
            "Epoch 1420/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2294 - accuracy: 0.2516 - val_loss: 2.3713 - val_accuracy: 0.2322\n",
            "Epoch 1421/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2245 - accuracy: 0.2510 - val_loss: 2.4003 - val_accuracy: 0.2213\n",
            "Epoch 1422/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2277 - accuracy: 0.2508 - val_loss: 2.3547 - val_accuracy: 0.2405\n",
            "Epoch 1423/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2277 - accuracy: 0.2542 - val_loss: 2.3711 - val_accuracy: 0.2313\n",
            "Epoch 1424/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2295 - accuracy: 0.2494 - val_loss: 2.3517 - val_accuracy: 0.2423\n",
            "Epoch 1425/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2319 - accuracy: 0.2509 - val_loss: 2.3582 - val_accuracy: 0.2344\n",
            "Epoch 1426/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2299 - accuracy: 0.2509 - val_loss: 2.3774 - val_accuracy: 0.2449\n",
            "Epoch 1427/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2255 - accuracy: 0.2504 - val_loss: 2.4393 - val_accuracy: 0.2139\n",
            "Epoch 1428/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2294 - accuracy: 0.2495 - val_loss: 2.4158 - val_accuracy: 0.2204\n",
            "Epoch 1429/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2291 - accuracy: 0.2489 - val_loss: 2.3452 - val_accuracy: 0.2318\n",
            "Epoch 1430/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2277 - accuracy: 0.2501 - val_loss: 2.4648 - val_accuracy: 0.2052\n",
            "Epoch 1431/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2289 - accuracy: 0.2520 - val_loss: 2.4126 - val_accuracy: 0.2200\n",
            "Epoch 1432/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2288 - accuracy: 0.2550 - val_loss: 2.3615 - val_accuracy: 0.2318\n",
            "Epoch 1433/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2288 - accuracy: 0.2497 - val_loss: 2.3661 - val_accuracy: 0.2409\n",
            "Epoch 1434/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2305 - accuracy: 0.2519 - val_loss: 2.4132 - val_accuracy: 0.2169\n",
            "Epoch 1435/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2310 - accuracy: 0.2480 - val_loss: 2.3475 - val_accuracy: 0.2449\n",
            "Epoch 1436/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2244 - accuracy: 0.2505 - val_loss: 2.4026 - val_accuracy: 0.2230\n",
            "Epoch 1437/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2263 - accuracy: 0.2533 - val_loss: 2.3706 - val_accuracy: 0.2174\n",
            "Epoch 1438/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2255 - accuracy: 0.2515 - val_loss: 2.3786 - val_accuracy: 0.2357\n",
            "Epoch 1439/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2294 - accuracy: 0.2494 - val_loss: 2.3500 - val_accuracy: 0.2335\n",
            "Epoch 1440/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2271 - accuracy: 0.2530 - val_loss: 2.3797 - val_accuracy: 0.2296\n",
            "Epoch 1441/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2270 - accuracy: 0.2525 - val_loss: 2.3719 - val_accuracy: 0.2252\n",
            "Epoch 1442/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2213 - accuracy: 0.2544 - val_loss: 2.4934 - val_accuracy: 0.1877\n",
            "Epoch 1443/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2261 - accuracy: 0.2497 - val_loss: 2.4551 - val_accuracy: 0.2073\n",
            "Epoch 1444/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2194 - accuracy: 0.2553 - val_loss: 2.3427 - val_accuracy: 0.2527\n",
            "Epoch 1445/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2331 - accuracy: 0.2504 - val_loss: 2.3454 - val_accuracy: 0.2366\n",
            "Epoch 1446/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2323 - accuracy: 0.2505 - val_loss: 2.3565 - val_accuracy: 0.2353\n",
            "Epoch 1447/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2228 - accuracy: 0.2519 - val_loss: 2.3809 - val_accuracy: 0.2244\n",
            "Epoch 1448/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2242 - accuracy: 0.2508 - val_loss: 2.4103 - val_accuracy: 0.2283\n",
            "Epoch 1449/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2260 - accuracy: 0.2522 - val_loss: 2.3675 - val_accuracy: 0.2379\n",
            "Epoch 1450/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2304 - accuracy: 0.2537 - val_loss: 2.4064 - val_accuracy: 0.2200\n",
            "Epoch 1451/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2308 - accuracy: 0.2498 - val_loss: 2.3548 - val_accuracy: 0.2244\n",
            "Epoch 1452/10000\n",
            "453/453 [==============================] - 4s 10ms/step - loss: 2.2245 - accuracy: 0.2514 - val_loss: 2.3628 - val_accuracy: 0.2344\n",
            "Epoch 1453/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2241 - accuracy: 0.2541 - val_loss: 2.3394 - val_accuracy: 0.2418\n",
            "Epoch 1454/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2224 - accuracy: 0.2520 - val_loss: 2.3894 - val_accuracy: 0.2318\n",
            "Epoch 1455/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2312 - accuracy: 0.2514 - val_loss: 2.3690 - val_accuracy: 0.2370\n",
            "Epoch 1456/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2280 - accuracy: 0.2526 - val_loss: 2.3886 - val_accuracy: 0.2335\n",
            "Epoch 1457/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2263 - accuracy: 0.2513 - val_loss: 2.3643 - val_accuracy: 0.2510\n",
            "Epoch 1458/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2271 - accuracy: 0.2507 - val_loss: 2.3574 - val_accuracy: 0.2401\n",
            "Epoch 1459/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2252 - accuracy: 0.2528 - val_loss: 2.3695 - val_accuracy: 0.2326\n",
            "Epoch 1460/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2309 - accuracy: 0.2511 - val_loss: 2.4096 - val_accuracy: 0.2069\n",
            "Epoch 1461/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2198 - accuracy: 0.2520 - val_loss: 2.3411 - val_accuracy: 0.2353\n",
            "Epoch 1462/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2274 - accuracy: 0.2533 - val_loss: 2.3535 - val_accuracy: 0.2501\n",
            "Epoch 1463/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2251 - accuracy: 0.2528 - val_loss: 2.3943 - val_accuracy: 0.2235\n",
            "Epoch 1464/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2296 - accuracy: 0.2504 - val_loss: 2.4234 - val_accuracy: 0.2187\n",
            "Epoch 1465/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2227 - accuracy: 0.2542 - val_loss: 2.3715 - val_accuracy: 0.2318\n",
            "Epoch 1466/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2240 - accuracy: 0.2497 - val_loss: 2.3760 - val_accuracy: 0.2423\n",
            "Epoch 1467/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2230 - accuracy: 0.2532 - val_loss: 2.3634 - val_accuracy: 0.2444\n",
            "Epoch 1468/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2306 - accuracy: 0.2469 - val_loss: 2.3579 - val_accuracy: 0.2440\n",
            "Epoch 1469/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2264 - accuracy: 0.2532 - val_loss: 2.3439 - val_accuracy: 0.2436\n",
            "Epoch 1470/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2200 - accuracy: 0.2551 - val_loss: 2.4131 - val_accuracy: 0.2187\n",
            "Epoch 1471/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2249 - accuracy: 0.2527 - val_loss: 2.3526 - val_accuracy: 0.2388\n",
            "Epoch 1472/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2274 - accuracy: 0.2497 - val_loss: 2.3540 - val_accuracy: 0.2318\n",
            "Epoch 1473/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2251 - accuracy: 0.2509 - val_loss: 2.3964 - val_accuracy: 0.2353\n",
            "Epoch 1474/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2285 - accuracy: 0.2507 - val_loss: 2.3425 - val_accuracy: 0.2357\n",
            "Epoch 1475/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2214 - accuracy: 0.2514 - val_loss: 2.3840 - val_accuracy: 0.2405\n",
            "Epoch 1476/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2207 - accuracy: 0.2529 - val_loss: 2.3905 - val_accuracy: 0.2340\n",
            "Epoch 1477/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2191 - accuracy: 0.2523 - val_loss: 2.3583 - val_accuracy: 0.2348\n",
            "Epoch 1478/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2229 - accuracy: 0.2523 - val_loss: 2.3603 - val_accuracy: 0.2305\n",
            "Epoch 1479/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2234 - accuracy: 0.2508 - val_loss: 2.3460 - val_accuracy: 0.2409\n",
            "Epoch 1480/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2264 - accuracy: 0.2533 - val_loss: 2.3890 - val_accuracy: 0.2300\n",
            "Epoch 1481/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2212 - accuracy: 0.2538 - val_loss: 2.3680 - val_accuracy: 0.2244\n",
            "Epoch 1482/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2222 - accuracy: 0.2526 - val_loss: 2.4711 - val_accuracy: 0.2056\n",
            "Epoch 1483/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2317 - accuracy: 0.2501 - val_loss: 2.3646 - val_accuracy: 0.2165\n",
            "Epoch 1484/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2244 - accuracy: 0.2522 - val_loss: 2.3805 - val_accuracy: 0.2353\n",
            "Epoch 1485/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2267 - accuracy: 0.2491 - val_loss: 2.3658 - val_accuracy: 0.2383\n",
            "Epoch 1486/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2272 - accuracy: 0.2508 - val_loss: 2.4534 - val_accuracy: 0.2038\n",
            "Epoch 1487/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2282 - accuracy: 0.2489 - val_loss: 2.3533 - val_accuracy: 0.2353\n",
            "Epoch 1488/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2219 - accuracy: 0.2540 - val_loss: 2.3723 - val_accuracy: 0.2414\n",
            "Epoch 1489/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2184 - accuracy: 0.2540 - val_loss: 2.3641 - val_accuracy: 0.2471\n",
            "Epoch 1490/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2229 - accuracy: 0.2534 - val_loss: 2.3545 - val_accuracy: 0.2326\n",
            "Epoch 1491/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2254 - accuracy: 0.2513 - val_loss: 2.3487 - val_accuracy: 0.2375\n",
            "Epoch 1492/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2278 - accuracy: 0.2498 - val_loss: 2.3960 - val_accuracy: 0.2239\n",
            "Epoch 1493/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2253 - accuracy: 0.2535 - val_loss: 2.3749 - val_accuracy: 0.2305\n",
            "Epoch 1494/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2294 - accuracy: 0.2506 - val_loss: 2.3588 - val_accuracy: 0.2209\n",
            "Epoch 1495/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2234 - accuracy: 0.2540 - val_loss: 2.4060 - val_accuracy: 0.2187\n",
            "Epoch 1496/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2213 - accuracy: 0.2522 - val_loss: 2.3574 - val_accuracy: 0.2270\n",
            "Epoch 1497/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2247 - accuracy: 0.2512 - val_loss: 2.3448 - val_accuracy: 0.2274\n",
            "Epoch 1498/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2305 - accuracy: 0.2511 - val_loss: 2.3547 - val_accuracy: 0.2257\n",
            "Epoch 1499/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2231 - accuracy: 0.2518 - val_loss: 2.3698 - val_accuracy: 0.2405\n",
            "Epoch 1500/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2218 - accuracy: 0.2512 - val_loss: 2.3653 - val_accuracy: 0.2414\n",
            "Epoch 1501/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2266 - accuracy: 0.2527 - val_loss: 2.3635 - val_accuracy: 0.2348\n",
            "Epoch 1502/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2233 - accuracy: 0.2499 - val_loss: 2.4156 - val_accuracy: 0.2196\n",
            "Epoch 1503/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2171 - accuracy: 0.2549 - val_loss: 2.3435 - val_accuracy: 0.2431\n",
            "Epoch 1504/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2250 - accuracy: 0.2522 - val_loss: 2.3432 - val_accuracy: 0.2396\n",
            "Epoch 1505/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2232 - accuracy: 0.2545 - val_loss: 2.4200 - val_accuracy: 0.2065\n",
            "Epoch 1506/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2175 - accuracy: 0.2543 - val_loss: 2.3726 - val_accuracy: 0.2296\n",
            "Epoch 1507/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2183 - accuracy: 0.2533 - val_loss: 2.3750 - val_accuracy: 0.2296\n",
            "Epoch 1508/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2232 - accuracy: 0.2542 - val_loss: 2.3814 - val_accuracy: 0.2313\n",
            "Epoch 1509/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2226 - accuracy: 0.2520 - val_loss: 2.3758 - val_accuracy: 0.2427\n",
            "Epoch 1510/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2211 - accuracy: 0.2511 - val_loss: 2.3835 - val_accuracy: 0.2292\n",
            "Epoch 1511/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2188 - accuracy: 0.2551 - val_loss: 2.4066 - val_accuracy: 0.2174\n",
            "Epoch 1512/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2272 - accuracy: 0.2492 - val_loss: 2.3414 - val_accuracy: 0.2553\n",
            "Epoch 1513/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2207 - accuracy: 0.2560 - val_loss: 2.3422 - val_accuracy: 0.2357\n",
            "Epoch 1514/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2257 - accuracy: 0.2506 - val_loss: 2.3788 - val_accuracy: 0.2235\n",
            "Epoch 1515/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2246 - accuracy: 0.2523 - val_loss: 2.3383 - val_accuracy: 0.2497\n",
            "Epoch 1516/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2183 - accuracy: 0.2517 - val_loss: 2.3439 - val_accuracy: 0.2322\n",
            "Epoch 1517/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2230 - accuracy: 0.2522 - val_loss: 2.3555 - val_accuracy: 0.2401\n",
            "Epoch 1518/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2183 - accuracy: 0.2549 - val_loss: 2.4389 - val_accuracy: 0.2139\n",
            "Epoch 1519/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2259 - accuracy: 0.2515 - val_loss: 2.3567 - val_accuracy: 0.2230\n",
            "Epoch 1520/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2207 - accuracy: 0.2523 - val_loss: 2.3454 - val_accuracy: 0.2462\n",
            "Epoch 1521/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2234 - accuracy: 0.2514 - val_loss: 2.4955 - val_accuracy: 0.1912\n",
            "Epoch 1522/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2213 - accuracy: 0.2525 - val_loss: 2.3668 - val_accuracy: 0.2326\n",
            "Epoch 1523/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2186 - accuracy: 0.2553 - val_loss: 2.3547 - val_accuracy: 0.2244\n",
            "Epoch 1524/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2195 - accuracy: 0.2530 - val_loss: 2.3561 - val_accuracy: 0.2348\n",
            "Epoch 1525/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2177 - accuracy: 0.2522 - val_loss: 2.3939 - val_accuracy: 0.2235\n",
            "Epoch 1526/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2249 - accuracy: 0.2515 - val_loss: 2.3638 - val_accuracy: 0.2414\n",
            "Epoch 1527/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2218 - accuracy: 0.2536 - val_loss: 2.3517 - val_accuracy: 0.2388\n",
            "Epoch 1528/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2191 - accuracy: 0.2518 - val_loss: 2.4046 - val_accuracy: 0.2191\n",
            "Epoch 1529/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2238 - accuracy: 0.2513 - val_loss: 2.3612 - val_accuracy: 0.2217\n",
            "Epoch 1530/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2227 - accuracy: 0.2518 - val_loss: 2.3868 - val_accuracy: 0.2326\n",
            "Epoch 1531/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2140 - accuracy: 0.2571 - val_loss: 2.3722 - val_accuracy: 0.2335\n",
            "Epoch 1532/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2198 - accuracy: 0.2536 - val_loss: 2.3968 - val_accuracy: 0.2008\n",
            "Epoch 1533/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2187 - accuracy: 0.2540 - val_loss: 2.4249 - val_accuracy: 0.2108\n",
            "Epoch 1534/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2222 - accuracy: 0.2522 - val_loss: 2.3561 - val_accuracy: 0.2357\n",
            "Epoch 1535/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2209 - accuracy: 0.2501 - val_loss: 2.3670 - val_accuracy: 0.2313\n",
            "Epoch 1536/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2153 - accuracy: 0.2530 - val_loss: 2.3721 - val_accuracy: 0.2278\n",
            "Epoch 1537/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2214 - accuracy: 0.2518 - val_loss: 2.3514 - val_accuracy: 0.2353\n",
            "Epoch 1538/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2229 - accuracy: 0.2528 - val_loss: 2.3743 - val_accuracy: 0.2257\n",
            "Epoch 1539/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2160 - accuracy: 0.2554 - val_loss: 2.3847 - val_accuracy: 0.2174\n",
            "Epoch 1540/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2264 - accuracy: 0.2521 - val_loss: 2.3453 - val_accuracy: 0.2340\n",
            "Epoch 1541/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2199 - accuracy: 0.2539 - val_loss: 2.3431 - val_accuracy: 0.2540\n",
            "Epoch 1542/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2179 - accuracy: 0.2536 - val_loss: 2.3440 - val_accuracy: 0.2457\n",
            "Epoch 1543/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2190 - accuracy: 0.2518 - val_loss: 2.3767 - val_accuracy: 0.2318\n",
            "Epoch 1544/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2200 - accuracy: 0.2505 - val_loss: 2.3748 - val_accuracy: 0.2222\n",
            "Epoch 1545/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2185 - accuracy: 0.2528 - val_loss: 2.3503 - val_accuracy: 0.2318\n",
            "Epoch 1546/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2173 - accuracy: 0.2539 - val_loss: 2.3990 - val_accuracy: 0.2270\n",
            "Epoch 1547/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2236 - accuracy: 0.2501 - val_loss: 2.4690 - val_accuracy: 0.2030\n",
            "Epoch 1548/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2178 - accuracy: 0.2536 - val_loss: 2.4194 - val_accuracy: 0.2130\n",
            "Epoch 1549/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2197 - accuracy: 0.2542 - val_loss: 2.3967 - val_accuracy: 0.2213\n",
            "Epoch 1550/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2187 - accuracy: 0.2514 - val_loss: 2.4639 - val_accuracy: 0.1859\n",
            "Epoch 1551/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2240 - accuracy: 0.2519 - val_loss: 2.3453 - val_accuracy: 0.2366\n",
            "Epoch 1552/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2187 - accuracy: 0.2531 - val_loss: 2.3630 - val_accuracy: 0.2148\n",
            "Epoch 1553/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2195 - accuracy: 0.2519 - val_loss: 2.3588 - val_accuracy: 0.2366\n",
            "Epoch 1554/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2207 - accuracy: 0.2526 - val_loss: 2.3496 - val_accuracy: 0.2501\n",
            "Epoch 1555/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2176 - accuracy: 0.2529 - val_loss: 2.3649 - val_accuracy: 0.2488\n",
            "Epoch 1556/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2251 - accuracy: 0.2515 - val_loss: 2.3846 - val_accuracy: 0.2370\n",
            "Epoch 1557/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2222 - accuracy: 0.2530 - val_loss: 2.4805 - val_accuracy: 0.1921\n",
            "Epoch 1558/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2169 - accuracy: 0.2567 - val_loss: 2.3626 - val_accuracy: 0.2344\n",
            "Epoch 1559/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2152 - accuracy: 0.2547 - val_loss: 2.3436 - val_accuracy: 0.2388\n",
            "Epoch 1560/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2216 - accuracy: 0.2504 - val_loss: 2.4999 - val_accuracy: 0.1916\n",
            "Epoch 1561/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2207 - accuracy: 0.2536 - val_loss: 2.3599 - val_accuracy: 0.2261\n",
            "Epoch 1562/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2148 - accuracy: 0.2557 - val_loss: 2.4345 - val_accuracy: 0.2091\n",
            "Epoch 1563/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2269 - accuracy: 0.2514 - val_loss: 2.3342 - val_accuracy: 0.2479\n",
            "Epoch 1564/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2209 - accuracy: 0.2509 - val_loss: 2.3534 - val_accuracy: 0.2449\n",
            "Epoch 1565/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2181 - accuracy: 0.2518 - val_loss: 2.3707 - val_accuracy: 0.2296\n",
            "Epoch 1566/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2236 - accuracy: 0.2519 - val_loss: 2.3415 - val_accuracy: 0.2344\n",
            "Epoch 1567/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2188 - accuracy: 0.2514 - val_loss: 2.3562 - val_accuracy: 0.2335\n",
            "Epoch 1568/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2190 - accuracy: 0.2536 - val_loss: 2.3295 - val_accuracy: 0.2540\n",
            "Epoch 1569/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2182 - accuracy: 0.2527 - val_loss: 2.5170 - val_accuracy: 0.1838\n",
            "Epoch 1570/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2156 - accuracy: 0.2528 - val_loss: 2.3375 - val_accuracy: 0.2383\n",
            "Epoch 1571/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2192 - accuracy: 0.2486 - val_loss: 2.3495 - val_accuracy: 0.2353\n",
            "Epoch 1572/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2133 - accuracy: 0.2523 - val_loss: 2.3696 - val_accuracy: 0.2187\n",
            "Epoch 1573/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2214 - accuracy: 0.2517 - val_loss: 2.3415 - val_accuracy: 0.2409\n",
            "Epoch 1574/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2186 - accuracy: 0.2543 - val_loss: 2.4274 - val_accuracy: 0.1825\n",
            "Epoch 1575/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2191 - accuracy: 0.2526 - val_loss: 2.4065 - val_accuracy: 0.2257\n",
            "Epoch 1576/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2157 - accuracy: 0.2553 - val_loss: 2.3481 - val_accuracy: 0.2283\n",
            "Epoch 1577/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2127 - accuracy: 0.2554 - val_loss: 2.3556 - val_accuracy: 0.2449\n",
            "Epoch 1578/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2241 - accuracy: 0.2512 - val_loss: 2.3310 - val_accuracy: 0.2519\n",
            "Epoch 1579/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2186 - accuracy: 0.2549 - val_loss: 2.3578 - val_accuracy: 0.2462\n",
            "Epoch 1580/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2216 - accuracy: 0.2528 - val_loss: 2.3499 - val_accuracy: 0.2213\n",
            "Epoch 1581/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2125 - accuracy: 0.2543 - val_loss: 2.3288 - val_accuracy: 0.2558\n",
            "Epoch 1582/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2211 - accuracy: 0.2526 - val_loss: 2.3605 - val_accuracy: 0.2292\n",
            "Epoch 1583/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2204 - accuracy: 0.2535 - val_loss: 2.4332 - val_accuracy: 0.2143\n",
            "Epoch 1584/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2153 - accuracy: 0.2542 - val_loss: 2.3807 - val_accuracy: 0.2318\n",
            "Epoch 1585/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2260 - accuracy: 0.2524 - val_loss: 2.3628 - val_accuracy: 0.2475\n",
            "Epoch 1586/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2190 - accuracy: 0.2517 - val_loss: 2.3431 - val_accuracy: 0.2497\n",
            "Epoch 1587/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2239 - accuracy: 0.2515 - val_loss: 2.3616 - val_accuracy: 0.2366\n",
            "Epoch 1588/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2143 - accuracy: 0.2531 - val_loss: 2.3321 - val_accuracy: 0.2427\n",
            "Epoch 1589/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2161 - accuracy: 0.2527 - val_loss: 2.3550 - val_accuracy: 0.2326\n",
            "Epoch 1590/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2159 - accuracy: 0.2534 - val_loss: 2.4041 - val_accuracy: 0.2209\n",
            "Epoch 1591/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2163 - accuracy: 0.2527 - val_loss: 2.3792 - val_accuracy: 0.2335\n",
            "Epoch 1592/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2165 - accuracy: 0.2504 - val_loss: 2.4360 - val_accuracy: 0.2134\n",
            "Epoch 1593/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2153 - accuracy: 0.2504 - val_loss: 2.3506 - val_accuracy: 0.2348\n",
            "Epoch 1594/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2148 - accuracy: 0.2521 - val_loss: 2.3655 - val_accuracy: 0.2418\n",
            "Epoch 1595/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2186 - accuracy: 0.2540 - val_loss: 2.3817 - val_accuracy: 0.2108\n",
            "Epoch 1596/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2185 - accuracy: 0.2512 - val_loss: 2.3391 - val_accuracy: 0.2436\n",
            "Epoch 1597/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2186 - accuracy: 0.2515 - val_loss: 2.4215 - val_accuracy: 0.2161\n",
            "Epoch 1598/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2146 - accuracy: 0.2555 - val_loss: 2.3421 - val_accuracy: 0.2444\n",
            "Epoch 1599/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2177 - accuracy: 0.2504 - val_loss: 2.3510 - val_accuracy: 0.2409\n",
            "Epoch 1600/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2161 - accuracy: 0.2514 - val_loss: 2.3749 - val_accuracy: 0.2405\n",
            "Epoch 1601/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2180 - accuracy: 0.2550 - val_loss: 2.4348 - val_accuracy: 0.2104\n",
            "Epoch 1602/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2121 - accuracy: 0.2529 - val_loss: 2.3507 - val_accuracy: 0.2331\n",
            "Epoch 1603/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2130 - accuracy: 0.2557 - val_loss: 2.3585 - val_accuracy: 0.2261\n",
            "Epoch 1604/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2111 - accuracy: 0.2550 - val_loss: 2.3594 - val_accuracy: 0.2169\n",
            "Epoch 1605/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2133 - accuracy: 0.2547 - val_loss: 2.3322 - val_accuracy: 0.2423\n",
            "Epoch 1606/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2152 - accuracy: 0.2543 - val_loss: 2.3835 - val_accuracy: 0.2187\n",
            "Epoch 1607/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2118 - accuracy: 0.2528 - val_loss: 2.4599 - val_accuracy: 0.1999\n",
            "Epoch 1608/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2209 - accuracy: 0.2518 - val_loss: 2.3384 - val_accuracy: 0.2401\n",
            "Epoch 1609/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2193 - accuracy: 0.2546 - val_loss: 2.3526 - val_accuracy: 0.2431\n",
            "Epoch 1610/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2128 - accuracy: 0.2543 - val_loss: 2.3395 - val_accuracy: 0.2392\n",
            "Epoch 1611/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2137 - accuracy: 0.2569 - val_loss: 2.3636 - val_accuracy: 0.2414\n",
            "Epoch 1612/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2195 - accuracy: 0.2526 - val_loss: 2.3521 - val_accuracy: 0.2335\n",
            "Epoch 1613/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2175 - accuracy: 0.2534 - val_loss: 2.3611 - val_accuracy: 0.2379\n",
            "Epoch 1614/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2145 - accuracy: 0.2525 - val_loss: 2.3435 - val_accuracy: 0.2366\n",
            "Epoch 1615/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2108 - accuracy: 0.2558 - val_loss: 2.3656 - val_accuracy: 0.2134\n",
            "Epoch 1616/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2207 - accuracy: 0.2530 - val_loss: 2.3672 - val_accuracy: 0.2444\n",
            "Epoch 1617/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2144 - accuracy: 0.2536 - val_loss: 2.3525 - val_accuracy: 0.2182\n",
            "Epoch 1618/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2241 - accuracy: 0.2512 - val_loss: 2.3470 - val_accuracy: 0.2466\n",
            "Epoch 1619/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2144 - accuracy: 0.2525 - val_loss: 2.3216 - val_accuracy: 0.2567\n",
            "Epoch 1620/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2181 - accuracy: 0.2534 - val_loss: 2.3386 - val_accuracy: 0.2388\n",
            "Epoch 1621/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2134 - accuracy: 0.2521 - val_loss: 2.3693 - val_accuracy: 0.2130\n",
            "Epoch 1622/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2160 - accuracy: 0.2536 - val_loss: 2.3915 - val_accuracy: 0.2261\n",
            "Epoch 1623/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2103 - accuracy: 0.2535 - val_loss: 2.3442 - val_accuracy: 0.2322\n",
            "Epoch 1624/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2159 - accuracy: 0.2546 - val_loss: 2.3433 - val_accuracy: 0.2475\n",
            "Epoch 1625/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2131 - accuracy: 0.2533 - val_loss: 2.3327 - val_accuracy: 0.2427\n",
            "Epoch 1626/10000\n",
            "453/453 [==============================] - 5s 10ms/step - loss: 2.2127 - accuracy: 0.2544 - val_loss: 2.4081 - val_accuracy: 0.2213\n",
            "Epoch 1627/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2131 - accuracy: 0.2530 - val_loss: 2.3570 - val_accuracy: 0.2326\n",
            "Epoch 1628/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2122 - accuracy: 0.2547 - val_loss: 2.3932 - val_accuracy: 0.2331\n",
            "Epoch 1629/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2200 - accuracy: 0.2532 - val_loss: 2.3984 - val_accuracy: 0.2248\n",
            "Epoch 1630/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2144 - accuracy: 0.2538 - val_loss: 2.3488 - val_accuracy: 0.2196\n",
            "Epoch 1631/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2199 - accuracy: 0.2508 - val_loss: 2.3791 - val_accuracy: 0.2305\n",
            "Epoch 1632/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2118 - accuracy: 0.2550 - val_loss: 2.3723 - val_accuracy: 0.2313\n",
            "Epoch 1633/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2154 - accuracy: 0.2539 - val_loss: 2.3434 - val_accuracy: 0.2488\n",
            "Epoch 1634/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2253 - accuracy: 0.2498 - val_loss: 2.3930 - val_accuracy: 0.2326\n",
            "Epoch 1635/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2173 - accuracy: 0.2532 - val_loss: 2.3795 - val_accuracy: 0.2217\n",
            "Epoch 1636/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2165 - accuracy: 0.2543 - val_loss: 2.3414 - val_accuracy: 0.2265\n",
            "Epoch 1637/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2144 - accuracy: 0.2540 - val_loss: 2.3444 - val_accuracy: 0.2366\n",
            "Epoch 1638/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2113 - accuracy: 0.2531 - val_loss: 2.3292 - val_accuracy: 0.2484\n",
            "Epoch 1639/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2139 - accuracy: 0.2535 - val_loss: 2.3381 - val_accuracy: 0.2405\n",
            "Epoch 1640/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2184 - accuracy: 0.2514 - val_loss: 2.3351 - val_accuracy: 0.2453\n",
            "Epoch 1641/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2211 - accuracy: 0.2522 - val_loss: 2.4048 - val_accuracy: 0.2274\n",
            "Epoch 1642/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2096 - accuracy: 0.2566 - val_loss: 2.3364 - val_accuracy: 0.2457\n",
            "Epoch 1643/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2128 - accuracy: 0.2545 - val_loss: 2.4511 - val_accuracy: 0.2078\n",
            "Epoch 1644/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2154 - accuracy: 0.2535 - val_loss: 2.3423 - val_accuracy: 0.2326\n",
            "Epoch 1645/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2164 - accuracy: 0.2527 - val_loss: 2.3493 - val_accuracy: 0.2331\n",
            "Epoch 1646/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2124 - accuracy: 0.2535 - val_loss: 2.3421 - val_accuracy: 0.2309\n",
            "Epoch 1647/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2135 - accuracy: 0.2535 - val_loss: 2.3464 - val_accuracy: 0.2270\n",
            "Epoch 1648/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2142 - accuracy: 0.2533 - val_loss: 2.3347 - val_accuracy: 0.2418\n",
            "Epoch 1649/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2094 - accuracy: 0.2563 - val_loss: 2.3772 - val_accuracy: 0.2204\n",
            "Epoch 1650/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2128 - accuracy: 0.2540 - val_loss: 2.3576 - val_accuracy: 0.2340\n",
            "Epoch 1651/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2123 - accuracy: 0.2507 - val_loss: 2.3437 - val_accuracy: 0.2388\n",
            "Epoch 1652/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2182 - accuracy: 0.2533 - val_loss: 2.3417 - val_accuracy: 0.2383\n",
            "Epoch 1653/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2143 - accuracy: 0.2540 - val_loss: 2.4097 - val_accuracy: 0.2248\n",
            "Epoch 1654/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2101 - accuracy: 0.2533 - val_loss: 2.3946 - val_accuracy: 0.2257\n",
            "Epoch 1655/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2127 - accuracy: 0.2555 - val_loss: 2.3664 - val_accuracy: 0.2335\n",
            "Epoch 1656/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2201 - accuracy: 0.2521 - val_loss: 2.3709 - val_accuracy: 0.2270\n",
            "Epoch 1657/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2121 - accuracy: 0.2529 - val_loss: 2.3364 - val_accuracy: 0.2514\n",
            "Epoch 1658/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2146 - accuracy: 0.2523 - val_loss: 2.3631 - val_accuracy: 0.2405\n",
            "Epoch 1659/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2122 - accuracy: 0.2552 - val_loss: 2.3382 - val_accuracy: 0.2492\n",
            "Epoch 1660/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2133 - accuracy: 0.2530 - val_loss: 2.3570 - val_accuracy: 0.2440\n",
            "Epoch 1661/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2130 - accuracy: 0.2524 - val_loss: 2.3477 - val_accuracy: 0.2226\n",
            "Epoch 1662/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2098 - accuracy: 0.2553 - val_loss: 2.3389 - val_accuracy: 0.2309\n",
            "Epoch 1663/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2167 - accuracy: 0.2537 - val_loss: 2.3289 - val_accuracy: 0.2553\n",
            "Epoch 1664/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2157 - accuracy: 0.2552 - val_loss: 2.4328 - val_accuracy: 0.1999\n",
            "Epoch 1665/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2146 - accuracy: 0.2536 - val_loss: 2.3299 - val_accuracy: 0.2401\n",
            "Epoch 1666/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2115 - accuracy: 0.2546 - val_loss: 2.3632 - val_accuracy: 0.2300\n",
            "Epoch 1667/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2095 - accuracy: 0.2533 - val_loss: 2.3567 - val_accuracy: 0.2361\n",
            "Epoch 1668/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2146 - accuracy: 0.2537 - val_loss: 2.3416 - val_accuracy: 0.2532\n",
            "Epoch 1669/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2211 - accuracy: 0.2507 - val_loss: 2.3482 - val_accuracy: 0.2388\n",
            "Epoch 1670/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2127 - accuracy: 0.2535 - val_loss: 2.3679 - val_accuracy: 0.2418\n",
            "Epoch 1671/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2110 - accuracy: 0.2530 - val_loss: 2.3794 - val_accuracy: 0.2292\n",
            "Epoch 1672/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2197 - accuracy: 0.2507 - val_loss: 2.3503 - val_accuracy: 0.2375\n",
            "Epoch 1673/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2211 - accuracy: 0.2518 - val_loss: 2.3543 - val_accuracy: 0.2357\n",
            "Epoch 1674/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2109 - accuracy: 0.2554 - val_loss: 2.3505 - val_accuracy: 0.2370\n",
            "Epoch 1675/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2159 - accuracy: 0.2530 - val_loss: 2.3525 - val_accuracy: 0.2431\n",
            "Epoch 1676/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2095 - accuracy: 0.2555 - val_loss: 2.3595 - val_accuracy: 0.2213\n",
            "Epoch 1677/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2139 - accuracy: 0.2542 - val_loss: 2.4125 - val_accuracy: 0.2191\n",
            "Epoch 1678/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2070 - accuracy: 0.2561 - val_loss: 2.3461 - val_accuracy: 0.2379\n",
            "Epoch 1679/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2117 - accuracy: 0.2539 - val_loss: 2.3533 - val_accuracy: 0.2217\n",
            "Epoch 1680/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2178 - accuracy: 0.2519 - val_loss: 2.3506 - val_accuracy: 0.2169\n",
            "Epoch 1681/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2118 - accuracy: 0.2542 - val_loss: 2.3563 - val_accuracy: 0.2239\n",
            "Epoch 1682/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2127 - accuracy: 0.2542 - val_loss: 2.3520 - val_accuracy: 0.2388\n",
            "Epoch 1683/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2113 - accuracy: 0.2553 - val_loss: 2.3511 - val_accuracy: 0.2370\n",
            "Epoch 1684/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2091 - accuracy: 0.2545 - val_loss: 2.3384 - val_accuracy: 0.2366\n",
            "Epoch 1685/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2089 - accuracy: 0.2534 - val_loss: 2.3907 - val_accuracy: 0.2178\n",
            "Epoch 1686/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2148 - accuracy: 0.2525 - val_loss: 2.3572 - val_accuracy: 0.2440\n",
            "Epoch 1687/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2117 - accuracy: 0.2528 - val_loss: 2.3274 - val_accuracy: 0.2444\n",
            "Epoch 1688/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2122 - accuracy: 0.2530 - val_loss: 2.3632 - val_accuracy: 0.2440\n",
            "Epoch 1689/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2096 - accuracy: 0.2536 - val_loss: 2.3820 - val_accuracy: 0.2239\n",
            "Epoch 1690/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2132 - accuracy: 0.2531 - val_loss: 2.3637 - val_accuracy: 0.2322\n",
            "Epoch 1691/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2116 - accuracy: 0.2553 - val_loss: 2.3356 - val_accuracy: 0.2322\n",
            "Epoch 1692/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2110 - accuracy: 0.2547 - val_loss: 2.3428 - val_accuracy: 0.2405\n",
            "Epoch 1693/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2115 - accuracy: 0.2537 - val_loss: 2.4165 - val_accuracy: 0.2196\n",
            "Epoch 1694/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2095 - accuracy: 0.2553 - val_loss: 2.3320 - val_accuracy: 0.2357\n",
            "Epoch 1695/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2136 - accuracy: 0.2521 - val_loss: 2.6925 - val_accuracy: 0.1680\n",
            "Epoch 1696/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2125 - accuracy: 0.2530 - val_loss: 2.3595 - val_accuracy: 0.2296\n",
            "Epoch 1697/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2095 - accuracy: 0.2557 - val_loss: 2.4283 - val_accuracy: 0.2209\n",
            "Epoch 1698/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2071 - accuracy: 0.2534 - val_loss: 2.3484 - val_accuracy: 0.2462\n",
            "Epoch 1699/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2124 - accuracy: 0.2553 - val_loss: 2.3580 - val_accuracy: 0.2366\n",
            "Epoch 1700/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2085 - accuracy: 0.2541 - val_loss: 2.3533 - val_accuracy: 0.2296\n",
            "Epoch 1701/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2100 - accuracy: 0.2539 - val_loss: 2.3631 - val_accuracy: 0.2265\n",
            "Epoch 1702/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2109 - accuracy: 0.2545 - val_loss: 2.3776 - val_accuracy: 0.2383\n",
            "Epoch 1703/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2064 - accuracy: 0.2540 - val_loss: 2.3442 - val_accuracy: 0.2510\n",
            "Epoch 1704/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2141 - accuracy: 0.2522 - val_loss: 2.3393 - val_accuracy: 0.2475\n",
            "Epoch 1705/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2127 - accuracy: 0.2509 - val_loss: 2.3501 - val_accuracy: 0.2414\n",
            "Epoch 1706/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2101 - accuracy: 0.2539 - val_loss: 2.3200 - val_accuracy: 0.2457\n",
            "Epoch 1707/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2114 - accuracy: 0.2555 - val_loss: 2.3572 - val_accuracy: 0.2457\n",
            "Epoch 1708/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2100 - accuracy: 0.2544 - val_loss: 2.3734 - val_accuracy: 0.2283\n",
            "Epoch 1709/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2083 - accuracy: 0.2572 - val_loss: 2.3510 - val_accuracy: 0.2423\n",
            "Epoch 1710/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2092 - accuracy: 0.2545 - val_loss: 2.3448 - val_accuracy: 0.2161\n",
            "Epoch 1711/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2097 - accuracy: 0.2536 - val_loss: 2.3386 - val_accuracy: 0.2292\n",
            "Epoch 1712/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2091 - accuracy: 0.2550 - val_loss: 2.3455 - val_accuracy: 0.2444\n",
            "Epoch 1713/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2155 - accuracy: 0.2526 - val_loss: 2.3295 - val_accuracy: 0.2418\n",
            "Epoch 1714/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2064 - accuracy: 0.2545 - val_loss: 2.3520 - val_accuracy: 0.2121\n",
            "Epoch 1715/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2121 - accuracy: 0.2539 - val_loss: 2.3280 - val_accuracy: 0.2427\n",
            "Epoch 1716/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2079 - accuracy: 0.2545 - val_loss: 2.4692 - val_accuracy: 0.2034\n",
            "Epoch 1717/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2138 - accuracy: 0.2537 - val_loss: 2.4450 - val_accuracy: 0.2025\n",
            "Epoch 1718/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2133 - accuracy: 0.2543 - val_loss: 2.3670 - val_accuracy: 0.2427\n",
            "Epoch 1719/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2082 - accuracy: 0.2570 - val_loss: 2.3504 - val_accuracy: 0.2270\n",
            "Epoch 1720/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2102 - accuracy: 0.2545 - val_loss: 2.4382 - val_accuracy: 0.2139\n",
            "Epoch 1721/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2117 - accuracy: 0.2524 - val_loss: 2.4344 - val_accuracy: 0.2161\n",
            "Epoch 1722/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2053 - accuracy: 0.2570 - val_loss: 2.3481 - val_accuracy: 0.2178\n",
            "Epoch 1723/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2084 - accuracy: 0.2552 - val_loss: 2.3601 - val_accuracy: 0.2436\n",
            "Epoch 1724/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2100 - accuracy: 0.2535 - val_loss: 2.3431 - val_accuracy: 0.2405\n",
            "Epoch 1725/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2100 - accuracy: 0.2520 - val_loss: 2.3697 - val_accuracy: 0.2021\n",
            "Epoch 1726/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2069 - accuracy: 0.2570 - val_loss: 2.3779 - val_accuracy: 0.2379\n",
            "Epoch 1727/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2140 - accuracy: 0.2528 - val_loss: 2.3381 - val_accuracy: 0.2296\n",
            "Epoch 1728/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2076 - accuracy: 0.2568 - val_loss: 2.3332 - val_accuracy: 0.2401\n",
            "Epoch 1729/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2132 - accuracy: 0.2523 - val_loss: 2.4138 - val_accuracy: 0.2104\n",
            "Epoch 1730/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2107 - accuracy: 0.2556 - val_loss: 2.3570 - val_accuracy: 0.2418\n",
            "Epoch 1731/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2135 - accuracy: 0.2532 - val_loss: 2.3386 - val_accuracy: 0.2562\n",
            "Epoch 1732/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2046 - accuracy: 0.2571 - val_loss: 2.3748 - val_accuracy: 0.2375\n",
            "Epoch 1733/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2088 - accuracy: 0.2545 - val_loss: 2.3408 - val_accuracy: 0.2440\n",
            "Epoch 1734/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2097 - accuracy: 0.2555 - val_loss: 2.3401 - val_accuracy: 0.2340\n",
            "Epoch 1735/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2105 - accuracy: 0.2536 - val_loss: 2.3598 - val_accuracy: 0.2331\n",
            "Epoch 1736/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2115 - accuracy: 0.2551 - val_loss: 2.3391 - val_accuracy: 0.2388\n",
            "Epoch 1737/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2047 - accuracy: 0.2557 - val_loss: 2.3304 - val_accuracy: 0.2396\n",
            "Epoch 1738/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2106 - accuracy: 0.2535 - val_loss: 2.3457 - val_accuracy: 0.2213\n",
            "Epoch 1739/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2137 - accuracy: 0.2542 - val_loss: 2.3429 - val_accuracy: 0.2449\n",
            "Epoch 1740/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2099 - accuracy: 0.2536 - val_loss: 2.3420 - val_accuracy: 0.2353\n",
            "Epoch 1741/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2130 - accuracy: 0.2529 - val_loss: 2.3570 - val_accuracy: 0.2326\n",
            "Epoch 1742/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2109 - accuracy: 0.2560 - val_loss: 2.3424 - val_accuracy: 0.2348\n",
            "Epoch 1743/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2082 - accuracy: 0.2568 - val_loss: 2.3257 - val_accuracy: 0.2440\n",
            "Epoch 1744/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2155 - accuracy: 0.2534 - val_loss: 2.3830 - val_accuracy: 0.2252\n",
            "Epoch 1745/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2118 - accuracy: 0.2548 - val_loss: 2.3782 - val_accuracy: 0.2283\n",
            "Epoch 1746/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2101 - accuracy: 0.2546 - val_loss: 2.3497 - val_accuracy: 0.2196\n",
            "Epoch 1747/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2115 - accuracy: 0.2537 - val_loss: 2.4040 - val_accuracy: 0.2265\n",
            "Epoch 1748/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2098 - accuracy: 0.2535 - val_loss: 2.3549 - val_accuracy: 0.2366\n",
            "Epoch 1749/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2089 - accuracy: 0.2528 - val_loss: 2.3570 - val_accuracy: 0.2479\n",
            "Epoch 1750/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2126 - accuracy: 0.2539 - val_loss: 2.3481 - val_accuracy: 0.2449\n",
            "Epoch 1751/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2050 - accuracy: 0.2545 - val_loss: 2.3419 - val_accuracy: 0.2309\n",
            "Epoch 1752/10000\n",
            "453/453 [==============================] - 6s 14ms/step - loss: 2.2077 - accuracy: 0.2545 - val_loss: 2.4121 - val_accuracy: 0.2095\n",
            "Epoch 1753/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2122 - accuracy: 0.2530 - val_loss: 2.3280 - val_accuracy: 0.2457\n",
            "Epoch 1754/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2104 - accuracy: 0.2560 - val_loss: 2.3342 - val_accuracy: 0.2436\n",
            "Epoch 1755/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2086 - accuracy: 0.2552 - val_loss: 2.3653 - val_accuracy: 0.2361\n",
            "Epoch 1756/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2066 - accuracy: 0.2561 - val_loss: 2.3583 - val_accuracy: 0.2252\n",
            "Epoch 1757/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2078 - accuracy: 0.2521 - val_loss: 2.3686 - val_accuracy: 0.2283\n",
            "Epoch 1758/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2045 - accuracy: 0.2549 - val_loss: 2.3324 - val_accuracy: 0.2383\n",
            "Epoch 1759/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2084 - accuracy: 0.2565 - val_loss: 2.4381 - val_accuracy: 0.2113\n",
            "Epoch 1760/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2079 - accuracy: 0.2541 - val_loss: 2.3483 - val_accuracy: 0.2453\n",
            "Epoch 1761/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2066 - accuracy: 0.2539 - val_loss: 2.3462 - val_accuracy: 0.2466\n",
            "Epoch 1762/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2110 - accuracy: 0.2556 - val_loss: 2.3552 - val_accuracy: 0.2414\n",
            "Epoch 1763/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2173 - accuracy: 0.2504 - val_loss: 2.3288 - val_accuracy: 0.2418\n",
            "Epoch 1764/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2066 - accuracy: 0.2565 - val_loss: 2.3273 - val_accuracy: 0.2488\n",
            "Epoch 1765/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2021 - accuracy: 0.2561 - val_loss: 2.3477 - val_accuracy: 0.2388\n",
            "Epoch 1766/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2047 - accuracy: 0.2570 - val_loss: 2.3284 - val_accuracy: 0.2340\n",
            "Epoch 1767/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2098 - accuracy: 0.2540 - val_loss: 2.3460 - val_accuracy: 0.2248\n",
            "Epoch 1768/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2097 - accuracy: 0.2542 - val_loss: 2.3572 - val_accuracy: 0.2178\n",
            "Epoch 1769/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2040 - accuracy: 0.2576 - val_loss: 2.3525 - val_accuracy: 0.2235\n",
            "Epoch 1770/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2034 - accuracy: 0.2565 - val_loss: 2.3255 - val_accuracy: 0.2436\n",
            "Epoch 1771/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2118 - accuracy: 0.2553 - val_loss: 2.3470 - val_accuracy: 0.2401\n",
            "Epoch 1772/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2114 - accuracy: 0.2527 - val_loss: 2.3941 - val_accuracy: 0.1977\n",
            "Epoch 1773/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2104 - accuracy: 0.2533 - val_loss: 2.3906 - val_accuracy: 0.2187\n",
            "Epoch 1774/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2048 - accuracy: 0.2536 - val_loss: 2.3682 - val_accuracy: 0.2196\n",
            "Epoch 1775/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2027 - accuracy: 0.2552 - val_loss: 2.3412 - val_accuracy: 0.2353\n",
            "Epoch 1776/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2074 - accuracy: 0.2543 - val_loss: 2.3292 - val_accuracy: 0.2396\n",
            "Epoch 1777/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2095 - accuracy: 0.2536 - val_loss: 2.4270 - val_accuracy: 0.2209\n",
            "Epoch 1778/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2078 - accuracy: 0.2572 - val_loss: 2.3391 - val_accuracy: 0.2409\n",
            "Epoch 1779/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2071 - accuracy: 0.2552 - val_loss: 2.3395 - val_accuracy: 0.2318\n",
            "Epoch 1780/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2051 - accuracy: 0.2544 - val_loss: 2.3572 - val_accuracy: 0.2401\n",
            "Epoch 1781/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2092 - accuracy: 0.2545 - val_loss: 2.3274 - val_accuracy: 0.2449\n",
            "Epoch 1782/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2046 - accuracy: 0.2546 - val_loss: 2.4637 - val_accuracy: 0.2069\n",
            "Epoch 1783/10000\n",
            "453/453 [==============================] - 5s 11ms/step - loss: 2.2099 - accuracy: 0.2509 - val_loss: 2.3659 - val_accuracy: 0.2287\n",
            "Epoch 1784/10000\n",
            "453/453 [==============================] - 6s 13ms/step - loss: 2.2059 - accuracy: 0.2546 - val_loss: 2.3314 - val_accuracy: 0.2313\n",
            "Epoch 1785/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2103 - accuracy: 0.2533 - val_loss: 2.3414 - val_accuracy: 0.2296\n",
            "Epoch 1786/10000\n",
            "453/453 [==============================] - 6s 12ms/step - loss: 2.2085 - accuracy: 0.2542 - val_loss: 2.3251 - val_accuracy: 0.2449\n",
            "Epoch 1787/10000\n",
            "453/453 [==============================] - 5s 12ms/step - loss: 2.2035 - accuracy: 0.2562 - val_loss: 2.3450 - val_accuracy: 0.2344\n",
            "Epoch 1788/10000\n",
            "265/453 [================>.............] - ETA: 2s - loss: 2.2068 - accuracy: 0.2559"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-acc8bdfc8faf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m hist = model_NN.fit(x=X_train, y=y_train, batch_size = 64, epochs=10000,\n\u001b[0;32m----> 7\u001b[0;31m                  validation_data=(X_validation, y_validation))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_accuracy_score(y_validation, model_NN.predict(X_validation), labels = np.arange(0,26,1))"
      ],
      "metadata": {
        "id": "HtAqZ2Z4-Ua_",
        "outputId": "fa9680c0-7ed0-4855-e89b-cb862bdb55ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11916193801833261"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ]
}