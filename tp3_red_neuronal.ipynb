{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKMHMfaHCGIE/GqTPLkVat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nacho2904/orga_de_datos/blob/main/tp3_red_neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h_aJs-4Im0Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c566f85-ada8-46a1-fe57-bb0393023979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from google.colab import drive \n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import functools\n",
        "drive.mount('/content/gdrive')\n",
        "path_a_training_set = 'gdrive/MyDrive/TP3 dataset music/train.parquet'\n",
        "path_a_test_set = 'gdrive/MyDrive/TP3 dataset music/test.parquet'\n",
        "\n",
        "\n",
        "df_music_train = pd.read_parquet(path_a_training_set).fillna(\"\")\n",
        "df_music_test = pd.read_parquet(path_a_test_set).fillna(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "fwptY_P6y2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "def apply_sentiment_analysis_to_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  negative, neutral, positive, compound = 0, 1, 2, 3\n",
        "  sentimentAnalysisOfLyrics = df_music[\"lyric\"].map(lambda lyric: list(sia.polarity_scores(lyric).values()))\n",
        "  negativeScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[negative])\n",
        "  positiveScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[positive])\n",
        "  neutralScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[neutral])\n",
        "  compoundScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[compound])\n",
        "  return pd.DataFrame(pd.concat([negativeScoreOfLyrics, positiveScoreOfLyrics,neutralScoreOfLyrics,compoundScoreOfLyrics], axis = 1))"
      ],
      "metadata": {
        "id": "hMMWFU6D4BON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c225e55-8562-4f3e-8f94-668f4ebf2426"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "genres = list(df_music_train[\"genre\"].unique())\n",
        "def get_vectorizers_by_genre(df_music: pd.DataFrame) -> dict:\n",
        "  df_music_lyric_tokenized = df_music.copy().fillna(\"\")\n",
        "  df_music_lyric_tokenized[\"lyric\"] = df_music_lyric_tokenized[\"lyric\"].map(lambda lyric: set(nltk.word_tokenize(lyric)))\n",
        "  df_music_grouped_by_genre = df_music_lyric_tokenized[[\"genre\", \"lyric\"]].groupby('genre').agg(lambda x: functools.reduce(set.union, x)).reset_index()\n",
        "  vocabs = dict(zip(df_music_grouped_by_genre.genre.to_list(), df_music_grouped_by_genre.lyric.to_list()))\n",
        "  stopwords = set(nltk.corpus.stopwords.words(\"english\")).union(set(nltk.corpus.stopwords.words(\"spanish\"))).union(set(nltk.corpus.stopwords.words(\"french\")))\n",
        "  vectorizers = {genre: TfidfVectorizer(input = \"content\", stop_words = stopwords, vocabulary = vocabs[genre]) for genre in genres}\n",
        "  for genre in genres:\n",
        "    vectorizers[genre].fit(df_music[df_music[\"genre\"] == genre][\"genre\"])\n",
        "  return vectorizers\n",
        "\n",
        "vectorizers = get_vectorizers_by_genre(df_music_train)"
      ],
      "metadata": {
        "id": "UuLe4UY82Fv9",
        "outputId": "89ccc5de-3a06-4d86-c31c-2531be6ab400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1323: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
            "  \"Upper case characters found in\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_tfidf_from_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music = df_music.fillna(\"\")\n",
        "  column_names = [\"sum_tfidf_for_\" + genre.lower() for genre in genres]\n",
        "  for i in range(0, len(genres)):\n",
        "    df_music[column_names[i]] = np.sum(vectorizers[genres[i]].transform(df_music[\"lyric\"]), axis = 1)\n",
        "  return df_music[column_names]"
      ],
      "metadata": {
        "id": "Hn7ojEFq-YXi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_genres_without_enough_observations(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music_recuento_filas_por_genero = df_music.groupby(\"genre\").count().reset_index()[[\"genre\", \"track_name\"]].rename(\n",
        "    columns = {\"track_name\": \"rowCount\"}).sort_values(\"rowCount\")\n",
        "  problematic_genres = list(df_music_recuento_filas_por_genero[df_music_recuento_filas_por_genero[\"rowCount\"] < 50].genre)[1:]\n",
        "  return df_music[~df_music[\"genre\"].isin(problematic_genres)]"
      ],
      "metadata": {
        "id": "TQCnc16lQAxu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "def get_length_transforms_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"number_of_lines\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric.split(\"\\n\")))\n",
        "  df_music[\"number_of_tokens\"] = df_music[\"lyric\"].map(lambda lyric: len(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"length_lyrics\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric))\n",
        "  df_music[\"length_of_track_name\"] = df_music[\"track_name\"].map(lambda track_name: len(track_name))\n",
        "  return df_music[[\"length_lyrics\", \"length_of_track_name\", \"number_of_lines\", \"number_of_tokens\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1QqQUHIEHzj",
        "outputId": "15a54e1f-dfd1-4513-dc69-4620917f80bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_POS_vector_from_lyric_POS(lyric_POS):\n",
        "  useful_pos_tags = [\"FW\", \"JJR\", \"NN\", \"NNS\", \"NNP\", \"PDT\", \"PRP\", \"RB\", \"RBR\",\n",
        "                   \"UH\", \"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"]\n",
        "  POS_dictionary = {pos_tag:0 for pos_tag in useful_pos_tags}\n",
        "  POS_dictionary.update({\"other\":0})\n",
        "\n",
        "  for token in lyric_POS:\n",
        "    if token[1] in useful_pos_tags:\n",
        "      POS_dictionary[token[1]] += 1\n",
        "    else:\n",
        "      POS_dictionary[\"other\"] += 1\n",
        "\n",
        "  return [POS_dictionary[pos_tag] for pos_tag in POS_dictionary]\n",
        "  \n",
        "\n",
        "def get_POS_chunk_taggin_counts_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric\"].map(lambda lyric: nltk.pos_tag(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric_POS\"].map(lambda lyric_pos: get_POS_vector_from_lyric_POS(lyric_pos))\n",
        "  return pd.DataFrame(df_music[\"lyric_POS\"].to_list())\n"
      ],
      "metadata": {
        "id": "LOEyM2E-Ny6P",
        "outputId": "939bbe6a-26d3-4d40-8c89-eb85334fb6a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_music_filtered_genres = eliminate_genres_without_enough_observations(df_music_train)\n",
        "artists = list(df_music_filtered_genres[\"artist\"].unique())\n",
        "train_artists = set(artists[:int(0.9*len(artists))])\n",
        "validation_artists = set(artists[int(0.9*len(artists)):])\n",
        "train_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(train_artists)]\n",
        "validation_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(validation_artists)]"
      ],
      "metadata": {
        "id": "0WXfDLhA174X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_hot_encoder(df_music: pd.DataFrame, df_training: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_training_grouped_by_lang = df_training.groupby(\"language\").mean().reset_index()[[\"language\", \"popularity\", \"a_popularity\", \"loudness\"]]\n",
        "  df_new_columns = df_music.merge(df_training_grouped_by_lang, on = \"language\", how = \"left\")\n",
        "  return df_new_columns[[\"popularity_y\", \"a_popularity_y\", \"loudness_y\"]].fillna(0)\n",
        "\n",
        "mean_hot_encoder_using_training_set = lambda df_to_encode: mean_hot_encoder(df_to_encode, df_music_train) "
      ],
      "metadata": {
        "id": "wG1TiABKECHD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "text_features = [\"track_name\", \"lyric\", \"artist\"]\n",
        "\n",
        "numerical_features = [\"a_songs\", \"a_popularity\", \"popularity\", \"acousticness\", \"danceability\", \"duration_ms\",\n",
        "                   \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\"]\n",
        "\n",
        "ordinal_features = [\"key\", \"time_signature\"]\n",
        "\n",
        "one_hot_features = [\"mode\"]\n",
        "\n",
        "mean_enc_features = [\"language\"]\n",
        "\n",
        "artist_genres = [\"a_genres\", \"genre\"]\n",
        "\n",
        "label = [\"genre\"]\n",
        "\n",
        "identity_transformer = preprocessing.FunctionTransformer(None)\n",
        "\n",
        "full_processor = ColumnTransformer(transformers=[\n",
        "    ('text_sentiment_analysis', preprocessing.FunctionTransformer(apply_sentiment_analysis_to_lyrics), text_features),\n",
        "    ('text_tf_idf', preprocessing.FunctionTransformer(get_sum_tfidf_from_lyrics), text_features),\n",
        "    ('text_simple_transforms', preprocessing.FunctionTransformer(get_length_transforms_for_text), text_features),\n",
        "    ('text_POS_count', preprocessing.FunctionTransformer(get_POS_chunk_taggin_counts_for_text), text_features),\n",
        "    ('mean_encoding', preprocessing.FunctionTransformer(mean_hot_encoder_using_training_set), list(df_music_train.columns)),\n",
        "    ('one_hot_encoding', preprocessing.OneHotEncoder(), one_hot_features),\n",
        "    ('numerical', identity_transformer, numerical_features),\n",
        "    ('ordinal', preprocessing.OrdinalEncoder(categories = [['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'],\n",
        "                                                            ['1/4', '3/4', '4/4', '5/4']]), ordinal_features)])\n"
      ],
      "metadata": {
        "id": "ApBgPVOuocwU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Red Neuronal"
      ],
      "metadata": {
        "id": "h4qA0iu40-GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = full_processor.fit_transform(train_set)"
      ],
      "metadata": {
        "id": "2BSfUO_v1aEl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "label_encoder.fit(train_set.genre)\n",
        "y_train = label_encoder.transform(train_set.genre)\n",
        "X_validation = full_processor.transform(validation_set)\n",
        "y_validation = label_encoder.transform(validation_set.genre)"
      ],
      "metadata": {
        "id": "k58Z638pgVV2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_weights(model):\n",
        "    for l in model.layers:\n",
        "        if hasattr(l,\"kernel_initializer\"):\n",
        "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
        "        if hasattr(l,\"bias_initializer\"):\n",
        "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
        "        if hasattr(l,\"recurrent_initializer\"):\n",
        "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))\n"
      ],
      "metadata": {
        "id": "of1d2SgUqZRX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_columns = X_train.shape[1]\n",
        "num_classes = len(label_encoder.classes_)\n",
        "width = 30\n",
        "depth = 1\n",
        "activation = \"ReLU\"\n",
        "\n",
        "input = tf.keras.layers.Input(shape = (num_columns))\n",
        "normalize = tf.keras.layers.Normalization()(input)\n",
        "\n",
        "hidden_layers = [tf.keras.layers.Dense(width- int(0.3*i), activation = activation, kernel_initializer = tf.keras.initializers.HeNormal(),\n",
        "                                       kernel_constraint=tf.keras.constraints.MaxNorm(5))\n",
        "                  for i in range(0,depth)]\n",
        "\n",
        "for i in range(0, depth):\n",
        "  if i==0:\n",
        "    hidden_layers[i] = hidden_layers[i](input)\n",
        "  else:\n",
        "    hidden_layers[i] = hidden_layers[i](hidden_layers[i-1])\n",
        "\n",
        "\n",
        "output = tf.keras.layers.Dense(units = num_classes, activation = \"softmax\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.L1(0.001),\n",
        "                               bias_regularizer=tf.keras.regularizers.L1(0.001))(hidden_layers[-1])\n",
        "model_NN = tf.keras.models.Model(inputs = input, outputs = output)\n",
        "model_NN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yL7Q5xQougL",
        "outputId": "018f0a20-3588-4100-e535-2773494a002b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 71)]              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 30)                2160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 21)                651       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,811\n",
            "Trainable params: 2,811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_weights(model_NN)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=250, restore_best_weights = True)\n",
        "model_NN.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate = 0.000025),loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                 metrics = [\"accuracy\"])\n",
        "\n",
        "hist = model_NN.fit(x=X_train, y=y_train, batch_size = 64, epochs=2500, callbacks = [es],\n",
        "                 validation_data=(X_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE71MNcLqKzP",
        "outputId": "fb577889-9008-458b-ec23-ace8ef056e5a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2500\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 51821.6445 - accuracy: 0.0184 - val_loss: 49433.2305 - val_accuracy: 0.0039\n",
            "Epoch 2/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 35428.3398 - accuracy: 0.0439 - val_loss: 35386.4453 - val_accuracy: 0.0179\n",
            "Epoch 3/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 25102.5117 - accuracy: 0.0460 - val_loss: 24206.1289 - val_accuracy: 0.0157\n",
            "Epoch 4/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 16006.0752 - accuracy: 0.0360 - val_loss: 13713.8125 - val_accuracy: 0.0131\n",
            "Epoch 5/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8094.9663 - accuracy: 0.0241 - val_loss: 6063.3594 - val_accuracy: 0.0157\n",
            "Epoch 6/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 3639.8867 - accuracy: 0.0326 - val_loss: 3019.5505 - val_accuracy: 0.0345\n",
            "Epoch 7/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 1459.2217 - accuracy: 0.0367 - val_loss: 607.0683 - val_accuracy: 0.0546\n",
            "Epoch 8/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 461.1700 - accuracy: 0.0488 - val_loss: 302.8593 - val_accuracy: 0.0249\n",
            "Epoch 9/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 339.3150 - accuracy: 0.0487 - val_loss: 92.6033 - val_accuracy: 0.0594\n",
            "Epoch 10/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 269.8400 - accuracy: 0.0505 - val_loss: 89.7386 - val_accuracy: 0.0415\n",
            "Epoch 11/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 237.3208 - accuracy: 0.0517 - val_loss: 82.5275 - val_accuracy: 0.0533\n",
            "Epoch 12/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 205.6527 - accuracy: 0.0545 - val_loss: 69.2800 - val_accuracy: 0.0388\n",
            "Epoch 13/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 174.6767 - accuracy: 0.0575 - val_loss: 69.6546 - val_accuracy: 0.0733\n",
            "Epoch 14/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 145.1596 - accuracy: 0.0639 - val_loss: 68.2605 - val_accuracy: 0.0362\n",
            "Epoch 15/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 115.8267 - accuracy: 0.0704 - val_loss: 53.4086 - val_accuracy: 0.0550\n",
            "Epoch 16/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 86.9529 - accuracy: 0.0715 - val_loss: 52.9713 - val_accuracy: 0.0441\n",
            "Epoch 17/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 59.4660 - accuracy: 0.0768 - val_loss: 44.3233 - val_accuracy: 0.0585\n",
            "Epoch 18/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 49.2589 - accuracy: 0.0801 - val_loss: 39.4581 - val_accuracy: 0.0908\n",
            "Epoch 19/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 44.8825 - accuracy: 0.0850 - val_loss: 35.9127 - val_accuracy: 0.0624\n",
            "Epoch 20/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 41.4766 - accuracy: 0.0870 - val_loss: 36.6468 - val_accuracy: 0.0546\n",
            "Epoch 21/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 38.9980 - accuracy: 0.0958 - val_loss: 34.4585 - val_accuracy: 0.0659\n",
            "Epoch 22/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 37.1351 - accuracy: 0.0987 - val_loss: 32.1675 - val_accuracy: 0.0755\n",
            "Epoch 23/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 35.8459 - accuracy: 0.1024 - val_loss: 32.4788 - val_accuracy: 0.1104\n",
            "Epoch 24/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 34.7213 - accuracy: 0.1071 - val_loss: 32.9276 - val_accuracy: 0.0519\n",
            "Epoch 25/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 33.7066 - accuracy: 0.1093 - val_loss: 31.2827 - val_accuracy: 0.0677\n",
            "Epoch 26/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 32.5200 - accuracy: 0.1144 - val_loss: 27.8027 - val_accuracy: 0.0576\n",
            "Epoch 27/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 31.5970 - accuracy: 0.1158 - val_loss: 30.1281 - val_accuracy: 0.0777\n",
            "Epoch 28/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 30.7245 - accuracy: 0.1154 - val_loss: 30.7032 - val_accuracy: 0.0467\n",
            "Epoch 29/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 29.8935 - accuracy: 0.1191 - val_loss: 29.8966 - val_accuracy: 0.0646\n",
            "Epoch 30/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 28.9859 - accuracy: 0.1181 - val_loss: 27.4776 - val_accuracy: 0.1069\n",
            "Epoch 31/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 28.2216 - accuracy: 0.1213 - val_loss: 25.2378 - val_accuracy: 0.0816\n",
            "Epoch 32/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 27.4634 - accuracy: 0.1206 - val_loss: 26.3118 - val_accuracy: 0.1135\n",
            "Epoch 33/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 26.6664 - accuracy: 0.1218 - val_loss: 26.7189 - val_accuracy: 0.0637\n",
            "Epoch 34/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 26.0470 - accuracy: 0.1233 - val_loss: 26.5150 - val_accuracy: 0.1091\n",
            "Epoch 35/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 25.2895 - accuracy: 0.1285 - val_loss: 24.3245 - val_accuracy: 0.0877\n",
            "Epoch 36/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 24.7030 - accuracy: 0.1271 - val_loss: 24.7597 - val_accuracy: 0.0659\n",
            "Epoch 37/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 24.1332 - accuracy: 0.1288 - val_loss: 22.6947 - val_accuracy: 0.0969\n",
            "Epoch 38/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 23.4814 - accuracy: 0.1312 - val_loss: 25.3671 - val_accuracy: 0.0829\n",
            "Epoch 39/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 22.9486 - accuracy: 0.1311 - val_loss: 24.1939 - val_accuracy: 0.0642\n",
            "Epoch 40/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 22.3441 - accuracy: 0.1340 - val_loss: 21.2283 - val_accuracy: 0.1021\n",
            "Epoch 41/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 21.7961 - accuracy: 0.1333 - val_loss: 20.1411 - val_accuracy: 0.0886\n",
            "Epoch 42/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 21.3541 - accuracy: 0.1337 - val_loss: 20.3140 - val_accuracy: 0.0742\n",
            "Epoch 43/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 20.9385 - accuracy: 0.1351 - val_loss: 22.1294 - val_accuracy: 0.1109\n",
            "Epoch 44/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 20.4854 - accuracy: 0.1363 - val_loss: 22.1552 - val_accuracy: 0.0629\n",
            "Epoch 45/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 19.9972 - accuracy: 0.1387 - val_loss: 21.3980 - val_accuracy: 0.0886\n",
            "Epoch 46/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 19.7508 - accuracy: 0.1367 - val_loss: 19.2796 - val_accuracy: 0.0764\n",
            "Epoch 47/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 19.1383 - accuracy: 0.1385 - val_loss: 19.6572 - val_accuracy: 0.0777\n",
            "Epoch 48/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 18.8655 - accuracy: 0.1394 - val_loss: 19.3678 - val_accuracy: 0.0982\n",
            "Epoch 49/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 18.5112 - accuracy: 0.1380 - val_loss: 22.1558 - val_accuracy: 0.0493\n",
            "Epoch 50/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 18.2406 - accuracy: 0.1401 - val_loss: 20.2988 - val_accuracy: 0.0938\n",
            "Epoch 51/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 17.8500 - accuracy: 0.1415 - val_loss: 19.3894 - val_accuracy: 0.0624\n",
            "Epoch 52/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 17.4868 - accuracy: 0.1407 - val_loss: 18.2950 - val_accuracy: 0.1183\n",
            "Epoch 53/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 17.1989 - accuracy: 0.1412 - val_loss: 18.7579 - val_accuracy: 0.0995\n",
            "Epoch 54/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 16.9660 - accuracy: 0.1412 - val_loss: 19.2565 - val_accuracy: 0.1126\n",
            "Epoch 55/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 16.6261 - accuracy: 0.1427 - val_loss: 16.8301 - val_accuracy: 0.1196\n",
            "Epoch 56/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 16.3965 - accuracy: 0.1449 - val_loss: 17.4766 - val_accuracy: 0.0890\n",
            "Epoch 57/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 16.2770 - accuracy: 0.1451 - val_loss: 15.9200 - val_accuracy: 0.1148\n",
            "Epoch 58/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 15.7777 - accuracy: 0.1459 - val_loss: 17.4540 - val_accuracy: 0.0559\n",
            "Epoch 59/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 15.5263 - accuracy: 0.1466 - val_loss: 17.7230 - val_accuracy: 0.0895\n",
            "Epoch 60/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 15.2850 - accuracy: 0.1496 - val_loss: 17.5388 - val_accuracy: 0.0982\n",
            "Epoch 61/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 15.0332 - accuracy: 0.1492 - val_loss: 16.7083 - val_accuracy: 0.1353\n",
            "Epoch 62/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 14.9127 - accuracy: 0.1478 - val_loss: 19.6826 - val_accuracy: 0.0921\n",
            "Epoch 63/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 14.7107 - accuracy: 0.1490 - val_loss: 17.8240 - val_accuracy: 0.1279\n",
            "Epoch 64/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 14.4114 - accuracy: 0.1490 - val_loss: 17.2389 - val_accuracy: 0.1061\n",
            "Epoch 65/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 14.0509 - accuracy: 0.1512 - val_loss: 17.4439 - val_accuracy: 0.0589\n",
            "Epoch 66/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 13.9393 - accuracy: 0.1538 - val_loss: 18.4521 - val_accuracy: 0.0445\n",
            "Epoch 67/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 13.7861 - accuracy: 0.1541 - val_loss: 14.9622 - val_accuracy: 0.1034\n",
            "Epoch 68/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 13.6139 - accuracy: 0.1521 - val_loss: 15.2410 - val_accuracy: 0.0825\n",
            "Epoch 69/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 13.3796 - accuracy: 0.1530 - val_loss: 13.9879 - val_accuracy: 0.0860\n",
            "Epoch 70/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 13.2896 - accuracy: 0.1530 - val_loss: 14.6115 - val_accuracy: 0.1275\n",
            "Epoch 71/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 13.0137 - accuracy: 0.1534 - val_loss: 13.6278 - val_accuracy: 0.1279\n",
            "Epoch 72/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 12.9209 - accuracy: 0.1522 - val_loss: 15.6465 - val_accuracy: 0.1122\n",
            "Epoch 73/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 12.6993 - accuracy: 0.1552 - val_loss: 16.8543 - val_accuracy: 0.0498\n",
            "Epoch 74/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 12.6525 - accuracy: 0.1527 - val_loss: 13.7850 - val_accuracy: 0.1091\n",
            "Epoch 75/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 12.4619 - accuracy: 0.1538 - val_loss: 18.9558 - val_accuracy: 0.0629\n",
            "Epoch 76/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 12.2410 - accuracy: 0.1541 - val_loss: 12.2559 - val_accuracy: 0.1235\n",
            "Epoch 77/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 12.1338 - accuracy: 0.1539 - val_loss: 14.5883 - val_accuracy: 0.0786\n",
            "Epoch 78/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 11.9021 - accuracy: 0.1567 - val_loss: 13.4771 - val_accuracy: 0.1362\n",
            "Epoch 79/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 11.7515 - accuracy: 0.1593 - val_loss: 14.0868 - val_accuracy: 0.1091\n",
            "Epoch 80/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 11.7653 - accuracy: 0.1583 - val_loss: 14.0947 - val_accuracy: 0.0406\n",
            "Epoch 81/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 11.5025 - accuracy: 0.1605 - val_loss: 12.7062 - val_accuracy: 0.1475\n",
            "Epoch 82/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 11.3683 - accuracy: 0.1600 - val_loss: 14.9303 - val_accuracy: 0.0825\n",
            "Epoch 83/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 11.3878 - accuracy: 0.1575 - val_loss: 17.3857 - val_accuracy: 0.1301\n",
            "Epoch 84/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 11.3288 - accuracy: 0.1607 - val_loss: 12.9292 - val_accuracy: 0.1615\n",
            "Epoch 85/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 11.0541 - accuracy: 0.1571 - val_loss: 11.9977 - val_accuracy: 0.1283\n",
            "Epoch 86/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.9149 - accuracy: 0.1583 - val_loss: 12.9438 - val_accuracy: 0.1135\n",
            "Epoch 87/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.7742 - accuracy: 0.1631 - val_loss: 11.4503 - val_accuracy: 0.1165\n",
            "Epoch 88/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.6842 - accuracy: 0.1603 - val_loss: 11.3283 - val_accuracy: 0.1266\n",
            "Epoch 89/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.7525 - accuracy: 0.1595 - val_loss: 11.5721 - val_accuracy: 0.1144\n",
            "Epoch 90/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.5481 - accuracy: 0.1583 - val_loss: 12.7053 - val_accuracy: 0.1078\n",
            "Epoch 91/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.4063 - accuracy: 0.1648 - val_loss: 12.0964 - val_accuracy: 0.1261\n",
            "Epoch 92/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.3902 - accuracy: 0.1641 - val_loss: 13.6914 - val_accuracy: 0.1336\n",
            "Epoch 93/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.2562 - accuracy: 0.1649 - val_loss: 11.9432 - val_accuracy: 0.0799\n",
            "Epoch 94/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 10.1310 - accuracy: 0.1646 - val_loss: 14.6622 - val_accuracy: 0.0882\n",
            "Epoch 95/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.9787 - accuracy: 0.1638 - val_loss: 14.6172 - val_accuracy: 0.1048\n",
            "Epoch 96/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.9007 - accuracy: 0.1617 - val_loss: 11.6684 - val_accuracy: 0.1379\n",
            "Epoch 97/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 9.9503 - accuracy: 0.1656 - val_loss: 10.5793 - val_accuracy: 0.0808\n",
            "Epoch 98/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.7289 - accuracy: 0.1664 - val_loss: 11.8913 - val_accuracy: 0.1318\n",
            "Epoch 99/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.7197 - accuracy: 0.1651 - val_loss: 12.2579 - val_accuracy: 0.0506\n",
            "Epoch 100/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.5865 - accuracy: 0.1673 - val_loss: 9.9348 - val_accuracy: 0.1069\n",
            "Epoch 101/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.5853 - accuracy: 0.1675 - val_loss: 11.5577 - val_accuracy: 0.0877\n",
            "Epoch 102/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.4555 - accuracy: 0.1665 - val_loss: 10.1080 - val_accuracy: 0.0873\n",
            "Epoch 103/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.4104 - accuracy: 0.1672 - val_loss: 13.4407 - val_accuracy: 0.0755\n",
            "Epoch 104/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.2724 - accuracy: 0.1662 - val_loss: 12.0180 - val_accuracy: 0.1454\n",
            "Epoch 105/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.3098 - accuracy: 0.1656 - val_loss: 10.0407 - val_accuracy: 0.1100\n",
            "Epoch 106/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.0115 - accuracy: 0.1675 - val_loss: 9.6086 - val_accuracy: 0.1034\n",
            "Epoch 107/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 9.1274 - accuracy: 0.1663 - val_loss: 11.0374 - val_accuracy: 0.1270\n",
            "Epoch 108/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 9.1079 - accuracy: 0.1645 - val_loss: 10.6042 - val_accuracy: 0.1384\n",
            "Epoch 109/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.8199 - accuracy: 0.1690 - val_loss: 12.4489 - val_accuracy: 0.0856\n",
            "Epoch 110/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.7450 - accuracy: 0.1733 - val_loss: 10.2044 - val_accuracy: 0.1000\n",
            "Epoch 111/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.8340 - accuracy: 0.1676 - val_loss: 11.2398 - val_accuracy: 0.1362\n",
            "Epoch 112/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.6788 - accuracy: 0.1692 - val_loss: 10.4374 - val_accuracy: 0.0685\n",
            "Epoch 113/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.8984 - accuracy: 0.1685 - val_loss: 11.4649 - val_accuracy: 0.0690\n",
            "Epoch 114/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.6574 - accuracy: 0.1709 - val_loss: 11.3037 - val_accuracy: 0.0694\n",
            "Epoch 115/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.5796 - accuracy: 0.1692 - val_loss: 15.6004 - val_accuracy: 0.0585\n",
            "Epoch 116/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.6774 - accuracy: 0.1717 - val_loss: 9.8262 - val_accuracy: 0.1432\n",
            "Epoch 117/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.3429 - accuracy: 0.1738 - val_loss: 9.1210 - val_accuracy: 0.1152\n",
            "Epoch 118/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.2815 - accuracy: 0.1721 - val_loss: 9.3140 - val_accuracy: 0.0834\n",
            "Epoch 119/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.4054 - accuracy: 0.1731 - val_loss: 9.0924 - val_accuracy: 0.1427\n",
            "Epoch 120/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.1783 - accuracy: 0.1718 - val_loss: 12.7448 - val_accuracy: 0.1087\n",
            "Epoch 121/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.1712 - accuracy: 0.1761 - val_loss: 8.2356 - val_accuracy: 0.1510\n",
            "Epoch 122/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 8.0687 - accuracy: 0.1754 - val_loss: 9.9690 - val_accuracy: 0.0834\n",
            "Epoch 123/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.2427 - accuracy: 0.1727 - val_loss: 10.0111 - val_accuracy: 0.1109\n",
            "Epoch 124/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 8.1469 - accuracy: 0.1761 - val_loss: 8.8327 - val_accuracy: 0.0768\n",
            "Epoch 125/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.9541 - accuracy: 0.1782 - val_loss: 9.1259 - val_accuracy: 0.1384\n",
            "Epoch 126/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.9168 - accuracy: 0.1762 - val_loss: 9.9670 - val_accuracy: 0.0947\n",
            "Epoch 127/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.8622 - accuracy: 0.1741 - val_loss: 10.0281 - val_accuracy: 0.0904\n",
            "Epoch 128/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.8308 - accuracy: 0.1743 - val_loss: 10.6315 - val_accuracy: 0.1087\n",
            "Epoch 129/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.8194 - accuracy: 0.1790 - val_loss: 8.1751 - val_accuracy: 0.1689\n",
            "Epoch 130/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.5784 - accuracy: 0.1784 - val_loss: 7.7883 - val_accuracy: 0.1078\n",
            "Epoch 131/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.7790 - accuracy: 0.1766 - val_loss: 9.9722 - val_accuracy: 0.0690\n",
            "Epoch 132/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.8693 - accuracy: 0.1765 - val_loss: 11.7757 - val_accuracy: 0.1318\n",
            "Epoch 133/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.5726 - accuracy: 0.1759 - val_loss: 9.0900 - val_accuracy: 0.1144\n",
            "Epoch 134/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.5763 - accuracy: 0.1790 - val_loss: 11.0875 - val_accuracy: 0.0690\n",
            "Epoch 135/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.4645 - accuracy: 0.1799 - val_loss: 8.4541 - val_accuracy: 0.1061\n",
            "Epoch 136/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.5464 - accuracy: 0.1790 - val_loss: 12.7168 - val_accuracy: 0.1353\n",
            "Epoch 137/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.7341 - accuracy: 0.1782 - val_loss: 9.5972 - val_accuracy: 0.0869\n",
            "Epoch 138/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.3821 - accuracy: 0.1770 - val_loss: 9.0202 - val_accuracy: 0.1113\n",
            "Epoch 139/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.4901 - accuracy: 0.1802 - val_loss: 7.6344 - val_accuracy: 0.1371\n",
            "Epoch 140/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.4851 - accuracy: 0.1768 - val_loss: 9.7037 - val_accuracy: 0.0995\n",
            "Epoch 141/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.3727 - accuracy: 0.1784 - val_loss: 10.2847 - val_accuracy: 0.1183\n",
            "Epoch 142/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.2656 - accuracy: 0.1815 - val_loss: 8.9777 - val_accuracy: 0.1148\n",
            "Epoch 143/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.4567 - accuracy: 0.1773 - val_loss: 9.2166 - val_accuracy: 0.1427\n",
            "Epoch 144/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.1806 - accuracy: 0.1805 - val_loss: 8.1452 - val_accuracy: 0.0716\n",
            "Epoch 145/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.1407 - accuracy: 0.1807 - val_loss: 7.9952 - val_accuracy: 0.1680\n",
            "Epoch 146/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.6564 - accuracy: 0.1787 - val_loss: 8.7632 - val_accuracy: 0.1091\n",
            "Epoch 147/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.4117 - accuracy: 0.1799 - val_loss: 11.2000 - val_accuracy: 0.1366\n",
            "Epoch 148/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.0395 - accuracy: 0.1826 - val_loss: 7.2331 - val_accuracy: 0.1855\n",
            "Epoch 149/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.1888 - accuracy: 0.1827 - val_loss: 8.9667 - val_accuracy: 0.0973\n",
            "Epoch 150/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.1364 - accuracy: 0.1842 - val_loss: 8.6179 - val_accuracy: 0.0917\n",
            "Epoch 151/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.9763 - accuracy: 0.1849 - val_loss: 8.7659 - val_accuracy: 0.0882\n",
            "Epoch 152/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.1736 - accuracy: 0.1828 - val_loss: 8.8584 - val_accuracy: 0.1528\n",
            "Epoch 153/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.0317 - accuracy: 0.1851 - val_loss: 9.4533 - val_accuracy: 0.1454\n",
            "Epoch 154/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.9426 - accuracy: 0.1850 - val_loss: 6.7964 - val_accuracy: 0.1126\n",
            "Epoch 155/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.2172 - accuracy: 0.1841 - val_loss: 7.2385 - val_accuracy: 0.1973\n",
            "Epoch 156/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.8691 - accuracy: 0.1863 - val_loss: 12.6059 - val_accuracy: 0.0310\n",
            "Epoch 157/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.1975 - accuracy: 0.1823 - val_loss: 9.0958 - val_accuracy: 0.1615\n",
            "Epoch 158/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.9847 - accuracy: 0.1817 - val_loss: 7.7980 - val_accuracy: 0.1183\n",
            "Epoch 159/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6918 - accuracy: 0.1855 - val_loss: 6.5949 - val_accuracy: 0.1711\n",
            "Epoch 160/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 7.1556 - accuracy: 0.1839 - val_loss: 7.7651 - val_accuracy: 0.1078\n",
            "Epoch 161/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.8437 - accuracy: 0.1864 - val_loss: 8.8095 - val_accuracy: 0.1218\n",
            "Epoch 162/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.8676 - accuracy: 0.1861 - val_loss: 7.0513 - val_accuracy: 0.1462\n",
            "Epoch 163/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.6030 - accuracy: 0.1881 - val_loss: 12.9892 - val_accuracy: 0.0668\n",
            "Epoch 164/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 7.1134 - accuracy: 0.1852 - val_loss: 12.0871 - val_accuracy: 0.0781\n",
            "Epoch 165/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.7935 - accuracy: 0.1861 - val_loss: 8.7939 - val_accuracy: 0.1004\n",
            "Epoch 166/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6451 - accuracy: 0.1874 - val_loss: 7.3897 - val_accuracy: 0.1349\n",
            "Epoch 167/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.9584 - accuracy: 0.1852 - val_loss: 7.8607 - val_accuracy: 0.1305\n",
            "Epoch 168/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.8209 - accuracy: 0.1845 - val_loss: 8.7126 - val_accuracy: 0.1536\n",
            "Epoch 169/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5330 - accuracy: 0.1890 - val_loss: 7.3687 - val_accuracy: 0.1052\n",
            "Epoch 170/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.9603 - accuracy: 0.1859 - val_loss: 8.8902 - val_accuracy: 0.0812\n",
            "Epoch 171/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6525 - accuracy: 0.1860 - val_loss: 8.7113 - val_accuracy: 0.0895\n",
            "Epoch 172/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5852 - accuracy: 0.1846 - val_loss: 6.8830 - val_accuracy: 0.1301\n",
            "Epoch 173/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.8414 - accuracy: 0.1844 - val_loss: 7.6594 - val_accuracy: 0.1405\n",
            "Epoch 174/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4820 - accuracy: 0.1924 - val_loss: 11.3655 - val_accuracy: 0.0493\n",
            "Epoch 175/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.8597 - accuracy: 0.1887 - val_loss: 6.7346 - val_accuracy: 0.1921\n",
            "Epoch 176/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6990 - accuracy: 0.1846 - val_loss: 6.3337 - val_accuracy: 0.1314\n",
            "Epoch 177/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5966 - accuracy: 0.1880 - val_loss: 7.2682 - val_accuracy: 0.1405\n",
            "Epoch 178/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.5085 - accuracy: 0.1866 - val_loss: 10.8885 - val_accuracy: 0.1528\n",
            "Epoch 179/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.5759 - accuracy: 0.1906 - val_loss: 9.5032 - val_accuracy: 0.0952\n",
            "Epoch 180/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.7245 - accuracy: 0.1887 - val_loss: 7.4418 - val_accuracy: 0.0982\n",
            "Epoch 181/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.7017 - accuracy: 0.1834 - val_loss: 7.3383 - val_accuracy: 0.0882\n",
            "Epoch 182/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4723 - accuracy: 0.1888 - val_loss: 7.6955 - val_accuracy: 0.1048\n",
            "Epoch 183/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5134 - accuracy: 0.1859 - val_loss: 6.0169 - val_accuracy: 0.1401\n",
            "Epoch 184/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5350 - accuracy: 0.1891 - val_loss: 8.9337 - val_accuracy: 0.1344\n",
            "Epoch 185/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5992 - accuracy: 0.1872 - val_loss: 9.9050 - val_accuracy: 0.0720\n",
            "Epoch 186/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5069 - accuracy: 0.1914 - val_loss: 7.6291 - val_accuracy: 0.1266\n",
            "Epoch 187/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5728 - accuracy: 0.1890 - val_loss: 7.4574 - val_accuracy: 0.1100\n",
            "Epoch 188/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3265 - accuracy: 0.1909 - val_loss: 5.7375 - val_accuracy: 0.1458\n",
            "Epoch 189/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.8450 - accuracy: 0.1876 - val_loss: 7.2810 - val_accuracy: 0.1030\n",
            "Epoch 190/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6130 - accuracy: 0.1886 - val_loss: 8.5248 - val_accuracy: 0.1419\n",
            "Epoch 191/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4205 - accuracy: 0.1915 - val_loss: 5.2571 - val_accuracy: 0.1318\n",
            "Epoch 192/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5763 - accuracy: 0.1923 - val_loss: 8.8226 - val_accuracy: 0.0991\n",
            "Epoch 193/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.7643 - accuracy: 0.1863 - val_loss: 8.5742 - val_accuracy: 0.1069\n",
            "Epoch 194/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3008 - accuracy: 0.1904 - val_loss: 7.7225 - val_accuracy: 0.1139\n",
            "Epoch 195/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.2294 - accuracy: 0.1914 - val_loss: 5.1682 - val_accuracy: 0.1305\n",
            "Epoch 196/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.4413 - accuracy: 0.1891 - val_loss: 6.1493 - val_accuracy: 0.1283\n",
            "Epoch 197/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.6656 - accuracy: 0.1874 - val_loss: 7.5000 - val_accuracy: 0.1375\n",
            "Epoch 198/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4435 - accuracy: 0.1883 - val_loss: 8.5056 - val_accuracy: 0.1179\n",
            "Epoch 199/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.2226 - accuracy: 0.1949 - val_loss: 8.5755 - val_accuracy: 0.1432\n",
            "Epoch 200/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5742 - accuracy: 0.1924 - val_loss: 9.6537 - val_accuracy: 0.0615\n",
            "Epoch 201/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5509 - accuracy: 0.1879 - val_loss: 7.5211 - val_accuracy: 0.1192\n",
            "Epoch 202/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4234 - accuracy: 0.1877 - val_loss: 6.1545 - val_accuracy: 0.1309\n",
            "Epoch 203/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1663 - accuracy: 0.1913 - val_loss: 7.0368 - val_accuracy: 0.1327\n",
            "Epoch 204/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3927 - accuracy: 0.1883 - val_loss: 9.0436 - val_accuracy: 0.0773\n",
            "Epoch 205/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3981 - accuracy: 0.1916 - val_loss: 6.9339 - val_accuracy: 0.1200\n",
            "Epoch 206/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.3981 - accuracy: 0.1882 - val_loss: 7.8686 - val_accuracy: 0.1104\n",
            "Epoch 207/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0879 - accuracy: 0.1933 - val_loss: 6.4450 - val_accuracy: 0.1663\n",
            "Epoch 208/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.6254 - accuracy: 0.1890 - val_loss: 8.9240 - val_accuracy: 0.1275\n",
            "Epoch 209/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3374 - accuracy: 0.1945 - val_loss: 7.2881 - val_accuracy: 0.1061\n",
            "Epoch 210/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0006 - accuracy: 0.1930 - val_loss: 7.9859 - val_accuracy: 0.1405\n",
            "Epoch 211/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1452 - accuracy: 0.1947 - val_loss: 8.5096 - val_accuracy: 0.0986\n",
            "Epoch 212/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.5309 - accuracy: 0.1876 - val_loss: 9.3912 - val_accuracy: 0.0773\n",
            "Epoch 213/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2548 - accuracy: 0.1937 - val_loss: 5.2851 - val_accuracy: 0.1506\n",
            "Epoch 214/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.4558 - accuracy: 0.1861 - val_loss: 5.9920 - val_accuracy: 0.1659\n",
            "Epoch 215/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3792 - accuracy: 0.1915 - val_loss: 8.1619 - val_accuracy: 0.1523\n",
            "Epoch 216/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1463 - accuracy: 0.1903 - val_loss: 7.1172 - val_accuracy: 0.1096\n",
            "Epoch 217/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3754 - accuracy: 0.1918 - val_loss: 5.4313 - val_accuracy: 0.1654\n",
            "Epoch 218/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3183 - accuracy: 0.1855 - val_loss: 11.3883 - val_accuracy: 0.0917\n",
            "Epoch 219/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1407 - accuracy: 0.1921 - val_loss: 9.5834 - val_accuracy: 0.1580\n",
            "Epoch 220/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0626 - accuracy: 0.1918 - val_loss: 9.1343 - val_accuracy: 0.0633\n",
            "Epoch 221/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2794 - accuracy: 0.1904 - val_loss: 7.1478 - val_accuracy: 0.1270\n",
            "Epoch 222/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.3022 - accuracy: 0.1917 - val_loss: 6.4515 - val_accuracy: 0.1484\n",
            "Epoch 223/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2786 - accuracy: 0.1910 - val_loss: 7.5179 - val_accuracy: 0.1405\n",
            "Epoch 224/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4672 - accuracy: 0.1885 - val_loss: 11.4348 - val_accuracy: 0.1240\n",
            "Epoch 225/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5384 - accuracy: 0.1873 - val_loss: 8.2169 - val_accuracy: 0.0729\n",
            "Epoch 226/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3108 - accuracy: 0.1908 - val_loss: 6.0489 - val_accuracy: 0.1798\n",
            "Epoch 227/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0893 - accuracy: 0.1974 - val_loss: 8.9412 - val_accuracy: 0.1528\n",
            "Epoch 228/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1287 - accuracy: 0.1952 - val_loss: 7.8639 - val_accuracy: 0.1305\n",
            "Epoch 229/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1297 - accuracy: 0.1938 - val_loss: 9.0339 - val_accuracy: 0.0877\n",
            "Epoch 230/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2770 - accuracy: 0.1884 - val_loss: 6.9430 - val_accuracy: 0.1218\n",
            "Epoch 231/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.4117 - accuracy: 0.1888 - val_loss: 9.4318 - val_accuracy: 0.1646\n",
            "Epoch 232/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1076 - accuracy: 0.1902 - val_loss: 7.2463 - val_accuracy: 0.1109\n",
            "Epoch 233/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9921 - accuracy: 0.1937 - val_loss: 8.5810 - val_accuracy: 0.1296\n",
            "Epoch 234/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0913 - accuracy: 0.1921 - val_loss: 7.0513 - val_accuracy: 0.1004\n",
            "Epoch 235/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.3596 - accuracy: 0.1895 - val_loss: 5.0990 - val_accuracy: 0.1567\n",
            "Epoch 236/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3722 - accuracy: 0.1920 - val_loss: 10.2405 - val_accuracy: 0.0506\n",
            "Epoch 237/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.1791 - accuracy: 0.1917 - val_loss: 7.4357 - val_accuracy: 0.1598\n",
            "Epoch 238/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0440 - accuracy: 0.1912 - val_loss: 7.9555 - val_accuracy: 0.1798\n",
            "Epoch 239/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0494 - accuracy: 0.1942 - val_loss: 8.9639 - val_accuracy: 0.0908\n",
            "Epoch 240/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.0438 - accuracy: 0.1919 - val_loss: 8.6364 - val_accuracy: 0.1606\n",
            "Epoch 241/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1351 - accuracy: 0.1956 - val_loss: 6.8458 - val_accuracy: 0.1200\n",
            "Epoch 242/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3154 - accuracy: 0.1884 - val_loss: 9.1330 - val_accuracy: 0.1379\n",
            "Epoch 243/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9645 - accuracy: 0.1914 - val_loss: 6.4709 - val_accuracy: 0.0829\n",
            "Epoch 244/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.5180 - accuracy: 0.1883 - val_loss: 7.7409 - val_accuracy: 0.1091\n",
            "Epoch 245/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1928 - accuracy: 0.1948 - val_loss: 6.2411 - val_accuracy: 0.1798\n",
            "Epoch 246/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0637 - accuracy: 0.1922 - val_loss: 9.0377 - val_accuracy: 0.1301\n",
            "Epoch 247/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 6.0088 - accuracy: 0.1913 - val_loss: 5.7771 - val_accuracy: 0.1493\n",
            "Epoch 248/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1304 - accuracy: 0.1922 - val_loss: 6.3482 - val_accuracy: 0.1419\n",
            "Epoch 249/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4284 - accuracy: 0.1892 - val_loss: 8.4727 - val_accuracy: 0.1606\n",
            "Epoch 250/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2774 - accuracy: 0.1906 - val_loss: 6.2911 - val_accuracy: 0.1371\n",
            "Epoch 251/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9589 - accuracy: 0.1976 - val_loss: 6.0563 - val_accuracy: 0.1423\n",
            "Epoch 252/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1762 - accuracy: 0.1891 - val_loss: 9.0367 - val_accuracy: 0.0847\n",
            "Epoch 253/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0611 - accuracy: 0.1981 - val_loss: 6.4250 - val_accuracy: 0.0965\n",
            "Epoch 254/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0695 - accuracy: 0.1920 - val_loss: 6.2158 - val_accuracy: 0.1074\n",
            "Epoch 255/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3335 - accuracy: 0.1897 - val_loss: 6.8925 - val_accuracy: 0.1082\n",
            "Epoch 256/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0694 - accuracy: 0.1909 - val_loss: 8.9610 - val_accuracy: 0.0794\n",
            "Epoch 257/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7886 - accuracy: 0.1944 - val_loss: 5.2880 - val_accuracy: 0.1873\n",
            "Epoch 258/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1824 - accuracy: 0.1935 - val_loss: 12.0553 - val_accuracy: 0.0856\n",
            "Epoch 259/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0156 - accuracy: 0.1954 - val_loss: 5.5828 - val_accuracy: 0.1536\n",
            "Epoch 260/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4336 - accuracy: 0.1903 - val_loss: 8.0406 - val_accuracy: 0.1021\n",
            "Epoch 261/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9810 - accuracy: 0.1919 - val_loss: 7.7174 - val_accuracy: 0.1082\n",
            "Epoch 262/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1076 - accuracy: 0.1947 - val_loss: 7.2860 - val_accuracy: 0.1432\n",
            "Epoch 263/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2395 - accuracy: 0.1931 - val_loss: 4.9919 - val_accuracy: 0.1694\n",
            "Epoch 264/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0482 - accuracy: 0.1938 - val_loss: 8.7298 - val_accuracy: 0.0663\n",
            "Epoch 265/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3508 - accuracy: 0.1930 - val_loss: 8.5818 - val_accuracy: 0.0895\n",
            "Epoch 266/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9525 - accuracy: 0.2005 - val_loss: 5.1969 - val_accuracy: 0.1227\n",
            "Epoch 267/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3567 - accuracy: 0.1945 - val_loss: 7.0476 - val_accuracy: 0.1471\n",
            "Epoch 268/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1172 - accuracy: 0.1928 - val_loss: 6.2730 - val_accuracy: 0.1375\n",
            "Epoch 269/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9665 - accuracy: 0.1930 - val_loss: 6.2717 - val_accuracy: 0.1995\n",
            "Epoch 270/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2308 - accuracy: 0.1925 - val_loss: 11.2071 - val_accuracy: 0.1672\n",
            "Epoch 271/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7344 - accuracy: 0.1970 - val_loss: 6.3216 - val_accuracy: 0.0825\n",
            "Epoch 272/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1539 - accuracy: 0.1960 - val_loss: 5.0957 - val_accuracy: 0.1628\n",
            "Epoch 273/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2185 - accuracy: 0.1958 - val_loss: 5.7078 - val_accuracy: 0.0812\n",
            "Epoch 274/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0322 - accuracy: 0.1948 - val_loss: 7.2356 - val_accuracy: 0.0677\n",
            "Epoch 275/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9458 - accuracy: 0.1973 - val_loss: 7.1114 - val_accuracy: 0.1261\n",
            "Epoch 276/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1719 - accuracy: 0.1927 - val_loss: 6.1546 - val_accuracy: 0.1109\n",
            "Epoch 277/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.8884 - accuracy: 0.1944 - val_loss: 5.7722 - val_accuracy: 0.1069\n",
            "Epoch 278/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.9285 - accuracy: 0.1964 - val_loss: 4.9173 - val_accuracy: 0.1641\n",
            "Epoch 279/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 6.1870 - accuracy: 0.1937 - val_loss: 5.5305 - val_accuracy: 0.1825\n",
            "Epoch 280/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2802 - accuracy: 0.1920 - val_loss: 9.1236 - val_accuracy: 0.1021\n",
            "Epoch 281/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7547 - accuracy: 0.1992 - val_loss: 6.3247 - val_accuracy: 0.1392\n",
            "Epoch 282/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0307 - accuracy: 0.1972 - val_loss: 7.8421 - val_accuracy: 0.0969\n",
            "Epoch 283/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1824 - accuracy: 0.1893 - val_loss: 5.9171 - val_accuracy: 0.1606\n",
            "Epoch 284/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3161 - accuracy: 0.1949 - val_loss: 10.1399 - val_accuracy: 0.1405\n",
            "Epoch 285/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0908 - accuracy: 0.1938 - val_loss: 6.0864 - val_accuracy: 0.2038\n",
            "Epoch 286/2500\n",
            "453/453 [==============================] - 1s 2ms/step - loss: 5.7756 - accuracy: 0.1995 - val_loss: 6.8806 - val_accuracy: 0.1078\n",
            "Epoch 287/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1260 - accuracy: 0.1945 - val_loss: 9.1069 - val_accuracy: 0.0471\n",
            "Epoch 288/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9028 - accuracy: 0.1973 - val_loss: 7.7394 - val_accuracy: 0.0934\n",
            "Epoch 289/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0021 - accuracy: 0.1912 - val_loss: 8.1967 - val_accuracy: 0.1912\n",
            "Epoch 290/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8018 - accuracy: 0.1994 - val_loss: 5.1795 - val_accuracy: 0.2239\n",
            "Epoch 291/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8056 - accuracy: 0.1941 - val_loss: 7.9218 - val_accuracy: 0.1545\n",
            "Epoch 292/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0681 - accuracy: 0.1988 - val_loss: 5.7055 - val_accuracy: 0.1026\n",
            "Epoch 293/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0841 - accuracy: 0.1943 - val_loss: 5.0067 - val_accuracy: 0.1532\n",
            "Epoch 294/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0196 - accuracy: 0.1921 - val_loss: 5.3555 - val_accuracy: 0.1309\n",
            "Epoch 295/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0072 - accuracy: 0.1944 - val_loss: 5.8138 - val_accuracy: 0.1659\n",
            "Epoch 296/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1433 - accuracy: 0.1962 - val_loss: 6.7536 - val_accuracy: 0.1179\n",
            "Epoch 297/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.4672 - accuracy: 0.1913 - val_loss: 4.9844 - val_accuracy: 0.1628\n",
            "Epoch 298/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8377 - accuracy: 0.1963 - val_loss: 6.2878 - val_accuracy: 0.0873\n",
            "Epoch 299/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1767 - accuracy: 0.1956 - val_loss: 5.1983 - val_accuracy: 0.1907\n",
            "Epoch 300/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9710 - accuracy: 0.1932 - val_loss: 6.7070 - val_accuracy: 0.1379\n",
            "Epoch 301/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8580 - accuracy: 0.1989 - val_loss: 5.6487 - val_accuracy: 0.1759\n",
            "Epoch 302/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2824 - accuracy: 0.1901 - val_loss: 6.2308 - val_accuracy: 0.0917\n",
            "Epoch 303/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6341 - accuracy: 0.1999 - val_loss: 8.0446 - val_accuracy: 0.0991\n",
            "Epoch 304/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9023 - accuracy: 0.1950 - val_loss: 6.0558 - val_accuracy: 0.1619\n",
            "Epoch 305/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2061 - accuracy: 0.1924 - val_loss: 7.7645 - val_accuracy: 0.0672\n",
            "Epoch 306/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9285 - accuracy: 0.1982 - val_loss: 7.9008 - val_accuracy: 0.1344\n",
            "Epoch 307/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9869 - accuracy: 0.1958 - val_loss: 7.0189 - val_accuracy: 0.0773\n",
            "Epoch 308/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8905 - accuracy: 0.1964 - val_loss: 5.9910 - val_accuracy: 0.1069\n",
            "Epoch 309/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8861 - accuracy: 0.1937 - val_loss: 5.9041 - val_accuracy: 0.1772\n",
            "Epoch 310/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1106 - accuracy: 0.1962 - val_loss: 7.8341 - val_accuracy: 0.2047\n",
            "Epoch 311/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3769 - accuracy: 0.1897 - val_loss: 7.6794 - val_accuracy: 0.0842\n",
            "Epoch 312/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9410 - accuracy: 0.1958 - val_loss: 5.1634 - val_accuracy: 0.1598\n",
            "Epoch 313/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9735 - accuracy: 0.1996 - val_loss: 8.5304 - val_accuracy: 0.1868\n",
            "Epoch 314/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0448 - accuracy: 0.1933 - val_loss: 6.8651 - val_accuracy: 0.1270\n",
            "Epoch 315/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7137 - accuracy: 0.1998 - val_loss: 6.7689 - val_accuracy: 0.1838\n",
            "Epoch 316/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0772 - accuracy: 0.1949 - val_loss: 8.2584 - val_accuracy: 0.1672\n",
            "Epoch 317/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9621 - accuracy: 0.1993 - val_loss: 10.1047 - val_accuracy: 0.0773\n",
            "Epoch 318/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0265 - accuracy: 0.1924 - val_loss: 6.1352 - val_accuracy: 0.1052\n",
            "Epoch 319/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9293 - accuracy: 0.1985 - val_loss: 6.2098 - val_accuracy: 0.1580\n",
            "Epoch 320/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3743 - accuracy: 0.1974 - val_loss: 6.9384 - val_accuracy: 0.1209\n",
            "Epoch 321/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2325 - accuracy: 0.1944 - val_loss: 6.2648 - val_accuracy: 0.1353\n",
            "Epoch 322/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8090 - accuracy: 0.1958 - val_loss: 8.0751 - val_accuracy: 0.1929\n",
            "Epoch 323/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8995 - accuracy: 0.1981 - val_loss: 7.2071 - val_accuracy: 0.0794\n",
            "Epoch 324/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2043 - accuracy: 0.1921 - val_loss: 8.4226 - val_accuracy: 0.1196\n",
            "Epoch 325/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8513 - accuracy: 0.2011 - val_loss: 10.2164 - val_accuracy: 0.1148\n",
            "Epoch 326/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9558 - accuracy: 0.1973 - val_loss: 6.0831 - val_accuracy: 0.1506\n",
            "Epoch 327/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7041 - accuracy: 0.2005 - val_loss: 7.5563 - val_accuracy: 0.1013\n",
            "Epoch 328/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0537 - accuracy: 0.1939 - val_loss: 4.7741 - val_accuracy: 0.1170\n",
            "Epoch 329/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8975 - accuracy: 0.1971 - val_loss: 5.3808 - val_accuracy: 0.0877\n",
            "Epoch 330/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1514 - accuracy: 0.1944 - val_loss: 6.8731 - val_accuracy: 0.1598\n",
            "Epoch 331/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0197 - accuracy: 0.1947 - val_loss: 10.1460 - val_accuracy: 0.1977\n",
            "Epoch 332/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1612 - accuracy: 0.1985 - val_loss: 6.5635 - val_accuracy: 0.1628\n",
            "Epoch 333/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7248 - accuracy: 0.2000 - val_loss: 10.8838 - val_accuracy: 0.0794\n",
            "Epoch 334/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2705 - accuracy: 0.1944 - val_loss: 6.1591 - val_accuracy: 0.1619\n",
            "Epoch 335/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9725 - accuracy: 0.1974 - val_loss: 7.3499 - val_accuracy: 0.1519\n",
            "Epoch 336/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8347 - accuracy: 0.2005 - val_loss: 5.2618 - val_accuracy: 0.1078\n",
            "Epoch 337/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7502 - accuracy: 0.1962 - val_loss: 7.7051 - val_accuracy: 0.0799\n",
            "Epoch 338/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2241 - accuracy: 0.1933 - val_loss: 5.7366 - val_accuracy: 0.1877\n",
            "Epoch 339/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8434 - accuracy: 0.2013 - val_loss: 4.9560 - val_accuracy: 0.1929\n",
            "Epoch 340/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7503 - accuracy: 0.2003 - val_loss: 5.0972 - val_accuracy: 0.1894\n",
            "Epoch 341/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0385 - accuracy: 0.1975 - val_loss: 7.5877 - val_accuracy: 0.1344\n",
            "Epoch 342/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7613 - accuracy: 0.1966 - val_loss: 6.0873 - val_accuracy: 0.1654\n",
            "Epoch 343/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9666 - accuracy: 0.1956 - val_loss: 7.0100 - val_accuracy: 0.1353\n",
            "Epoch 344/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3326 - accuracy: 0.1962 - val_loss: 9.2596 - val_accuracy: 0.1576\n",
            "Epoch 345/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7397 - accuracy: 0.2037 - val_loss: 7.4490 - val_accuracy: 0.1768\n",
            "Epoch 346/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8993 - accuracy: 0.2036 - val_loss: 6.8467 - val_accuracy: 0.1873\n",
            "Epoch 347/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1206 - accuracy: 0.1939 - val_loss: 10.9543 - val_accuracy: 0.0585\n",
            "Epoch 348/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5857 - accuracy: 0.1980 - val_loss: 6.0321 - val_accuracy: 0.1571\n",
            "Epoch 349/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9594 - accuracy: 0.1983 - val_loss: 6.0824 - val_accuracy: 0.1427\n",
            "Epoch 350/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9473 - accuracy: 0.1978 - val_loss: 5.9710 - val_accuracy: 0.1624\n",
            "Epoch 351/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6413 - accuracy: 0.1994 - val_loss: 6.6576 - val_accuracy: 0.1419\n",
            "Epoch 352/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2574 - accuracy: 0.1940 - val_loss: 9.6266 - val_accuracy: 0.1772\n",
            "Epoch 353/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7849 - accuracy: 0.2033 - val_loss: 8.6029 - val_accuracy: 0.0986\n",
            "Epoch 354/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0856 - accuracy: 0.1959 - val_loss: 5.2918 - val_accuracy: 0.1602\n",
            "Epoch 355/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5149 - accuracy: 0.2020 - val_loss: 6.6235 - val_accuracy: 0.1462\n",
            "Epoch 356/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1597 - accuracy: 0.1964 - val_loss: 8.4344 - val_accuracy: 0.1475\n",
            "Epoch 357/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8663 - accuracy: 0.1977 - val_loss: 4.9336 - val_accuracy: 0.2012\n",
            "Epoch 358/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2112 - accuracy: 0.1971 - val_loss: 6.6051 - val_accuracy: 0.2095\n",
            "Epoch 359/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6965 - accuracy: 0.1996 - val_loss: 6.2489 - val_accuracy: 0.1772\n",
            "Epoch 360/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1271 - accuracy: 0.1959 - val_loss: 6.1444 - val_accuracy: 0.1711\n",
            "Epoch 361/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7748 - accuracy: 0.2014 - val_loss: 4.5855 - val_accuracy: 0.2375\n",
            "Epoch 362/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9733 - accuracy: 0.2013 - val_loss: 8.3072 - val_accuracy: 0.1357\n",
            "Epoch 363/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8923 - accuracy: 0.1973 - val_loss: 5.5707 - val_accuracy: 0.0908\n",
            "Epoch 364/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0607 - accuracy: 0.2001 - val_loss: 9.0881 - val_accuracy: 0.0947\n",
            "Epoch 365/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7602 - accuracy: 0.1987 - val_loss: 8.2702 - val_accuracy: 0.1554\n",
            "Epoch 366/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1126 - accuracy: 0.1980 - val_loss: 8.6605 - val_accuracy: 0.1375\n",
            "Epoch 367/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1185 - accuracy: 0.1962 - val_loss: 9.3205 - val_accuracy: 0.1536\n",
            "Epoch 368/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7542 - accuracy: 0.2006 - val_loss: 4.7121 - val_accuracy: 0.1410\n",
            "Epoch 369/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9321 - accuracy: 0.1975 - val_loss: 10.1298 - val_accuracy: 0.1336\n",
            "Epoch 370/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7428 - accuracy: 0.2027 - val_loss: 7.7957 - val_accuracy: 0.0978\n",
            "Epoch 371/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1929 - accuracy: 0.1951 - val_loss: 9.0939 - val_accuracy: 0.1414\n",
            "Epoch 372/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6804 - accuracy: 0.2023 - val_loss: 8.2392 - val_accuracy: 0.0877\n",
            "Epoch 373/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7665 - accuracy: 0.1975 - val_loss: 6.3773 - val_accuracy: 0.1624\n",
            "Epoch 374/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7362 - accuracy: 0.1979 - val_loss: 5.9544 - val_accuracy: 0.2008\n",
            "Epoch 375/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0731 - accuracy: 0.1973 - val_loss: 8.8885 - val_accuracy: 0.1231\n",
            "Epoch 376/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0928 - accuracy: 0.1964 - val_loss: 5.2279 - val_accuracy: 0.1563\n",
            "Epoch 377/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6190 - accuracy: 0.2035 - val_loss: 7.2143 - val_accuracy: 0.1104\n",
            "Epoch 378/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0598 - accuracy: 0.1930 - val_loss: 6.6317 - val_accuracy: 0.1179\n",
            "Epoch 379/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6222 - accuracy: 0.1997 - val_loss: 9.9821 - val_accuracy: 0.1471\n",
            "Epoch 380/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0326 - accuracy: 0.2026 - val_loss: 5.3603 - val_accuracy: 0.1126\n",
            "Epoch 381/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8821 - accuracy: 0.1982 - val_loss: 8.1382 - val_accuracy: 0.0925\n",
            "Epoch 382/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9602 - accuracy: 0.1997 - val_loss: 8.8934 - val_accuracy: 0.0842\n",
            "Epoch 383/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8564 - accuracy: 0.2010 - val_loss: 7.8493 - val_accuracy: 0.1148\n",
            "Epoch 384/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1851 - accuracy: 0.1945 - val_loss: 9.3320 - val_accuracy: 0.1659\n",
            "Epoch 385/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7130 - accuracy: 0.2041 - val_loss: 8.8048 - val_accuracy: 0.0471\n",
            "Epoch 386/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8204 - accuracy: 0.1963 - val_loss: 8.0979 - val_accuracy: 0.1502\n",
            "Epoch 387/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8422 - accuracy: 0.2005 - val_loss: 6.8523 - val_accuracy: 0.1746\n",
            "Epoch 388/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8636 - accuracy: 0.1961 - val_loss: 7.5140 - val_accuracy: 0.1362\n",
            "Epoch 389/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8047 - accuracy: 0.2015 - val_loss: 5.4955 - val_accuracy: 0.1825\n",
            "Epoch 390/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9130 - accuracy: 0.2009 - val_loss: 11.8105 - val_accuracy: 0.1632\n",
            "Epoch 391/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5665 - accuracy: 0.2025 - val_loss: 5.0928 - val_accuracy: 0.2610\n",
            "Epoch 392/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9504 - accuracy: 0.1981 - val_loss: 8.1090 - val_accuracy: 0.1039\n",
            "Epoch 393/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1721 - accuracy: 0.1968 - val_loss: 10.9226 - val_accuracy: 0.1532\n",
            "Epoch 394/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8092 - accuracy: 0.1991 - val_loss: 5.2257 - val_accuracy: 0.1921\n",
            "Epoch 395/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9189 - accuracy: 0.1973 - val_loss: 7.8535 - val_accuracy: 0.1283\n",
            "Epoch 396/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5702 - accuracy: 0.2044 - val_loss: 5.9032 - val_accuracy: 0.1663\n",
            "Epoch 397/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8432 - accuracy: 0.1986 - val_loss: 10.5544 - val_accuracy: 0.1541\n",
            "Epoch 398/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7766 - accuracy: 0.1991 - val_loss: 10.9602 - val_accuracy: 0.0572\n",
            "Epoch 399/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1075 - accuracy: 0.1965 - val_loss: 5.3395 - val_accuracy: 0.0991\n",
            "Epoch 400/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2175 - accuracy: 0.1962 - val_loss: 5.5823 - val_accuracy: 0.2335\n",
            "Epoch 401/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4801 - accuracy: 0.2074 - val_loss: 6.3033 - val_accuracy: 0.2305\n",
            "Epoch 402/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7837 - accuracy: 0.2003 - val_loss: 5.8871 - val_accuracy: 0.1868\n",
            "Epoch 403/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7959 - accuracy: 0.2033 - val_loss: 6.0298 - val_accuracy: 0.1955\n",
            "Epoch 404/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0070 - accuracy: 0.2011 - val_loss: 7.4540 - val_accuracy: 0.1519\n",
            "Epoch 405/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9541 - accuracy: 0.2001 - val_loss: 11.6306 - val_accuracy: 0.0947\n",
            "Epoch 406/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6992 - accuracy: 0.1998 - val_loss: 8.0071 - val_accuracy: 0.0938\n",
            "Epoch 407/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5863 - accuracy: 0.2014 - val_loss: 6.1290 - val_accuracy: 0.1999\n",
            "Epoch 408/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7795 - accuracy: 0.2013 - val_loss: 8.9794 - val_accuracy: 0.1375\n",
            "Epoch 409/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6698 - accuracy: 0.2031 - val_loss: 5.6866 - val_accuracy: 0.1619\n",
            "Epoch 410/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0178 - accuracy: 0.2018 - val_loss: 9.2005 - val_accuracy: 0.1144\n",
            "Epoch 411/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0919 - accuracy: 0.2015 - val_loss: 8.6010 - val_accuracy: 0.1109\n",
            "Epoch 412/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8544 - accuracy: 0.2010 - val_loss: 8.0931 - val_accuracy: 0.1768\n",
            "Epoch 413/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8565 - accuracy: 0.2002 - val_loss: 6.5134 - val_accuracy: 0.1720\n",
            "Epoch 414/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2427 - accuracy: 0.2023 - val_loss: 7.4668 - val_accuracy: 0.1052\n",
            "Epoch 415/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7013 - accuracy: 0.2019 - val_loss: 6.5736 - val_accuracy: 0.1296\n",
            "Epoch 416/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8582 - accuracy: 0.1986 - val_loss: 9.3089 - val_accuracy: 0.1519\n",
            "Epoch 417/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9404 - accuracy: 0.1984 - val_loss: 8.1081 - val_accuracy: 0.1244\n",
            "Epoch 418/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6643 - accuracy: 0.2012 - val_loss: 10.4609 - val_accuracy: 0.2052\n",
            "Epoch 419/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0206 - accuracy: 0.1977 - val_loss: 6.0567 - val_accuracy: 0.1379\n",
            "Epoch 420/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5885 - accuracy: 0.2036 - val_loss: 11.1574 - val_accuracy: 0.0790\n",
            "Epoch 421/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6823 - accuracy: 0.2025 - val_loss: 6.4809 - val_accuracy: 0.0969\n",
            "Epoch 422/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0246 - accuracy: 0.1968 - val_loss: 5.0366 - val_accuracy: 0.1436\n",
            "Epoch 423/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7563 - accuracy: 0.2022 - val_loss: 8.9204 - val_accuracy: 0.1314\n",
            "Epoch 424/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7820 - accuracy: 0.2053 - val_loss: 5.5866 - val_accuracy: 0.1873\n",
            "Epoch 425/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8019 - accuracy: 0.1982 - val_loss: 8.2457 - val_accuracy: 0.1947\n",
            "Epoch 426/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8180 - accuracy: 0.2005 - val_loss: 6.2517 - val_accuracy: 0.1654\n",
            "Epoch 427/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6142 - accuracy: 0.2000 - val_loss: 5.6943 - val_accuracy: 0.2025\n",
            "Epoch 428/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6531 - accuracy: 0.2039 - val_loss: 7.2033 - val_accuracy: 0.1388\n",
            "Epoch 429/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7035 - accuracy: 0.2042 - val_loss: 8.3113 - val_accuracy: 0.2182\n",
            "Epoch 430/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8866 - accuracy: 0.2047 - val_loss: 5.2000 - val_accuracy: 0.1842\n",
            "Epoch 431/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7835 - accuracy: 0.2006 - val_loss: 6.9163 - val_accuracy: 0.0851\n",
            "Epoch 432/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6745 - accuracy: 0.2052 - val_loss: 6.9216 - val_accuracy: 0.1563\n",
            "Epoch 433/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2324 - accuracy: 0.1964 - val_loss: 4.8153 - val_accuracy: 0.1803\n",
            "Epoch 434/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9641 - accuracy: 0.1995 - val_loss: 8.7925 - val_accuracy: 0.0899\n",
            "Epoch 435/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8708 - accuracy: 0.2006 - val_loss: 6.8392 - val_accuracy: 0.1523\n",
            "Epoch 436/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4588 - accuracy: 0.2050 - val_loss: 15.0357 - val_accuracy: 0.0397\n",
            "Epoch 437/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9408 - accuracy: 0.2015 - val_loss: 6.0432 - val_accuracy: 0.1886\n",
            "Epoch 438/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8883 - accuracy: 0.2025 - val_loss: 6.4455 - val_accuracy: 0.1851\n",
            "Epoch 439/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9741 - accuracy: 0.1992 - val_loss: 7.9371 - val_accuracy: 0.1807\n",
            "Epoch 440/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7895 - accuracy: 0.2020 - val_loss: 5.8874 - val_accuracy: 0.1135\n",
            "Epoch 441/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9819 - accuracy: 0.2010 - val_loss: 5.1581 - val_accuracy: 0.1995\n",
            "Epoch 442/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7428 - accuracy: 0.2004 - val_loss: 6.2778 - val_accuracy: 0.1694\n",
            "Epoch 443/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0294 - accuracy: 0.2003 - val_loss: 10.4474 - val_accuracy: 0.1846\n",
            "Epoch 444/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8524 - accuracy: 0.1991 - val_loss: 10.0679 - val_accuracy: 0.1820\n",
            "Epoch 445/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6176 - accuracy: 0.2027 - val_loss: 6.6339 - val_accuracy: 0.1584\n",
            "Epoch 446/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8782 - accuracy: 0.2014 - val_loss: 5.6450 - val_accuracy: 0.1017\n",
            "Epoch 447/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7383 - accuracy: 0.1974 - val_loss: 8.1257 - val_accuracy: 0.0860\n",
            "Epoch 448/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8624 - accuracy: 0.1978 - val_loss: 8.9937 - val_accuracy: 0.1218\n",
            "Epoch 449/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6787 - accuracy: 0.2060 - val_loss: 7.8768 - val_accuracy: 0.2073\n",
            "Epoch 450/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8334 - accuracy: 0.2042 - val_loss: 8.4116 - val_accuracy: 0.1493\n",
            "Epoch 451/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9205 - accuracy: 0.1990 - val_loss: 9.4063 - val_accuracy: 0.1017\n",
            "Epoch 452/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8887 - accuracy: 0.2013 - val_loss: 6.9873 - val_accuracy: 0.1405\n",
            "Epoch 453/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5531 - accuracy: 0.2031 - val_loss: 5.2119 - val_accuracy: 0.1148\n",
            "Epoch 454/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9652 - accuracy: 0.1998 - val_loss: 3.8620 - val_accuracy: 0.2278\n",
            "Epoch 455/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4582 - accuracy: 0.2011 - val_loss: 11.3539 - val_accuracy: 0.1894\n",
            "Epoch 456/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6740 - accuracy: 0.2035 - val_loss: 5.6146 - val_accuracy: 0.1563\n",
            "Epoch 457/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0015 - accuracy: 0.2011 - val_loss: 5.2232 - val_accuracy: 0.1790\n",
            "Epoch 458/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6862 - accuracy: 0.2018 - val_loss: 6.9044 - val_accuracy: 0.1798\n",
            "Epoch 459/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3085 - accuracy: 0.2071 - val_loss: 6.3071 - val_accuracy: 0.1165\n",
            "Epoch 460/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0245 - accuracy: 0.2042 - val_loss: 7.7685 - val_accuracy: 0.1689\n",
            "Epoch 461/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7886 - accuracy: 0.2032 - val_loss: 7.7347 - val_accuracy: 0.1213\n",
            "Epoch 462/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.6049 - accuracy: 0.2043 - val_loss: 6.2106 - val_accuracy: 0.0956\n",
            "Epoch 463/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.7158 - accuracy: 0.2035 - val_loss: 5.5260 - val_accuracy: 0.1484\n",
            "Epoch 464/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.6523 - accuracy: 0.2031 - val_loss: 7.5467 - val_accuracy: 0.1680\n",
            "Epoch 465/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0195 - accuracy: 0.2011 - val_loss: 7.2671 - val_accuracy: 0.1082\n",
            "Epoch 466/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8107 - accuracy: 0.2061 - val_loss: 5.2643 - val_accuracy: 0.1676\n",
            "Epoch 467/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5764 - accuracy: 0.2059 - val_loss: 5.0618 - val_accuracy: 0.2292\n",
            "Epoch 468/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5971 - accuracy: 0.2049 - val_loss: 7.0390 - val_accuracy: 0.2187\n",
            "Epoch 469/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9705 - accuracy: 0.1990 - val_loss: 8.2437 - val_accuracy: 0.0576\n",
            "Epoch 470/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6777 - accuracy: 0.2055 - val_loss: 4.8946 - val_accuracy: 0.1899\n",
            "Epoch 471/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7229 - accuracy: 0.2038 - val_loss: 7.7940 - val_accuracy: 0.1510\n",
            "Epoch 472/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3513 - accuracy: 0.1980 - val_loss: 10.5025 - val_accuracy: 0.0847\n",
            "Epoch 473/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9678 - accuracy: 0.2043 - val_loss: 7.0132 - val_accuracy: 0.1580\n",
            "Epoch 474/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.2991 - accuracy: 0.2098 - val_loss: 7.9570 - val_accuracy: 0.1174\n",
            "Epoch 475/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8902 - accuracy: 0.2049 - val_loss: 5.4359 - val_accuracy: 0.1938\n",
            "Epoch 476/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7503 - accuracy: 0.2017 - val_loss: 6.2040 - val_accuracy: 0.2152\n",
            "Epoch 477/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6669 - accuracy: 0.2030 - val_loss: 7.9802 - val_accuracy: 0.1877\n",
            "Epoch 478/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9383 - accuracy: 0.1980 - val_loss: 8.1744 - val_accuracy: 0.0956\n",
            "Epoch 479/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7802 - accuracy: 0.2028 - val_loss: 14.4630 - val_accuracy: 0.1580\n",
            "Epoch 480/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7219 - accuracy: 0.2006 - val_loss: 8.8916 - val_accuracy: 0.2034\n",
            "Epoch 481/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8865 - accuracy: 0.2027 - val_loss: 21.8627 - val_accuracy: 0.0044\n",
            "Epoch 482/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.3695 - accuracy: 0.1993 - val_loss: 4.1890 - val_accuracy: 0.1864\n",
            "Epoch 483/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4523 - accuracy: 0.2117 - val_loss: 6.9392 - val_accuracy: 0.1061\n",
            "Epoch 484/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4343 - accuracy: 0.2066 - val_loss: 4.5683 - val_accuracy: 0.1938\n",
            "Epoch 485/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8017 - accuracy: 0.2007 - val_loss: 5.7144 - val_accuracy: 0.1680\n",
            "Epoch 486/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8605 - accuracy: 0.2043 - val_loss: 8.9335 - val_accuracy: 0.0821\n",
            "Epoch 487/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5712 - accuracy: 0.2029 - val_loss: 4.7655 - val_accuracy: 0.1781\n",
            "Epoch 488/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7551 - accuracy: 0.2017 - val_loss: 7.4600 - val_accuracy: 0.0925\n",
            "Epoch 489/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5436 - accuracy: 0.2083 - val_loss: 8.2287 - val_accuracy: 0.1550\n",
            "Epoch 490/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2187 - accuracy: 0.1986 - val_loss: 9.3095 - val_accuracy: 0.1811\n",
            "Epoch 491/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3712 - accuracy: 0.2110 - val_loss: 6.4785 - val_accuracy: 0.1825\n",
            "Epoch 492/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8144 - accuracy: 0.2021 - val_loss: 6.7616 - val_accuracy: 0.1825\n",
            "Epoch 493/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8848 - accuracy: 0.2014 - val_loss: 6.6795 - val_accuracy: 0.1170\n",
            "Epoch 494/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8214 - accuracy: 0.2028 - val_loss: 3.9987 - val_accuracy: 0.1536\n",
            "Epoch 495/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5896 - accuracy: 0.2074 - val_loss: 3.8614 - val_accuracy: 0.2069\n",
            "Epoch 496/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5482 - accuracy: 0.2046 - val_loss: 4.5173 - val_accuracy: 0.2108\n",
            "Epoch 497/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7543 - accuracy: 0.2031 - val_loss: 5.2756 - val_accuracy: 0.2449\n",
            "Epoch 498/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4886 - accuracy: 0.2078 - val_loss: 7.2163 - val_accuracy: 0.2100\n",
            "Epoch 499/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0760 - accuracy: 0.2011 - val_loss: 5.5706 - val_accuracy: 0.0851\n",
            "Epoch 500/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8832 - accuracy: 0.2029 - val_loss: 6.1272 - val_accuracy: 0.0969\n",
            "Epoch 501/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7952 - accuracy: 0.2043 - val_loss: 6.4272 - val_accuracy: 0.1646\n",
            "Epoch 502/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6095 - accuracy: 0.2038 - val_loss: 11.8449 - val_accuracy: 0.0620\n",
            "Epoch 503/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8482 - accuracy: 0.2049 - val_loss: 5.5603 - val_accuracy: 0.1873\n",
            "Epoch 504/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5818 - accuracy: 0.2045 - val_loss: 6.9769 - val_accuracy: 0.1480\n",
            "Epoch 505/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9224 - accuracy: 0.2020 - val_loss: 6.4759 - val_accuracy: 0.1309\n",
            "Epoch 506/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8318 - accuracy: 0.2025 - val_loss: 11.4501 - val_accuracy: 0.1227\n",
            "Epoch 507/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5111 - accuracy: 0.2064 - val_loss: 6.3343 - val_accuracy: 0.1170\n",
            "Epoch 508/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9329 - accuracy: 0.2008 - val_loss: 7.2879 - val_accuracy: 0.1576\n",
            "Epoch 509/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9362 - accuracy: 0.2023 - val_loss: 9.8248 - val_accuracy: 0.1515\n",
            "Epoch 510/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7864 - accuracy: 0.1995 - val_loss: 10.9439 - val_accuracy: 0.0877\n",
            "Epoch 511/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8213 - accuracy: 0.2073 - val_loss: 5.7408 - val_accuracy: 0.1126\n",
            "Epoch 512/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3449 - accuracy: 0.2067 - val_loss: 5.0342 - val_accuracy: 0.2073\n",
            "Epoch 513/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1245 - accuracy: 0.2042 - val_loss: 4.2150 - val_accuracy: 0.2265\n",
            "Epoch 514/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7338 - accuracy: 0.2073 - val_loss: 4.7930 - val_accuracy: 0.2017\n",
            "Epoch 515/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6387 - accuracy: 0.2051 - val_loss: 10.9745 - val_accuracy: 0.0764\n",
            "Epoch 516/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8301 - accuracy: 0.2077 - val_loss: 5.1194 - val_accuracy: 0.2130\n",
            "Epoch 517/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7128 - accuracy: 0.2017 - val_loss: 5.7924 - val_accuracy: 0.1471\n",
            "Epoch 518/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5950 - accuracy: 0.2077 - val_loss: 8.1741 - val_accuracy: 0.2134\n",
            "Epoch 519/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0940 - accuracy: 0.2000 - val_loss: 6.0066 - val_accuracy: 0.1777\n",
            "Epoch 520/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6570 - accuracy: 0.2035 - val_loss: 5.4468 - val_accuracy: 0.2034\n",
            "Epoch 521/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4503 - accuracy: 0.2113 - val_loss: 8.2613 - val_accuracy: 0.1458\n",
            "Epoch 522/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8680 - accuracy: 0.2025 - val_loss: 8.2542 - val_accuracy: 0.0808\n",
            "Epoch 523/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5805 - accuracy: 0.2069 - val_loss: 7.4916 - val_accuracy: 0.1532\n",
            "Epoch 524/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7758 - accuracy: 0.2027 - val_loss: 4.7863 - val_accuracy: 0.1266\n",
            "Epoch 525/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6830 - accuracy: 0.2039 - val_loss: 4.4847 - val_accuracy: 0.2034\n",
            "Epoch 526/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8736 - accuracy: 0.2015 - val_loss: 8.2269 - val_accuracy: 0.1707\n",
            "Epoch 527/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9504 - accuracy: 0.2016 - val_loss: 4.7646 - val_accuracy: 0.2152\n",
            "Epoch 528/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1116 - accuracy: 0.2021 - val_loss: 9.9387 - val_accuracy: 0.1248\n",
            "Epoch 529/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7222 - accuracy: 0.2073 - val_loss: 6.0591 - val_accuracy: 0.1986\n",
            "Epoch 530/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4725 - accuracy: 0.2073 - val_loss: 9.9921 - val_accuracy: 0.1676\n",
            "Epoch 531/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0313 - accuracy: 0.2043 - val_loss: 5.3766 - val_accuracy: 0.1916\n",
            "Epoch 532/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5394 - accuracy: 0.2074 - val_loss: 5.0995 - val_accuracy: 0.1379\n",
            "Epoch 533/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6504 - accuracy: 0.2046 - val_loss: 6.2364 - val_accuracy: 0.1846\n",
            "Epoch 534/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0116 - accuracy: 0.1980 - val_loss: 10.4689 - val_accuracy: 0.0982\n",
            "Epoch 535/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0131 - accuracy: 0.2037 - val_loss: 8.3625 - val_accuracy: 0.1384\n",
            "Epoch 536/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3368 - accuracy: 0.2086 - val_loss: 5.4409 - val_accuracy: 0.1999\n",
            "Epoch 537/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6370 - accuracy: 0.2101 - val_loss: 9.6062 - val_accuracy: 0.1309\n",
            "Epoch 538/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4968 - accuracy: 0.2074 - val_loss: 4.0660 - val_accuracy: 0.1938\n",
            "Epoch 539/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7130 - accuracy: 0.2038 - val_loss: 5.4112 - val_accuracy: 0.2409\n",
            "Epoch 540/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9869 - accuracy: 0.2022 - val_loss: 5.3837 - val_accuracy: 0.1768\n",
            "Epoch 541/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5461 - accuracy: 0.2106 - val_loss: 6.9519 - val_accuracy: 0.1947\n",
            "Epoch 542/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8626 - accuracy: 0.2058 - val_loss: 5.2264 - val_accuracy: 0.1436\n",
            "Epoch 543/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5170 - accuracy: 0.2072 - val_loss: 5.9730 - val_accuracy: 0.1794\n",
            "Epoch 544/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6639 - accuracy: 0.2078 - val_loss: 6.6432 - val_accuracy: 0.1663\n",
            "Epoch 545/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6849 - accuracy: 0.2029 - val_loss: 5.3736 - val_accuracy: 0.1842\n",
            "Epoch 546/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6970 - accuracy: 0.2075 - val_loss: 5.4806 - val_accuracy: 0.1746\n",
            "Epoch 547/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6823 - accuracy: 0.2047 - val_loss: 11.1194 - val_accuracy: 0.1842\n",
            "Epoch 548/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7533 - accuracy: 0.2076 - val_loss: 7.6741 - val_accuracy: 0.1484\n",
            "Epoch 549/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8953 - accuracy: 0.2029 - val_loss: 6.3431 - val_accuracy: 0.1179\n",
            "Epoch 550/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7536 - accuracy: 0.2035 - val_loss: 13.7350 - val_accuracy: 0.1174\n",
            "Epoch 551/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6120 - accuracy: 0.2054 - val_loss: 5.1552 - val_accuracy: 0.1227\n",
            "Epoch 552/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6313 - accuracy: 0.2075 - val_loss: 8.4076 - val_accuracy: 0.0659\n",
            "Epoch 553/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7662 - accuracy: 0.2053 - val_loss: 6.3947 - val_accuracy: 0.2200\n",
            "Epoch 554/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5201 - accuracy: 0.2073 - val_loss: 6.8207 - val_accuracy: 0.1467\n",
            "Epoch 555/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8142 - accuracy: 0.2025 - val_loss: 7.8715 - val_accuracy: 0.2143\n",
            "Epoch 556/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8482 - accuracy: 0.2045 - val_loss: 6.5336 - val_accuracy: 0.2148\n",
            "Epoch 557/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4522 - accuracy: 0.2066 - val_loss: 5.8633 - val_accuracy: 0.1672\n",
            "Epoch 558/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8731 - accuracy: 0.2058 - val_loss: 8.6972 - val_accuracy: 0.1929\n",
            "Epoch 559/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4825 - accuracy: 0.2134 - val_loss: 12.1690 - val_accuracy: 0.0463\n",
            "Epoch 560/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8472 - accuracy: 0.2039 - val_loss: 7.7660 - val_accuracy: 0.1611\n",
            "Epoch 561/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7653 - accuracy: 0.2083 - val_loss: 7.4347 - val_accuracy: 0.1240\n",
            "Epoch 562/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7160 - accuracy: 0.2034 - val_loss: 4.8592 - val_accuracy: 0.1685\n",
            "Epoch 563/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3382 - accuracy: 0.2113 - val_loss: 5.6881 - val_accuracy: 0.1676\n",
            "Epoch 564/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.2371 - accuracy: 0.2015 - val_loss: 4.8909 - val_accuracy: 0.1702\n",
            "Epoch 565/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5518 - accuracy: 0.2074 - val_loss: 5.0907 - val_accuracy: 0.2204\n",
            "Epoch 566/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8539 - accuracy: 0.2040 - val_loss: 5.5121 - val_accuracy: 0.1606\n",
            "Epoch 567/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8100 - accuracy: 0.2026 - val_loss: 4.6947 - val_accuracy: 0.1362\n",
            "Epoch 568/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5366 - accuracy: 0.2114 - val_loss: 9.3600 - val_accuracy: 0.1174\n",
            "Epoch 569/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5997 - accuracy: 0.2087 - val_loss: 5.2255 - val_accuracy: 0.1881\n",
            "Epoch 570/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9513 - accuracy: 0.2058 - val_loss: 5.2714 - val_accuracy: 0.1969\n",
            "Epoch 571/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5892 - accuracy: 0.2078 - val_loss: 6.3690 - val_accuracy: 0.2025\n",
            "Epoch 572/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6479 - accuracy: 0.2081 - val_loss: 8.1269 - val_accuracy: 0.1296\n",
            "Epoch 573/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5289 - accuracy: 0.2125 - val_loss: 5.9624 - val_accuracy: 0.2270\n",
            "Epoch 574/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6896 - accuracy: 0.2116 - val_loss: 5.6802 - val_accuracy: 0.1405\n",
            "Epoch 575/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8421 - accuracy: 0.2043 - val_loss: 6.4733 - val_accuracy: 0.0777\n",
            "Epoch 576/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5549 - accuracy: 0.2076 - val_loss: 5.1955 - val_accuracy: 0.1288\n",
            "Epoch 577/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5417 - accuracy: 0.2091 - val_loss: 5.3461 - val_accuracy: 0.1803\n",
            "Epoch 578/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0855 - accuracy: 0.2081 - val_loss: 8.4093 - val_accuracy: 0.2732\n",
            "Epoch 579/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4882 - accuracy: 0.2072 - val_loss: 8.2677 - val_accuracy: 0.1148\n",
            "Epoch 580/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7972 - accuracy: 0.2034 - val_loss: 4.7408 - val_accuracy: 0.2143\n",
            "Epoch 581/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4253 - accuracy: 0.2111 - val_loss: 6.5582 - val_accuracy: 0.1750\n",
            "Epoch 582/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8649 - accuracy: 0.2093 - val_loss: 5.7642 - val_accuracy: 0.1379\n",
            "Epoch 583/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9107 - accuracy: 0.2064 - val_loss: 7.5474 - val_accuracy: 0.1349\n",
            "Epoch 584/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8429 - accuracy: 0.2058 - val_loss: 7.3166 - val_accuracy: 0.1611\n",
            "Epoch 585/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3261 - accuracy: 0.2060 - val_loss: 9.0142 - val_accuracy: 0.0611\n",
            "Epoch 586/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8459 - accuracy: 0.2069 - val_loss: 5.6990 - val_accuracy: 0.0886\n",
            "Epoch 587/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5228 - accuracy: 0.2106 - val_loss: 7.1840 - val_accuracy: 0.1825\n",
            "Epoch 588/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8660 - accuracy: 0.2066 - val_loss: 6.9193 - val_accuracy: 0.2300\n",
            "Epoch 589/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5250 - accuracy: 0.2092 - val_loss: 10.1480 - val_accuracy: 0.1148\n",
            "Epoch 590/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.1366 - accuracy: 0.2037 - val_loss: 8.4560 - val_accuracy: 0.2082\n",
            "Epoch 591/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6315 - accuracy: 0.2084 - val_loss: 7.7282 - val_accuracy: 0.0886\n",
            "Epoch 592/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4319 - accuracy: 0.2074 - val_loss: 7.3439 - val_accuracy: 0.1960\n",
            "Epoch 593/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9001 - accuracy: 0.2063 - val_loss: 10.5657 - val_accuracy: 0.1951\n",
            "Epoch 594/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5490 - accuracy: 0.2077 - val_loss: 7.6307 - val_accuracy: 0.1868\n",
            "Epoch 595/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5356 - accuracy: 0.2059 - val_loss: 6.1379 - val_accuracy: 0.1641\n",
            "Epoch 596/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5736 - accuracy: 0.2102 - val_loss: 5.5593 - val_accuracy: 0.2126\n",
            "Epoch 597/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9970 - accuracy: 0.2068 - val_loss: 8.2756 - val_accuracy: 0.1122\n",
            "Epoch 598/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5248 - accuracy: 0.2047 - val_loss: 7.7369 - val_accuracy: 0.1462\n",
            "Epoch 599/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5040 - accuracy: 0.2125 - val_loss: 7.4882 - val_accuracy: 0.1624\n",
            "Epoch 600/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6074 - accuracy: 0.2103 - val_loss: 7.5498 - val_accuracy: 0.1563\n",
            "Epoch 601/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0383 - accuracy: 0.2016 - val_loss: 6.5385 - val_accuracy: 0.1139\n",
            "Epoch 602/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7003 - accuracy: 0.2083 - val_loss: 8.1345 - val_accuracy: 0.0607\n",
            "Epoch 603/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7152 - accuracy: 0.2069 - val_loss: 4.9319 - val_accuracy: 0.1838\n",
            "Epoch 604/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3563 - accuracy: 0.2134 - val_loss: 4.3596 - val_accuracy: 0.2139\n",
            "Epoch 605/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5565 - accuracy: 0.2069 - val_loss: 4.9740 - val_accuracy: 0.2073\n",
            "Epoch 606/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8289 - accuracy: 0.2072 - val_loss: 7.7876 - val_accuracy: 0.1742\n",
            "Epoch 607/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9306 - accuracy: 0.2055 - val_loss: 8.2756 - val_accuracy: 0.1213\n",
            "Epoch 608/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5075 - accuracy: 0.2118 - val_loss: 5.8636 - val_accuracy: 0.1632\n",
            "Epoch 609/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9028 - accuracy: 0.2006 - val_loss: 4.9769 - val_accuracy: 0.1152\n",
            "Epoch 610/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4876 - accuracy: 0.2071 - val_loss: 11.9049 - val_accuracy: 0.0463\n",
            "Epoch 611/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8450 - accuracy: 0.2002 - val_loss: 7.1321 - val_accuracy: 0.0842\n",
            "Epoch 612/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7763 - accuracy: 0.2011 - val_loss: 5.7263 - val_accuracy: 0.1641\n",
            "Epoch 613/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.2967 - accuracy: 0.2095 - val_loss: 5.6626 - val_accuracy: 0.1379\n",
            "Epoch 614/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6771 - accuracy: 0.2113 - val_loss: 4.5453 - val_accuracy: 0.1598\n",
            "Epoch 615/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9801 - accuracy: 0.2054 - val_loss: 7.0722 - val_accuracy: 0.1929\n",
            "Epoch 616/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4686 - accuracy: 0.2076 - val_loss: 5.1120 - val_accuracy: 0.1309\n",
            "Epoch 617/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7949 - accuracy: 0.2075 - val_loss: 9.0614 - val_accuracy: 0.1733\n",
            "Epoch 618/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6218 - accuracy: 0.2042 - val_loss: 5.4123 - val_accuracy: 0.2318\n",
            "Epoch 619/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3176 - accuracy: 0.2105 - val_loss: 5.6872 - val_accuracy: 0.1235\n",
            "Epoch 620/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6348 - accuracy: 0.2066 - val_loss: 6.3132 - val_accuracy: 0.1619\n",
            "Epoch 621/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9165 - accuracy: 0.2077 - val_loss: 5.7639 - val_accuracy: 0.1034\n",
            "Epoch 622/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3552 - accuracy: 0.2116 - val_loss: 4.4338 - val_accuracy: 0.2244\n",
            "Epoch 623/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8420 - accuracy: 0.2035 - val_loss: 8.1860 - val_accuracy: 0.1619\n",
            "Epoch 624/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4770 - accuracy: 0.2123 - val_loss: 4.3499 - val_accuracy: 0.2165\n",
            "Epoch 625/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8509 - accuracy: 0.2081 - val_loss: 8.8805 - val_accuracy: 0.1916\n",
            "Epoch 626/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4488 - accuracy: 0.2103 - val_loss: 8.4906 - val_accuracy: 0.1515\n",
            "Epoch 627/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8795 - accuracy: 0.2066 - val_loss: 6.3512 - val_accuracy: 0.2292\n",
            "Epoch 628/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5773 - accuracy: 0.2084 - val_loss: 6.0637 - val_accuracy: 0.1515\n",
            "Epoch 629/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6951 - accuracy: 0.2065 - val_loss: 6.8799 - val_accuracy: 0.1873\n",
            "Epoch 630/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6465 - accuracy: 0.2127 - val_loss: 5.7368 - val_accuracy: 0.0956\n",
            "Epoch 631/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5571 - accuracy: 0.2088 - val_loss: 6.6814 - val_accuracy: 0.1737\n",
            "Epoch 632/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5471 - accuracy: 0.2056 - val_loss: 9.5644 - val_accuracy: 0.2047\n",
            "Epoch 633/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4698 - accuracy: 0.2104 - val_loss: 6.6858 - val_accuracy: 0.1584\n",
            "Epoch 634/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3642 - accuracy: 0.2125 - val_loss: 5.4541 - val_accuracy: 0.2095\n",
            "Epoch 635/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8994 - accuracy: 0.2065 - val_loss: 11.1363 - val_accuracy: 0.1707\n",
            "Epoch 636/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6600 - accuracy: 0.2053 - val_loss: 7.0505 - val_accuracy: 0.1043\n",
            "Epoch 637/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.5722 - accuracy: 0.2046 - val_loss: 9.3467 - val_accuracy: 0.1065\n",
            "Epoch 638/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.7505 - accuracy: 0.2093 - val_loss: 5.9529 - val_accuracy: 0.2065\n",
            "Epoch 639/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.6713 - accuracy: 0.2046 - val_loss: 3.7189 - val_accuracy: 0.1969\n",
            "Epoch 640/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.4585 - accuracy: 0.2081 - val_loss: 6.0238 - val_accuracy: 0.1746\n",
            "Epoch 641/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5999 - accuracy: 0.2103 - val_loss: 6.6829 - val_accuracy: 0.2632\n",
            "Epoch 642/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0395 - accuracy: 0.2057 - val_loss: 7.8004 - val_accuracy: 0.2165\n",
            "Epoch 643/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7532 - accuracy: 0.2087 - val_loss: 5.3502 - val_accuracy: 0.2204\n",
            "Epoch 644/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4601 - accuracy: 0.2095 - val_loss: 7.6870 - val_accuracy: 0.1331\n",
            "Epoch 645/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7026 - accuracy: 0.2123 - val_loss: 6.9597 - val_accuracy: 0.1183\n",
            "Epoch 646/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5835 - accuracy: 0.2092 - val_loss: 9.7696 - val_accuracy: 0.1021\n",
            "Epoch 647/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0066 - accuracy: 0.2016 - val_loss: 5.1134 - val_accuracy: 0.1458\n",
            "Epoch 648/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5108 - accuracy: 0.2104 - val_loss: 13.4656 - val_accuracy: 0.0550\n",
            "Epoch 649/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7650 - accuracy: 0.2066 - val_loss: 5.8818 - val_accuracy: 0.1855\n",
            "Epoch 650/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4331 - accuracy: 0.2091 - val_loss: 7.7183 - val_accuracy: 0.1825\n",
            "Epoch 651/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7406 - accuracy: 0.2098 - val_loss: 5.9233 - val_accuracy: 0.2453\n",
            "Epoch 652/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8221 - accuracy: 0.2052 - val_loss: 6.1718 - val_accuracy: 0.1615\n",
            "Epoch 653/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4987 - accuracy: 0.2101 - val_loss: 5.9117 - val_accuracy: 0.1746\n",
            "Epoch 654/2500\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 5.7495 - accuracy: 0.2072 - val_loss: 8.4662 - val_accuracy: 0.1336\n",
            "Epoch 655/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6225 - accuracy: 0.2078 - val_loss: 8.3664 - val_accuracy: 0.1899\n",
            "Epoch 656/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6279 - accuracy: 0.2098 - val_loss: 6.6720 - val_accuracy: 0.1589\n",
            "Epoch 657/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6738 - accuracy: 0.2110 - val_loss: 5.2426 - val_accuracy: 0.1772\n",
            "Epoch 658/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7247 - accuracy: 0.2081 - val_loss: 10.0096 - val_accuracy: 0.1667\n",
            "Epoch 659/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5186 - accuracy: 0.2113 - val_loss: 8.6641 - val_accuracy: 0.0834\n",
            "Epoch 660/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5272 - accuracy: 0.2141 - val_loss: 8.0890 - val_accuracy: 0.2121\n",
            "Epoch 661/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5164 - accuracy: 0.2126 - val_loss: 6.3785 - val_accuracy: 0.1746\n",
            "Epoch 662/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6683 - accuracy: 0.2087 - val_loss: 9.5441 - val_accuracy: 0.1174\n",
            "Epoch 663/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8708 - accuracy: 0.2094 - val_loss: 6.2882 - val_accuracy: 0.2021\n",
            "Epoch 664/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4330 - accuracy: 0.2116 - val_loss: 8.8908 - val_accuracy: 0.1733\n",
            "Epoch 665/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5777 - accuracy: 0.2073 - val_loss: 7.1377 - val_accuracy: 0.2628\n",
            "Epoch 666/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7283 - accuracy: 0.2102 - val_loss: 4.7318 - val_accuracy: 0.2073\n",
            "Epoch 667/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4828 - accuracy: 0.2154 - val_loss: 8.7212 - val_accuracy: 0.0602\n",
            "Epoch 668/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8427 - accuracy: 0.2052 - val_loss: 7.6086 - val_accuracy: 0.1964\n",
            "Epoch 669/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0835 - accuracy: 0.2093 - val_loss: 8.2934 - val_accuracy: 0.1829\n",
            "Epoch 670/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3522 - accuracy: 0.2146 - val_loss: 4.8818 - val_accuracy: 0.1484\n",
            "Epoch 671/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6424 - accuracy: 0.2052 - val_loss: 5.8530 - val_accuracy: 0.1248\n",
            "Epoch 672/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3259 - accuracy: 0.2117 - val_loss: 4.1243 - val_accuracy: 0.2148\n",
            "Epoch 673/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6579 - accuracy: 0.2151 - val_loss: 7.9130 - val_accuracy: 0.1707\n",
            "Epoch 674/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7639 - accuracy: 0.2090 - val_loss: 6.3988 - val_accuracy: 0.2278\n",
            "Epoch 675/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7035 - accuracy: 0.2064 - val_loss: 10.0740 - val_accuracy: 0.1449\n",
            "Epoch 676/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4990 - accuracy: 0.2090 - val_loss: 10.6698 - val_accuracy: 0.1013\n",
            "Epoch 677/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5831 - accuracy: 0.2144 - val_loss: 5.7279 - val_accuracy: 0.0952\n",
            "Epoch 678/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4683 - accuracy: 0.2096 - val_loss: 4.3998 - val_accuracy: 0.2296\n",
            "Epoch 679/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8644 - accuracy: 0.2060 - val_loss: 5.2201 - val_accuracy: 0.2030\n",
            "Epoch 680/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8787 - accuracy: 0.2051 - val_loss: 5.7580 - val_accuracy: 0.0869\n",
            "Epoch 681/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7836 - accuracy: 0.2090 - val_loss: 8.7929 - val_accuracy: 0.2161\n",
            "Epoch 682/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4688 - accuracy: 0.2073 - val_loss: 6.1299 - val_accuracy: 0.1833\n",
            "Epoch 683/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6307 - accuracy: 0.2086 - val_loss: 6.6879 - val_accuracy: 0.1218\n",
            "Epoch 684/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6479 - accuracy: 0.2084 - val_loss: 6.0658 - val_accuracy: 0.1401\n",
            "Epoch 685/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6781 - accuracy: 0.2095 - val_loss: 6.5021 - val_accuracy: 0.0899\n",
            "Epoch 686/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4452 - accuracy: 0.2099 - val_loss: 5.9842 - val_accuracy: 0.1563\n",
            "Epoch 687/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6939 - accuracy: 0.2093 - val_loss: 8.8411 - val_accuracy: 0.1667\n",
            "Epoch 688/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5884 - accuracy: 0.2108 - val_loss: 6.8980 - val_accuracy: 0.1502\n",
            "Epoch 689/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9002 - accuracy: 0.2057 - val_loss: 5.6200 - val_accuracy: 0.0895\n",
            "Epoch 690/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8083 - accuracy: 0.2055 - val_loss: 7.7892 - val_accuracy: 0.1698\n",
            "Epoch 691/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.2971 - accuracy: 0.2111 - val_loss: 6.3090 - val_accuracy: 0.1825\n",
            "Epoch 692/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5864 - accuracy: 0.2124 - val_loss: 7.4151 - val_accuracy: 0.1305\n",
            "Epoch 693/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8161 - accuracy: 0.2085 - val_loss: 10.9029 - val_accuracy: 0.0877\n",
            "Epoch 694/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5873 - accuracy: 0.2124 - val_loss: 4.6410 - val_accuracy: 0.1820\n",
            "Epoch 695/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4335 - accuracy: 0.2082 - val_loss: 8.3003 - val_accuracy: 0.1611\n",
            "Epoch 696/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8900 - accuracy: 0.2082 - val_loss: 5.7762 - val_accuracy: 0.1947\n",
            "Epoch 697/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3679 - accuracy: 0.2108 - val_loss: 9.3053 - val_accuracy: 0.1881\n",
            "Epoch 698/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6855 - accuracy: 0.2072 - val_loss: 5.1949 - val_accuracy: 0.2196\n",
            "Epoch 699/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6749 - accuracy: 0.2108 - val_loss: 7.3554 - val_accuracy: 0.1388\n",
            "Epoch 700/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5085 - accuracy: 0.2055 - val_loss: 6.8152 - val_accuracy: 0.1069\n",
            "Epoch 701/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3166 - accuracy: 0.2140 - val_loss: 7.4902 - val_accuracy: 0.1859\n",
            "Epoch 702/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8733 - accuracy: 0.2094 - val_loss: 4.9110 - val_accuracy: 0.2003\n",
            "Epoch 703/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3777 - accuracy: 0.2101 - val_loss: 5.2053 - val_accuracy: 0.2265\n",
            "Epoch 704/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6923 - accuracy: 0.2098 - val_loss: 11.0245 - val_accuracy: 0.0960\n",
            "Epoch 705/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3311 - accuracy: 0.2177 - val_loss: 4.8603 - val_accuracy: 0.1628\n",
            "Epoch 706/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5019 - accuracy: 0.2132 - val_loss: 4.2887 - val_accuracy: 0.1427\n",
            "Epoch 707/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5265 - accuracy: 0.2148 - val_loss: 8.4200 - val_accuracy: 0.1550\n",
            "Epoch 708/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8860 - accuracy: 0.2116 - val_loss: 7.9251 - val_accuracy: 0.1584\n",
            "Epoch 709/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4581 - accuracy: 0.2124 - val_loss: 7.6047 - val_accuracy: 0.0851\n",
            "Epoch 710/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7009 - accuracy: 0.2108 - val_loss: 6.4925 - val_accuracy: 0.2038\n",
            "Epoch 711/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6398 - accuracy: 0.2165 - val_loss: 8.4463 - val_accuracy: 0.1785\n",
            "Epoch 712/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6736 - accuracy: 0.2101 - val_loss: 7.0710 - val_accuracy: 0.1013\n",
            "Epoch 713/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4749 - accuracy: 0.2067 - val_loss: 5.6545 - val_accuracy: 0.1624\n",
            "Epoch 714/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5857 - accuracy: 0.2071 - val_loss: 7.6742 - val_accuracy: 0.0860\n",
            "Epoch 715/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5260 - accuracy: 0.2154 - val_loss: 6.5974 - val_accuracy: 0.1292\n",
            "Epoch 716/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4719 - accuracy: 0.2140 - val_loss: 4.7428 - val_accuracy: 0.1641\n",
            "Epoch 717/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6611 - accuracy: 0.2120 - val_loss: 12.2415 - val_accuracy: 0.2012\n",
            "Epoch 718/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4729 - accuracy: 0.2101 - val_loss: 7.4798 - val_accuracy: 0.1218\n",
            "Epoch 719/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7312 - accuracy: 0.2113 - val_loss: 6.7634 - val_accuracy: 0.1842\n",
            "Epoch 720/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8451 - accuracy: 0.2101 - val_loss: 7.6108 - val_accuracy: 0.1074\n",
            "Epoch 721/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8492 - accuracy: 0.2073 - val_loss: 4.8048 - val_accuracy: 0.0856\n",
            "Epoch 722/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4818 - accuracy: 0.2150 - val_loss: 5.7724 - val_accuracy: 0.1973\n",
            "Epoch 723/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3976 - accuracy: 0.2188 - val_loss: 5.1196 - val_accuracy: 0.2532\n",
            "Epoch 724/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7273 - accuracy: 0.2075 - val_loss: 5.7656 - val_accuracy: 0.2283\n",
            "Epoch 725/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6841 - accuracy: 0.2120 - val_loss: 7.9343 - val_accuracy: 0.1357\n",
            "Epoch 726/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4334 - accuracy: 0.2101 - val_loss: 7.1758 - val_accuracy: 0.1729\n",
            "Epoch 727/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6308 - accuracy: 0.2116 - val_loss: 7.1122 - val_accuracy: 0.1571\n",
            "Epoch 728/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9334 - accuracy: 0.2080 - val_loss: 7.1358 - val_accuracy: 0.1733\n",
            "Epoch 729/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5115 - accuracy: 0.2182 - val_loss: 8.1134 - val_accuracy: 0.1877\n",
            "Epoch 730/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7219 - accuracy: 0.2124 - val_loss: 4.7894 - val_accuracy: 0.2335\n",
            "Epoch 731/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5781 - accuracy: 0.2116 - val_loss: 5.2856 - val_accuracy: 0.1711\n",
            "Epoch 732/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5589 - accuracy: 0.2117 - val_loss: 6.1591 - val_accuracy: 0.1938\n",
            "Epoch 733/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3311 - accuracy: 0.2153 - val_loss: 3.8797 - val_accuracy: 0.2405\n",
            "Epoch 734/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9289 - accuracy: 0.2047 - val_loss: 8.8953 - val_accuracy: 0.1218\n",
            "Epoch 735/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4980 - accuracy: 0.2150 - val_loss: 5.5503 - val_accuracy: 0.0746\n",
            "Epoch 736/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5445 - accuracy: 0.2126 - val_loss: 4.2660 - val_accuracy: 0.2217\n",
            "Epoch 737/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5094 - accuracy: 0.2099 - val_loss: 4.6239 - val_accuracy: 0.2169\n",
            "Epoch 738/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7937 - accuracy: 0.2094 - val_loss: 5.1922 - val_accuracy: 0.2104\n",
            "Epoch 739/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6326 - accuracy: 0.2125 - val_loss: 10.8824 - val_accuracy: 0.0886\n",
            "Epoch 740/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6623 - accuracy: 0.2109 - val_loss: 5.1999 - val_accuracy: 0.1755\n",
            "Epoch 741/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7079 - accuracy: 0.2112 - val_loss: 6.7365 - val_accuracy: 0.0952\n",
            "Epoch 742/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9171 - accuracy: 0.2054 - val_loss: 6.9006 - val_accuracy: 0.1912\n",
            "Epoch 743/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6915 - accuracy: 0.2121 - val_loss: 5.8479 - val_accuracy: 0.1292\n",
            "Epoch 744/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4636 - accuracy: 0.2136 - val_loss: 5.1054 - val_accuracy: 0.1969\n",
            "Epoch 745/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8058 - accuracy: 0.2088 - val_loss: 6.1552 - val_accuracy: 0.1227\n",
            "Epoch 746/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3715 - accuracy: 0.2120 - val_loss: 11.4725 - val_accuracy: 0.0624\n",
            "Epoch 747/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5883 - accuracy: 0.2119 - val_loss: 7.8869 - val_accuracy: 0.1803\n",
            "Epoch 748/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8355 - accuracy: 0.2058 - val_loss: 6.1199 - val_accuracy: 0.1929\n",
            "Epoch 749/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5276 - accuracy: 0.2128 - val_loss: 8.1064 - val_accuracy: 0.1729\n",
            "Epoch 750/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.2745 - accuracy: 0.2157 - val_loss: 5.2362 - val_accuracy: 0.1772\n",
            "Epoch 751/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5010 - accuracy: 0.2110 - val_loss: 5.9840 - val_accuracy: 0.1593\n",
            "Epoch 752/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9637 - accuracy: 0.2074 - val_loss: 9.0250 - val_accuracy: 0.1523\n",
            "Epoch 753/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3424 - accuracy: 0.2181 - val_loss: 6.9955 - val_accuracy: 0.1392\n",
            "Epoch 754/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7098 - accuracy: 0.2090 - val_loss: 7.2179 - val_accuracy: 0.1772\n",
            "Epoch 755/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3765 - accuracy: 0.2098 - val_loss: 8.4918 - val_accuracy: 0.0978\n",
            "Epoch 756/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4315 - accuracy: 0.2120 - val_loss: 4.7137 - val_accuracy: 0.2187\n",
            "Epoch 757/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7609 - accuracy: 0.2094 - val_loss: 6.8281 - val_accuracy: 0.1772\n",
            "Epoch 758/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3915 - accuracy: 0.2160 - val_loss: 5.7636 - val_accuracy: 0.1349\n",
            "Epoch 759/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6775 - accuracy: 0.2112 - val_loss: 8.0145 - val_accuracy: 0.1004\n",
            "Epoch 760/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 4.9734 - accuracy: 0.2198 - val_loss: 8.5273 - val_accuracy: 0.1305\n",
            "Epoch 761/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7679 - accuracy: 0.2146 - val_loss: 5.7477 - val_accuracy: 0.1584\n",
            "Epoch 762/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7048 - accuracy: 0.2111 - val_loss: 7.0402 - val_accuracy: 0.1654\n",
            "Epoch 763/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6180 - accuracy: 0.2118 - val_loss: 11.0485 - val_accuracy: 0.1624\n",
            "Epoch 764/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7931 - accuracy: 0.2098 - val_loss: 5.7357 - val_accuracy: 0.2165\n",
            "Epoch 765/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5737 - accuracy: 0.2119 - val_loss: 6.4174 - val_accuracy: 0.1554\n",
            "Epoch 766/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7314 - accuracy: 0.2116 - val_loss: 5.5371 - val_accuracy: 0.0965\n",
            "Epoch 767/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4868 - accuracy: 0.2082 - val_loss: 5.9123 - val_accuracy: 0.1667\n",
            "Epoch 768/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.0125 - accuracy: 0.2201 - val_loss: 5.6273 - val_accuracy: 0.1187\n",
            "Epoch 769/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7247 - accuracy: 0.2140 - val_loss: 4.6637 - val_accuracy: 0.2305\n",
            "Epoch 770/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6256 - accuracy: 0.2119 - val_loss: 7.8575 - val_accuracy: 0.2226\n",
            "Epoch 771/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7633 - accuracy: 0.2095 - val_loss: 7.0155 - val_accuracy: 0.2174\n",
            "Epoch 772/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6009 - accuracy: 0.2097 - val_loss: 8.2106 - val_accuracy: 0.1218\n",
            "Epoch 773/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4484 - accuracy: 0.2136 - val_loss: 8.9764 - val_accuracy: 0.1200\n",
            "Epoch 774/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6038 - accuracy: 0.2112 - val_loss: 5.5510 - val_accuracy: 0.1536\n",
            "Epoch 775/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 6.0073 - accuracy: 0.2073 - val_loss: 8.2462 - val_accuracy: 0.1270\n",
            "Epoch 776/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3696 - accuracy: 0.2110 - val_loss: 4.9465 - val_accuracy: 0.1715\n",
            "Epoch 777/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5463 - accuracy: 0.2117 - val_loss: 5.4226 - val_accuracy: 0.2340\n",
            "Epoch 778/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4182 - accuracy: 0.2115 - val_loss: 5.5620 - val_accuracy: 0.1550\n",
            "Epoch 779/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3363 - accuracy: 0.2095 - val_loss: 6.6711 - val_accuracy: 0.1126\n",
            "Epoch 780/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8438 - accuracy: 0.2063 - val_loss: 5.9050 - val_accuracy: 0.1628\n",
            "Epoch 781/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7996 - accuracy: 0.2057 - val_loss: 6.9331 - val_accuracy: 0.1899\n",
            "Epoch 782/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5749 - accuracy: 0.2116 - val_loss: 7.5263 - val_accuracy: 0.1667\n",
            "Epoch 783/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8184 - accuracy: 0.2103 - val_loss: 10.1040 - val_accuracy: 0.0829\n",
            "Epoch 784/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.2275 - accuracy: 0.2156 - val_loss: 15.8671 - val_accuracy: 0.1082\n",
            "Epoch 785/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8292 - accuracy: 0.2085 - val_loss: 5.0365 - val_accuracy: 0.1458\n",
            "Epoch 786/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7454 - accuracy: 0.2109 - val_loss: 7.4526 - val_accuracy: 0.1344\n",
            "Epoch 787/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6244 - accuracy: 0.2095 - val_loss: 5.6522 - val_accuracy: 0.1384\n",
            "Epoch 788/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3919 - accuracy: 0.2148 - val_loss: 6.0977 - val_accuracy: 0.1091\n",
            "Epoch 789/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8174 - accuracy: 0.2159 - val_loss: 6.1854 - val_accuracy: 0.1423\n",
            "Epoch 790/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9832 - accuracy: 0.2056 - val_loss: 5.7336 - val_accuracy: 0.1196\n",
            "Epoch 791/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5187 - accuracy: 0.2126 - val_loss: 9.2362 - val_accuracy: 0.1715\n",
            "Epoch 792/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3755 - accuracy: 0.2168 - val_loss: 4.3524 - val_accuracy: 0.1650\n",
            "Epoch 793/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4328 - accuracy: 0.2129 - val_loss: 7.5381 - val_accuracy: 0.1576\n",
            "Epoch 794/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7603 - accuracy: 0.2082 - val_loss: 9.9941 - val_accuracy: 0.1545\n",
            "Epoch 795/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4891 - accuracy: 0.2129 - val_loss: 6.8550 - val_accuracy: 0.2169\n",
            "Epoch 796/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4786 - accuracy: 0.2117 - val_loss: 7.6048 - val_accuracy: 0.1816\n",
            "Epoch 797/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5549 - accuracy: 0.2081 - val_loss: 6.0021 - val_accuracy: 0.1580\n",
            "Epoch 798/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3907 - accuracy: 0.2162 - val_loss: 3.9888 - val_accuracy: 0.1445\n",
            "Epoch 799/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9062 - accuracy: 0.2067 - val_loss: 6.3101 - val_accuracy: 0.1309\n",
            "Epoch 800/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4904 - accuracy: 0.2119 - val_loss: 4.8717 - val_accuracy: 0.1685\n",
            "Epoch 801/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.8781 - accuracy: 0.2059 - val_loss: 5.3291 - val_accuracy: 0.1999\n",
            "Epoch 802/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5583 - accuracy: 0.2151 - val_loss: 6.1426 - val_accuracy: 0.2025\n",
            "Epoch 803/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4416 - accuracy: 0.2128 - val_loss: 4.4760 - val_accuracy: 0.1916\n",
            "Epoch 804/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6719 - accuracy: 0.2107 - val_loss: 6.5034 - val_accuracy: 0.1890\n",
            "Epoch 805/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6847 - accuracy: 0.2092 - val_loss: 6.4203 - val_accuracy: 0.1619\n",
            "Epoch 806/2500\n",
            "453/453 [==============================] - 2s 3ms/step - loss: 5.3250 - accuracy: 0.2157 - val_loss: 8.3504 - val_accuracy: 0.1248\n",
            "Epoch 807/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.4838 - accuracy: 0.2154 - val_loss: 7.5335 - val_accuracy: 0.1052\n",
            "Epoch 808/2500\n",
            "453/453 [==============================] - 2s 4ms/step - loss: 5.5723 - accuracy: 0.2138 - val_loss: 6.6545 - val_accuracy: 0.1724\n",
            "Epoch 809/2500\n",
            "453/453 [==============================] - 2s 5ms/step - loss: 5.5591 - accuracy: 0.2118 - val_loss: 5.3486 - val_accuracy: 0.2449\n",
            "Epoch 810/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6927 - accuracy: 0.2099 - val_loss: 11.1896 - val_accuracy: 0.1641\n",
            "Epoch 811/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5066 - accuracy: 0.2163 - val_loss: 5.4272 - val_accuracy: 0.1729\n",
            "Epoch 812/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3604 - accuracy: 0.2189 - val_loss: 6.1466 - val_accuracy: 0.1576\n",
            "Epoch 813/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5242 - accuracy: 0.2099 - val_loss: 6.6299 - val_accuracy: 0.1711\n",
            "Epoch 814/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5501 - accuracy: 0.2125 - val_loss: 6.9562 - val_accuracy: 0.1227\n",
            "Epoch 815/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4859 - accuracy: 0.2163 - val_loss: 5.9118 - val_accuracy: 0.1615\n",
            "Epoch 816/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5686 - accuracy: 0.2191 - val_loss: 5.1344 - val_accuracy: 0.2078\n",
            "Epoch 817/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.7798 - accuracy: 0.2087 - val_loss: 5.6311 - val_accuracy: 0.1231\n",
            "Epoch 818/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4374 - accuracy: 0.2181 - val_loss: 9.5667 - val_accuracy: 0.1467\n",
            "Epoch 819/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.9422 - accuracy: 0.2050 - val_loss: 6.4516 - val_accuracy: 0.2510\n",
            "Epoch 820/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5668 - accuracy: 0.2122 - val_loss: 5.2760 - val_accuracy: 0.1820\n",
            "Epoch 821/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.4588 - accuracy: 0.2100 - val_loss: 4.3929 - val_accuracy: 0.2056\n",
            "Epoch 822/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5175 - accuracy: 0.2151 - val_loss: 5.7586 - val_accuracy: 0.1859\n",
            "Epoch 823/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5061 - accuracy: 0.2137 - val_loss: 8.6955 - val_accuracy: 0.1615\n",
            "Epoch 824/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.5295 - accuracy: 0.2169 - val_loss: 7.1194 - val_accuracy: 0.0703\n",
            "Epoch 825/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3636 - accuracy: 0.2119 - val_loss: 5.7244 - val_accuracy: 0.1213\n",
            "Epoch 826/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6579 - accuracy: 0.2125 - val_loss: 7.3043 - val_accuracy: 0.1990\n",
            "Epoch 827/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.6041 - accuracy: 0.2139 - val_loss: 7.9677 - val_accuracy: 0.2100\n",
            "Epoch 828/2500\n",
            "453/453 [==============================] - 1s 3ms/step - loss: 5.3240 - accuracy: 0.2152 - val_loss: 4.3942 - val_accuracy: 0.1680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_validation, np.argmax(model_NN.predict(X_validation), axis = 1))"
      ],
      "metadata": {
        "id": "7rAbl_V2yDew",
        "outputId": "9caac039-ff67-424b-e0b1-46d037a55d68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27324312527280664"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_accuracy_score(y_validation, model_NN.predict(X_validation), labels = np.arange(0,21,1))"
      ],
      "metadata": {
        "id": "HtAqZ2Z4-Ua_",
        "outputId": "140cdaae-4661-4db6-d06f-88c9100aa136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3897861195984286"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = full_processor.transform(eliminate_genres_without_enough_observations(df_music_test))"
      ],
      "metadata": {
        "id": "Po3cxn9z-CtY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = label_encoder.transform(eliminate_genres_without_enough_observations(df_music_test).genre)"
      ],
      "metadata": {
        "id": "xbAFY0Tc-mZB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_accuracy_score(y_test, model_NN.predict(X_test), labels = np.arange(0,21,1))"
      ],
      "metadata": {
        "id": "o0C8hfQd-O3X",
        "outputId": "067922bd-5003-44c1-dba0-ce317fd00fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92/92 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3484796720191322"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}