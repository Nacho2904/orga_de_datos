{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+1jnzE0tBp3aADDAY4jpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nacho2904/orga_de_datos/blob/main/tp3_parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP3 Parte II: Baseline"
      ],
      "metadata": {
        "id": "JMf_D_txvJfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del análisis exploratorio de la parte I hemos aprendido algunas cosas:\n",
        "- Hay algunas columnas que no nos aportan información. En particular *did* tiene utilidad por no estar en la mayoría de columnas, y *s-label* no sabemos cómo interpretarlo. *Language* tampoco aporta demasiado debido a que falta en muchas canciones. El *artist_name* no debería proporcionar demasiada información al modelo teniendo en cuenta que tenemos su número de canciones y sus géneros predilectos.\n",
        "\n",
        "- Algunas columnas requieren preprocessing. Las tres columnas de texto que tenemos, *track-name*, *lyrics* y *artist*, no pueden ser usadas directamente. *mode* y *key*, por otro lado, son features categóricas. *a_genres* también es una variable categórica que contiene varias clases. Luego hay que preprocesar las features de texto para crear nuevos features útiles, y preprocesar las features categóricas para poder utilizarlas en la regresión logística.\n",
        "\n",
        "- No tenemos suficientes observaciones para algunos de los posibles valores del target."
      ],
      "metadata": {
        "id": "FBkL9n3Vt7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive \n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import functools\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path_a_training_set = 'gdrive/MyDrive/TP3 dataset music/train.parquet'\n",
        "\n",
        "df_music_train = pd.read_parquet(path_a_training_set)"
      ],
      "metadata": {
        "id": "CfvksKXqhTcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb39bc7-ea30-4f06-aec3-ae5558b629b7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_music_train_filtered = df_music_train.drop(labels=[\"s-label\", \"did\", \"language\"], axis=1)\n",
        "df_music_train_filtered.info()"
      ],
      "metadata": {
        "id": "-BCToRkEi8Db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114ff3d0-6d24-4841-9ec0-5741dcce7a1a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31383 entries, 0 to 34336\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   track_name        31383 non-null  object \n",
            " 1   lyric             31380 non-null  object \n",
            " 2   genre             31383 non-null  object \n",
            " 3   popularity        31383 non-null  int64  \n",
            " 4   artist            31383 non-null  object \n",
            " 5   a_genres          31383 non-null  object \n",
            " 6   a_songs           31383 non-null  float64\n",
            " 7   a_popularity      31383 non-null  float64\n",
            " 8   acousticness      31383 non-null  float64\n",
            " 9   danceability      31383 non-null  float64\n",
            " 10  duration_ms       31383 non-null  int64  \n",
            " 11  energy            31383 non-null  float64\n",
            " 12  instrumentalness  31383 non-null  float64\n",
            " 13  key               31383 non-null  object \n",
            " 14  liveness          31383 non-null  float64\n",
            " 15  loudness          31383 non-null  float64\n",
            " 16  mode              31383 non-null  object \n",
            " 17  speechiness       31383 non-null  float64\n",
            " 18  tempo             31383 non-null  float64\n",
            " 19  time_signature    31383 non-null  object \n",
            " 20  valence           31383 non-null  float64\n",
            "dtypes: float64(11), int64(2), object(8)\n",
            "memory usage: 5.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar notamos que las variables categóricas *key* y *time-signature* ambas son ordinales. La primera representa el tono dominante en la canción., y tomaremos el orden dado en [este blog](https://viva.pressbooks.pub/openmusictheory/chapter/pitch-and-pitch-class/). El *time-signature* es una medida de la cantidad de pulsos por unidad, y también está ordenado naturalmente. *Mode* es una variable binaria así que la encodeamos como 0 y 1."
      ],
      "metadata": {
        "id": "hFJV8C5gjLEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordinalEncoder = preprocessing.OrdinalEncoder(categories = [[\"Minor\", \"Major\"],['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'],\n",
        "                                                            ['1/4', '3/4', '4/4', '5/4']])"
      ],
      "metadata": {
        "id": "dQohiJ4Lhn86"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para las letras de los se me ocurre aplicar algo de NLP para realizar sentiment analysis."
      ],
      "metadata": {
        "id": "FA6kTDsNyR4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_sentiment_analysis_to_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"instrumental\")\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  negative, neutral, positive, compound = 0, 1, 2, 3\n",
        "  sentimentAnalysisOfLyrics = df_music[\"lyric\"].map(lambda lyric: list(sia.polarity_scores(lyric).values()))\n",
        "  negativeScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[negative])\n",
        "  positiveScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[positive])\n",
        "  neutralScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[neutral])\n",
        "  compoundScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[compound])\n",
        "  return pd.DataFrame(pd.concat([negativeScoreOfLyrics, positiveScoreOfLyrics,neutralScoreOfLyrics,compoundScoreOfLyrics], axis = 1))"
      ],
      "metadata": {
        "id": "hMMWFU6D4BON"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra cosa que se me ocurre es usar la suma del tf-idf para medir qué tan \"rico\" es el vocabulario de una canción: La idea es que canciones de géneros como el pop que son más masivos y apuntan a un público general tendrán una suma de tf-idf alto, mientras que géneros como la música alternativa deberían usar un vocabulario más \"peculiar\"."
      ],
      "metadata": {
        "id": "TYwPrgmfJZos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sum_tfidf_from_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  nltk.download(\"stopwords\")\n",
        "  stopwords = set(nltk.corpus.stopwords.words(\"english\")).union(set(nltk.corpus.stopwords.words(\"spanish\"))).union(set(nltk.corpus.stopwords.words(\"french\")))\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"instrumental\")\n",
        "  vectorizer = TfidfVectorizer(input = \"content\", stop_words = stopwords)\n",
        "  vectorizer.fit(df_music[\"lyric\"])\n",
        "  return pd.DataFrame([np.sum(tfidf_vector) for tfidf_vector in vectorizer.transform(df_music[\"lyric\"])])"
      ],
      "metadata": {
        "id": "seazRU21KuOZ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para los géneros simplemente utilizaré un one-hot encoding pues no quiero nublar la información super valiosa que provee los géneros usuales de los artistas con mean encoding, y además no tenemos demasiadas clases."
      ],
      "metadata": {
        "id": "q8jtrD_iBxQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode_genres(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  genres = sorted(df_music[\"genre\"].unique())\n",
        "  create_one_hot_vector_for_artist_genres = lambda a_genres: [1 if genre in a_genres else 0 for genre in genres]\n",
        "  df_music[\"one_hot_encoded_a_genres\"] = df_music[\"a_genres\"].map(create_one_hot_vector_for_artist_genres)\n",
        "  return pd.DataFrame(df_music[\"one_hot_encoded_a_genres\"].to_list())"
      ],
      "metadata": {
        "id": "TJKObbnXB-WZ"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_genres_without_enough_observations(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music_recuento_filas_por_genero = df_music.groupby(\"genre\").count().reset_index()[[\"genre\", \"track_name\"]].rename(\n",
        "    columns = {\"track_name\": \"rowCount\"}).sort_values(\"rowCount\")\n",
        "  problematic_genres = list(df_music_recuento_filas_por_genero[df_music_recuento_filas_por_genero[\"rowCount\"] < 50].genre)[1:]\n",
        "  return df_music[~df_music[\"genre\"].isin(problematic_genres)]"
      ],
      "metadata": {
        "id": "TQCnc16lQAxu"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "labelEncoder.fit_transform(df_music_train_filtered [\"genre\"])"
      ],
      "metadata": {
        "id": "7eoDYC18YWDb",
        "outputId": "4f33bdf2-e707-4037-9ee5-a11d73aceeb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 16, 17, ..., 25, 25, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_features = [\"track_name\", \"lyric\", \"artist\"]\n",
        "\n",
        "numerical_features = [\"a_songs\", \"a_popularity\", \"popularity\", \"acousticness\", \"danceability\", \"duration_ms\",\n",
        "                   \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\"]\n",
        "\n",
        "ordinal_features = [\"mode\", \"key\", \"time_signature\"]\n",
        "\n",
        "artist_genres = [\"a_genres\", \"genre\"]\n",
        "\n",
        "label = [\"genre\"]\n",
        "\n",
        "identity_transformer = preprocessing.FunctionTransformer(None)\n",
        "\n",
        "full_processor = ColumnTransformer(transformers=[\n",
        "    ('text_sentiment_analysis', preprocessing.FunctionTransformer(apply_sentiment_analysis_to_lyrics), text_features),\n",
        "    ('text_tf_idf', preprocessing.FunctionTransformer(get_sum_tfidf_from_lyrics), text_features),\n",
        "    ('artist_genres', preprocessing.FunctionTransformer(one_hot_encode_genres), artist_genres),\n",
        "    ('numerical', identity_transformer, numerical_features),\n",
        "    ('ordinal', ordinalEncoder, ordinal_features),\n",
        "])\n",
        "\n",
        "logistic_regression_pipeline = Pipeline(steps = [\n",
        "    ('preprocess_X', full_processor),\n",
        "    ('model', LogisticRegression(penalty='l2', C = 1, solver = \"liblinear\", max_iter = 50))\n",
        "])"
      ],
      "metadata": {
        "id": "ApBgPVOuocwU"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "y = labelEncoder.fit_transform(eliminate_genres_without_enough_observations(df_music_train_filtered)[\"genre\"])\n",
        "\n",
        "logistic_regression_pipeline.fit(eliminate_genres_without_enough_observations(df_music_train), y)"
      ],
      "metadata": {
        "id": "PEUXTnO9hY41",
        "outputId": "ff1f1ad1-40ba-47ef-88b8-62306b28b2af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocess_X',\n",
              "                 ColumnTransformer(transformers=[('text_sentiment_analysis',\n",
              "                                                  FunctionTransformer(func=<function apply_sentiment_analysis_to_lyrics at 0x7f09342eec20>),\n",
              "                                                  ['track_name', 'lyric',\n",
              "                                                   'artist']),\n",
              "                                                 ('text_tf_idf',\n",
              "                                                  FunctionTransformer(func=<function get_sum_tfidf_from_lyrics at 0x7f093426e830>),\n",
              "                                                  ['track_name', 'lyric',\n",
              "                                                   'artist']),\n",
              "                                                 ('artist_genr...\n",
              "                                                   'danceability',\n",
              "                                                   'duration_ms', 'energy',\n",
              "                                                   'instrumentalness',\n",
              "                                                   'liveness', 'loudness',\n",
              "                                                   'speechiness', 'tempo',\n",
              "                                                   'valence']),\n",
              "                                                 ('ordinal',\n",
              "                                                  OrdinalEncoder(categories=[['Minor',\n",
              "                                                                              'Major'],\n",
              "                                                                             ['C',\n",
              "                                                                              'C#',\n",
              "                                                                              'D',\n",
              "                                                                              'D#',\n",
              "                                                                              'E',\n",
              "                                                                              'F',\n",
              "                                                                              'F#',\n",
              "                                                                              'G',\n",
              "                                                                              'G#',\n",
              "                                                                              'A',\n",
              "                                                                              'A#',\n",
              "                                                                              'B'],\n",
              "                                                                             ['1/4',\n",
              "                                                                              '3/4',\n",
              "                                                                              '4/4',\n",
              "                                                                              '5/4']]),\n",
              "                                                  ['mode', 'key',\n",
              "                                                   'time_signature'])])),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=1, max_iter=50, solver='liblinear'))])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = logistic_regression_pipeline.predict_proba(eliminate_genres_without_enough_observations(df_music_train))"
      ],
      "metadata": {
        "id": "pAXQW8M-i-ui",
        "outputId": "7b0efefe-be64-4321-94a3-c3fe06c089f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import top_k_accuracy_score\n",
        "top_k_accuracy_score(y, preds, k=2)"
      ],
      "metadata": {
        "id": "lRv8CYgBkoHl",
        "outputId": "5b442d0f-d588-48aa-8678-f10e659581a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3156024963994239"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "mylUnMKklkIy",
        "outputId": "e65d4d20-ea69-42da-8fd6-a15da392e43f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12, 12, 12, ...,  7,  0,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    }
  ]
}