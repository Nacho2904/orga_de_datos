{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsnToeNOeGGl/3jvfbb2vp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nacho2904/orga_de_datos/blob/main/tp3_parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP3 Parte II: Baseline"
      ],
      "metadata": {
        "id": "JMf_D_txvJfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del análisis exploratorio de la parte I hemos aprendido algunas cosas:\n",
        "- Hay algunas columnas que no nos aportan información. En particular *did* tiene utilidad por no estar en la mayoría de columnas. El *artist_name* no debería proporcionar demasiada información al modelo teniendo en cuenta que tenemos su número de canciones y sus géneros predilectos.\n",
        "\n",
        "- Algunas columnas requieren preprocessing. Las tres columnas de texto que tenemos, *track-name*, *lyrics* y *artist*, no pueden ser usadas directamente. *mode* y *key*, por otro lado, son features categóricas. *a_genres* también es una variable categórica que contiene varias clases. Luego hay que preprocesar las features de texto para crear nuevos features útiles, y preprocesar las features categóricas para poder utilizarlas en la regresión logística.\n",
        "\n",
        "- No tenemos suficientes observaciones para algunos de los posibles valores del target."
      ],
      "metadata": {
        "id": "FBkL9n3Vt7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from google.colab import drive \n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "import functools\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path_a_training_set = 'gdrive/MyDrive/TP3 dataset music/train.parquet'\n",
        "\n",
        "df_music_train = pd.read_parquet(path_a_training_set)"
      ],
      "metadata": {
        "id": "CfvksKXqhTcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23772270-478b-41ae-f19a-58249d2c293d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_music_train_filtered = df_music_train.drop(labels=[\"did\"], axis=1)\n",
        "df_music_train_filtered.info()"
      ],
      "metadata": {
        "id": "-BCToRkEi8Db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6138a03-ea8d-4a48-e8ed-84b5d808dd32"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31383 entries, 0 to 34336\n",
            "Data columns (total 23 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   track_name        31383 non-null  object \n",
            " 1   lyric             31380 non-null  object \n",
            " 2   genre             31383 non-null  object \n",
            " 3   language          24021 non-null  object \n",
            " 4   popularity        31383 non-null  int64  \n",
            " 5   artist            31383 non-null  object \n",
            " 6   a_genres          31383 non-null  object \n",
            " 7   a_songs           31383 non-null  float64\n",
            " 8   a_popularity      31383 non-null  float64\n",
            " 9   s-label           7004 non-null   float64\n",
            " 10  acousticness      31383 non-null  float64\n",
            " 11  danceability      31383 non-null  float64\n",
            " 12  duration_ms       31383 non-null  int64  \n",
            " 13  energy            31383 non-null  float64\n",
            " 14  instrumentalness  31383 non-null  float64\n",
            " 15  key               31383 non-null  object \n",
            " 16  liveness          31383 non-null  float64\n",
            " 17  loudness          31383 non-null  float64\n",
            " 18  mode              31383 non-null  object \n",
            " 19  speechiness       31383 non-null  float64\n",
            " 20  tempo             31383 non-null  float64\n",
            " 21  time_signature    31383 non-null  object \n",
            " 22  valence           31383 non-null  float64\n",
            "dtypes: float64(12), int64(2), object(9)\n",
            "memory usage: 5.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar notamos que las variables categóricas *key* y *time-signature* ambas son ordinales. La primera representa el tono dominante en la canción., y tomaremos el orden dado en [este blog](https://viva.pressbooks.pub/openmusictheory/chapter/pitch-and-pitch-class/). El *time-signature* es una medida de la cantidad de pulsos por unidad, y también está ordenado naturalmente. *Mode* es una variable binaria así que la encodeamos como 0 y 1."
      ],
      "metadata": {
        "id": "hFJV8C5gjLEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordinalEncoder = preprocessing.OrdinalEncoder(categories = [[\"Minor\", \"Major\"],['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'],\n",
        "                                                            ['1/4', '3/4', '4/4', '5/4']])"
      ],
      "metadata": {
        "id": "dQohiJ4Lhn86"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para las letras de los se me ocurre aplicar algo de NLP para realizar sentiment analysis."
      ],
      "metadata": {
        "id": "FA6kTDsNyR4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "def apply_sentiment_analysis_to_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"instrumental\")\n",
        "  sia = SentimentIntensityAnalyzer()\n",
        "  negative, neutral, positive, compound = 0, 1, 2, 3\n",
        "  sentimentAnalysisOfLyrics = df_music[\"lyric\"].map(lambda lyric: list(sia.polarity_scores(lyric).values()))\n",
        "  negativeScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[negative])\n",
        "  positiveScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[positive])\n",
        "  neutralScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[neutral])\n",
        "  compoundScoreOfLyrics = sentimentAnalysisOfLyrics.map(lambda row: row[compound])\n",
        "  return pd.DataFrame(pd.concat([negativeScoreOfLyrics, positiveScoreOfLyrics,neutralScoreOfLyrics,compoundScoreOfLyrics], axis = 1))"
      ],
      "metadata": {
        "id": "hMMWFU6D4BON",
        "outputId": "79a6ee07-d618-418d-8e14-9210ecf5bcfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra cosa que se me ocurre es usar la suma del tf-idf para medir qué tan \"rico\" es el vocabulario de una canción: La idea es que canciones de géneros como el pop que son más masivos y apuntan a un público general tendrán una suma de tf-idf alto, mientras que géneros como la música alternativa deberían usar un vocabulario más \"peculiar\"."
      ],
      "metadata": {
        "id": "TYwPrgmfJZos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "def get_sum_tfidf_from_lyrics(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  stopwords = set(nltk.corpus.stopwords.words(\"english\")).union(set(nltk.corpus.stopwords.words(\"spanish\"))).union(set(nltk.corpus.stopwords.words(\"french\")))\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"instrumental\")\n",
        "  vectorizer = TfidfVectorizer(input = \"content\", stop_words = stopwords)\n",
        "  vectorizer.fit(df_music[\"lyric\"])\n",
        "  return pd.DataFrame([np.sum(tfidf_vector) for tfidf_vector in vectorizer.transform(df_music[\"lyric\"])])"
      ],
      "metadata": {
        "id": "seazRU21KuOZ",
        "outputId": "760f0346-82a3-463a-bf2c-ca6018cd4beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminate_genres_without_enough_observations(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music_recuento_filas_por_genero = df_music.groupby(\"genre\").count().reset_index()[[\"genre\", \"track_name\"]].rename(\n",
        "    columns = {\"track_name\": \"rowCount\"}).sort_values(\"rowCount\")\n",
        "  problematic_genres = list(df_music_recuento_filas_por_genero[df_music_recuento_filas_por_genero[\"rowCount\"] < 50].genre)[1:]\n",
        "  return df_music[~df_music[\"genre\"].isin(problematic_genres)]"
      ],
      "metadata": {
        "id": "TQCnc16lQAxu"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos conseguir varias features de las longitudes de los textos"
      ],
      "metadata": {
        "id": "10nohwQQNmOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "def get_length_transforms_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"\")\n",
        "  df_music[\"track_name\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"\")\n",
        "  df_music[\"number_of_lines\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric.split(\"\\n\")))\n",
        "  df_music[\"number_of_tokens\"] = df_music[\"lyric\"].map(lambda lyric: len(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"length_lyrics\"] = df_music[\"lyric\"].map(lambda lyric: len(lyric))\n",
        "  df_music[\"length_of_track_name\"] = df_music[\"track_name\"].map(lambda track_name: len(track_name))\n",
        "  df_music[\"tokens_of_track_name\"] = df_music[\"track_name\"].map(lambda track_name: len(nltk.word_tokenize(track_name)))\n",
        "  return df_music[[\"length_lyrics\", \"length_of_track_name\", \"number_of_lines\", \"number_of_tokens\"]]"
      ],
      "metadata": {
        "id": "T1QqQUHIEHzj",
        "outputId": "0219a03c-c18a-4e89-f9d1-35e80c2fcdfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analizo las lyrics también usando [POS-Chunk tagging](https://www.guru99.com/pos-tagging-chunking-nltk.html)"
      ],
      "metadata": {
        "id": "Kl3xUtILNqi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(nltk.word_tokenize(\"Hey how are you\"))\n",
        "useful_pos_tags = {\"FW\", \"JJR\", \"JJS\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"PRP\", \"RB\", \"RBR\", \"RBS\",\n",
        "                   \"UH\", \"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"}"
      ],
      "metadata": {
        "id": "AeUMKy6VRbbn",
        "outputId": "c0afb464-0482-4699-f3ce-1e8559452151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hey', 'NNP'), ('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP')]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_POS_vector_from_lyric_POS(lyric_POS):\n",
        "  useful_pos_tags = [\"FW\", \"JJR\", \"JJS\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"PRP\", \"RB\", \"RBR\", \"RBS\",\n",
        "                   \"UH\", \"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"]\n",
        "  POS_dictionary = {pos_tag:0 for pos_tag in useful_pos_tags}\n",
        "  POS_dictionary.update({\"other\":0})\n",
        "\n",
        "  for token in lyric_POS:\n",
        "    if token[1] in useful_pos_tags:\n",
        "      POS_dictionary[token[1]] += 1\n",
        "    else:\n",
        "      POS_dictionary[\"other\"] += 1\n",
        "\n",
        "  return [POS_dictionary[pos_tag] for pos_tag in POS_dictionary]\n",
        "  \n",
        "  \n",
        "def get_POS_chunk_taggin_counts_for_text(df_music: pd.DataFrame) -> pd.DataFrame:\n",
        "  useful_pos_tags = {\"FW\", \"JJR\", \"JJS\", \"NN\", \"NNS\", \"NNP\", \"NNPS\", \"PDT\", \"PRP\", \"RB\", \"RBR\", \"RBS\",\n",
        "                   \"UH\", \"VB\", \"VBG\", \"VBD\", \"VBN\", \"VBP\", \"VBZ\"}\n",
        "  df_music[\"lyric\"] = df_music[\"lyric\"].map(lambda lyric: lyric if lyric else \"\")\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric\"].map(lambda lyric: nltk.pos_tag(nltk.word_tokenize(lyric)))\n",
        "  df_music[\"lyric_POS\"] = df_music[\"lyric_POS\"].map(lambda lyric_pos: get_POS_vector_from_lyric_POS(lyric_pos))\n",
        "  return pd.DataFrame(df_music[\"lyric_POS\"].to_list())\n"
      ],
      "metadata": {
        "id": "LOEyM2E-Ny6P"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos un test de validation seleccionando diferentes artistas"
      ],
      "metadata": {
        "id": "A269jvKR12DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_music_filtered_genres = eliminate_genres_without_enough_observations(df_music_train_filtered)\n",
        "artists = list(df_music_filtered_genres[\"artist\"].unique())\n",
        "train_artists = set(artists[:int(0.8*len(artists))])\n",
        "validation_artists = set(artists[int(0.8*len(artists)):])\n",
        "train_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(train_artists)]\n",
        "validation_set = df_music_filtered_genres[df_music_filtered_genres[\"artist\"].isin(validation_artists)]"
      ],
      "metadata": {
        "id": "0WXfDLhA174X"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "text_features = [\"track_name\", \"lyric\", \"artist\"]\n",
        "\n",
        "numerical_features = [\"a_songs\", \"a_popularity\", \"popularity\", \"acousticness\", \"danceability\", \"duration_ms\",\n",
        "                   \"energy\", \"instrumentalness\", \"liveness\", \"loudness\", \"speechiness\", \"tempo\", \"valence\"]\n",
        "\n",
        "ordinal_features = [\"mode\", \"key\", \"time_signature\"]\n",
        "\n",
        "one_hot_features = [\"language\"]\n",
        "\n",
        "artist_genres = [\"a_genres\", \"genre\"]\n",
        "\n",
        "label = [\"genre\"]\n",
        "\n",
        "identity_transformer = preprocessing.FunctionTransformer(None)\n",
        "\n",
        "full_processor = ColumnTransformer(transformers=[\n",
        "    ('text_sentiment_analysis', preprocessing.FunctionTransformer(apply_sentiment_analysis_to_lyrics), text_features),\n",
        "    ('text_tf_idf', preprocessing.FunctionTransformer(get_sum_tfidf_from_lyrics), text_features),\n",
        "    ('text_simple_transforms', preprocessing.FunctionTransformer(get_length_transforms_for_text), text_features),\n",
        "    ('text_POS_count', preprocessing.FunctionTransformer(get_POS_chunk_taggin_counts_for_text), text_features),\n",
        "    ('one-hot', preprocessing.OneHotEncoder(), one_hot_features),\n",
        "    ('numerical', identity_transformer, numerical_features),\n",
        "    ('ordinal', ordinalEncoder, ordinal_features),\n",
        "])\n",
        "\n",
        "logistic_regression_pipeline = Pipeline(steps = [\n",
        "    ('preprocess_X', full_processor),\n",
        "    ('model', LogisticRegression(penalty='l2', C = 1, solver = \"liblinear\", max_iter = 500))\n",
        "])"
      ],
      "metadata": {
        "id": "ApBgPVOuocwU"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "labelEncoder.fit(eliminate_genres_without_enough_observations(df_music_train_filtered)[\"genre\"])\n",
        "y = labelEncoder.transform(train_set[\"genre\"])\n",
        "\n",
        "logistic_regression_pipeline.fit(train_set, y)"
      ],
      "metadata": {
        "id": "PEUXTnO9hY41",
        "outputId": "4494e5c2-b1c9-4c65-c7dd-f8a6149f1159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocess_X',\n",
              "                 ColumnTransformer(transformers=[('text_sentiment_analysis',\n",
              "                                                  FunctionTransformer(func=<function apply_sentiment_analysis_to_lyrics at 0x7fea70de8200>),\n",
              "                                                  ['track_name', 'lyric',\n",
              "                                                   'artist']),\n",
              "                                                 ('text_tf_idf',\n",
              "                                                  FunctionTransformer(func=<function get_sum_tfidf_from_lyrics at 0x7fea6abaf290>),\n",
              "                                                  ['track_name', 'lyric',\n",
              "                                                   'artist']),\n",
              "                                                 ('text_simple...\n",
              "                                                   'danceability',\n",
              "                                                   'duration_ms', 'energy',\n",
              "                                                   'instrumentalness',\n",
              "                                                   'liveness', 'loudness',\n",
              "                                                   'speechiness', 'tempo',\n",
              "                                                   'valence']),\n",
              "                                                 ('ordinal',\n",
              "                                                  OrdinalEncoder(categories=[['Minor',\n",
              "                                                                              'Major'],\n",
              "                                                                             ['C',\n",
              "                                                                              'C#',\n",
              "                                                                              'D',\n",
              "                                                                              'D#',\n",
              "                                                                              'E',\n",
              "                                                                              'F',\n",
              "                                                                              'F#',\n",
              "                                                                              'G',\n",
              "                                                                              'G#',\n",
              "                                                                              'A',\n",
              "                                                                              'A#',\n",
              "                                                                              'B'],\n",
              "                                                                             ['1/4',\n",
              "                                                                              '3/4',\n",
              "                                                                              '4/4',\n",
              "                                                                              '5/4']]),\n",
              "                                                  ['mode', 'key',\n",
              "                                                   'time_signature'])])),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=1, max_iter=500, solver='liblinear'))])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = logistic_regression_pipeline.predict_proba(validation_set)"
      ],
      "metadata": {
        "id": "pAXQW8M-i-ui"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import top_k_accuracy_score\n",
        "top_k_accuracy_score(labelEncoder.transform(validation_set[\"genre\"]), preds, k=2, labels=logistic_regression_pipeline.named_steps[\"model\"].classes_)"
      ],
      "metadata": {
        "id": "lRv8CYgBkoHl",
        "outputId": "3211cb22-d7c4-405c-f65d-bf2c295cb2da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3398286937901499"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6VOuIYQ7M-m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}